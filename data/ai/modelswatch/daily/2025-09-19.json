{
  "date": "2025-09-19",
  "updated_at": "2025-09-18T22:06:45.745Z",
  "items": [
    {
      "id": "twbs/bootstrap",
      "source": "github",
      "name": "bootstrap",
      "url": "https://github.com/twbs/bootstrap",
      "license": "MIT",
      "lang": "MDX",
      "tags": [
        "bootstrap",
        "css",
        "css-framework",
        "html",
        "javascript",
        "sass",
        "scss"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 173434,
        "forks": 79155,
        "issues": 577
      },
      "score": 189364.49197584877,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Bootstrap æ˜¯ä¸€ä¸ªå¼€æºå‰ç«¯æ¡†æ¶ï¼Œç”¨äºå¿«é€Ÿæ„å»ºå“åº”å¼ã€ç§»åŠ¨ä¼˜å…ˆçš„ç½‘é¡µé¡¹ç›®ã€‚å®ƒæä¾›äº†ä¸€å¥—å®Œæ•´çš„ HTMLã€CSS å’Œ JavaScript ç»„ä»¶ï¼ŒåŒ…æ‹¬ç½‘æ ¼ç³»ç»Ÿã€è¡¨å•ã€æŒ‰é’®å’Œå¯¼èˆªç­‰ï¼Œå¸®åŠ©å¼€å‘è€…é«˜æ•ˆå®ç°ä¸€è‡´çš„ç”¨æˆ·ç•Œé¢ã€‚å…¶æ ¸å¿ƒäº®ç‚¹åœ¨äºå¼ºå¤§çš„å“åº”å¼è®¾è®¡èƒ½åŠ›ï¼Œæ”¯æŒè·¨è®¾å¤‡é€‚é…ï¼ŒåŒæ—¶å…·å¤‡é«˜åº¦å¯å®šåˆ¶æ€§å’Œä¸°å¯Œçš„é¢„å®šä¹‰æ ·å¼ã€‚é€‚ç”¨äºå„ç±» Web åº”ç”¨å¼€å‘ï¼Œå°¤å…¶é€‚åˆéœ€è¦å¿«é€ŸåŸå‹è®¾è®¡æˆ–ç»Ÿä¸€è§†è§‰è§„èŒƒçš„é¡¹ç›®ã€‚",
      "updated_at": "2025-09-18T15:42:19Z",
      "summary_en": "Bootstrap is a widely-used front-end framework for building responsive, mobile-first websites. It provides a comprehensive set of CSS and JavaScript components, such as grids, forms, and navigation bars, to streamline development. Its key strengths include ease of use, extensive documentation, and a large community for support. It is ideal for developers seeking to create consistent, cross-device compatible web projects efficiently.",
      "summary_zh": "Bootstrap æ˜¯ä¸€ä¸ªå¼€æºå‰ç«¯æ¡†æ¶ï¼Œç”¨äºå¿«é€Ÿæ„å»ºå“åº”å¼ã€ç§»åŠ¨ä¼˜å…ˆçš„ç½‘é¡µé¡¹ç›®ã€‚å®ƒæä¾›äº†ä¸€å¥—å®Œæ•´çš„ HTMLã€CSS å’Œ JavaScript ç»„ä»¶ï¼ŒåŒ…æ‹¬ç½‘æ ¼ç³»ç»Ÿã€è¡¨å•ã€æŒ‰é’®å’Œå¯¼èˆªç­‰ï¼Œå¸®åŠ©å¼€å‘è€…é«˜æ•ˆå®ç°ä¸€è‡´çš„ç”¨æˆ·ç•Œé¢ã€‚å…¶æ ¸å¿ƒäº®ç‚¹åœ¨äºå¼ºå¤§çš„å“åº”å¼è®¾è®¡èƒ½åŠ›ï¼Œæ”¯æŒè·¨è®¾å¤‡é€‚é…ï¼ŒåŒæ—¶å…·å¤‡é«˜åº¦å¯å®šåˆ¶æ€§å’Œä¸°å¯Œçš„é¢„å®šä¹‰æ ·å¼ã€‚é€‚ç”¨äºå„ç±» Web åº”ç”¨å¼€å‘ï¼Œå°¤å…¶é€‚åˆéœ€è¦å¿«é€ŸåŸå‹è®¾è®¡æˆ–ç»Ÿä¸€è§†è§‰è§„èŒƒçš„é¡¹ç›®ã€‚",
      "summary_es": "Bootstrap es un framework front-end para crear sitios web responsivos y mobile-first. Incluye componentes predefinidos, sistema de grid y utilidades CSS/JS. Su principal fortaleza es la rapidez de desarrollo y consistencia cross-browser. Ideal para prototipado y proyectos que priorizan compatibilidad."
    },
    {
      "id": "avelino/awesome-go",
      "source": "github",
      "name": "awesome-go",
      "url": "https://github.com/avelino/awesome-go",
      "license": "MIT",
      "lang": "Go",
      "tags": [
        "awesome",
        "awesome-list",
        "go",
        "golang",
        "golang-library",
        "hacktoberfest"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 152639,
        "forks": 12574,
        "issues": 157
      },
      "score": 155253.73078757714,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "è¿™æ˜¯ä¸€ä¸ªç²¾é€‰çš„ Go è¯­è¨€èµ„æºé›†åˆï¼Œæ”¶å½•äº†å¤§é‡é«˜è´¨é‡çš„æ¡†æ¶ã€åº“å’Œè½¯ä»¶é¡¹ç›®ã€‚å®ƒè¦†ç›–äº† Go ç”Ÿæ€ç³»ç»Ÿçš„å¤šä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬ç½‘ç»œå¼€å‘ã€æ•°æ®åº“ã€å·¥å…·é“¾å’Œå®ç”¨ç¨‹åºç­‰ã€‚è¯¥é¡¹ç›®ç”±ç¤¾åŒºå…±åŒç»´æŠ¤ï¼Œå†…å®¹æŒç»­æ›´æ–°ï¼Œé€‚åˆ Go å¼€å‘è€…å¿«é€ŸæŸ¥æ‰¾å’Œè¯„ä¼°å¯ç”¨èµ„æºã€‚æ— è®ºæ˜¯åˆå­¦è€…å¯»æ‰¾å…¥é—¨å·¥å…·ï¼Œè¿˜æ˜¯èµ„æ·±å¼€å‘è€…æ¢ç´¢é«˜çº§åº“ï¼Œéƒ½èƒ½ä»ä¸­è·å¾—å®ç”¨å‚è€ƒã€‚",
      "updated_at": "2025-09-18T18:51:53Z",
      "summary_en": "A curated collection of high-quality Go frameworks, libraries, and software, organized by category. Ideal for developers seeking reliable tools for building applications in Go, from web development to system utilities. Its strength lies in community-driven curation and regular updates, ensuring relevance and quality. Essential for Go programmers at any level to discover and evaluate resources efficiently.",
      "summary_zh": "è¿™æ˜¯ä¸€ä¸ªç²¾é€‰çš„ Go è¯­è¨€èµ„æºé›†åˆï¼Œæ”¶å½•äº†å¤§é‡é«˜è´¨é‡çš„æ¡†æ¶ã€åº“å’Œè½¯ä»¶é¡¹ç›®ã€‚å®ƒè¦†ç›–äº† Go ç”Ÿæ€ç³»ç»Ÿçš„å¤šä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬ç½‘ç»œå¼€å‘ã€æ•°æ®åº“ã€å·¥å…·é“¾å’Œå®ç”¨ç¨‹åºç­‰ã€‚è¯¥é¡¹ç›®ç”±ç¤¾åŒºå…±åŒç»´æŠ¤ï¼Œå†…å®¹æŒç»­æ›´æ–°ï¼Œé€‚åˆ Go å¼€å‘è€…å¿«é€ŸæŸ¥æ‰¾å’Œè¯„ä¼°å¯ç”¨èµ„æºã€‚æ— è®ºæ˜¯åˆå­¦è€…å¯»æ‰¾å…¥é—¨å·¥å…·ï¼Œè¿˜æ˜¯èµ„æ·±å¼€å‘è€…æ¢ç´¢é«˜çº§åº“ï¼Œéƒ½èƒ½ä»ä¸­è·å¾—å®ç”¨å‚è€ƒã€‚",
      "summary_es": "Lista curada de frameworks, bibliotecas y software destacados en Go. Facilita el descubrimiento de herramientas para desarrollo backend, sistemas distribuidos y microservicios. Ideal para desarrolladores que buscan recursos confiables y comunitariamente validados."
    },
    {
      "id": "trimstray/the-book-of-secret-knowledge",
      "source": "github",
      "name": "the-book-of-secret-knowledge",
      "url": "https://github.com/trimstray/the-book-of-secret-knowledge",
      "license": "MIT",
      "lang": "N/A",
      "tags": [
        "awesome",
        "awesome-list",
        "bsd",
        "cheatsheets",
        "devops",
        "guidelines",
        "hacking",
        "hacks",
        "howtos",
        "linux",
        "lists",
        "manuals",
        "one-liners",
        "pentesters",
        "resources",
        "search-engines",
        "security",
        "security-researchers",
        "sysops"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 186629,
        "forks": 11545,
        "issues": 99
      },
      "score": 189037.99795578702,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ã€Šthe-book-of-secret-knowledgeã€‹æ˜¯ä¸€ä¸ªç»¼åˆæ€§çš„æŠ€æœ¯çŸ¥è¯†é›†åˆåº“ï¼Œæ”¶å½•äº†å¤§é‡å®ç”¨èµ„æºï¼ŒåŒ…æ‹¬é€ŸæŸ¥è¡¨ã€æ“ä½œæŒ‡å—ã€å‘½ä»¤è¡Œå·¥å…·å’Œåšå®¢ç­‰ã€‚è¯¥é¡¹ç›®ç‰¹åˆ«é€‚åˆå¼€å‘è€…å’Œè¿ç»´äººå‘˜ä½¿ç”¨ï¼Œå†…å®¹æ¶µç›–Linuxç³»ç»Ÿç®¡ç†ã€DevOpså®è·µä»¥åŠå®‰å…¨æ”»é˜²æŠ€å·§ã€‚å…¶äº®ç‚¹åœ¨äºæ•´ç†äº†å¤§é‡é«˜è´¨é‡çš„ä¸€æ‰‹èµ„æ–™å’Œå®ç”¨æŠ€å·§ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿè§£å†³å®é™…é—®é¢˜ã€‚æ— è®ºæ˜¯æ—¥å¸¸å¼€å‘è¿˜æ˜¯ç³»ç»Ÿç»´æŠ¤ï¼Œéƒ½èƒ½ä»ä¸­æ‰¾åˆ°æœ‰ä»·å€¼çš„å‚è€ƒä¿¡æ¯ã€‚",
      "updated_at": "2025-09-18T19:20:54Z",
      "summary_en": "The Book of Secret Knowledge is a comprehensive, community-driven repository of practical IT and security resources. It includes cheatsheets, guides, tools, and one-liners for system administration, DevOps, and cybersecurity. Its strength lies in its extensive, curated content and ease of access for quick reference. This makes it highly applicable for professionals and enthusiasts seeking efficient solutions and best practices.",
      "summary_zh": "ã€Šthe-book-of-secret-knowledgeã€‹æ˜¯ä¸€ä¸ªç»¼åˆæ€§çš„æŠ€æœ¯çŸ¥è¯†é›†åˆåº“ï¼Œæ”¶å½•äº†å¤§é‡å®ç”¨èµ„æºï¼ŒåŒ…æ‹¬é€ŸæŸ¥è¡¨ã€æ“ä½œæŒ‡å—ã€å‘½ä»¤è¡Œå·¥å…·å’Œåšå®¢ç­‰ã€‚è¯¥é¡¹ç›®ç‰¹åˆ«é€‚åˆå¼€å‘è€…å’Œè¿ç»´äººå‘˜ä½¿ç”¨ï¼Œå†…å®¹æ¶µç›–Linuxç³»ç»Ÿç®¡ç†ã€DevOpså®è·µä»¥åŠå®‰å…¨æ”»é˜²æŠ€å·§ã€‚å…¶äº®ç‚¹åœ¨äºæ•´ç†äº†å¤§é‡é«˜è´¨é‡çš„ä¸€æ‰‹èµ„æ–™å’Œå®ç”¨æŠ€å·§ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿè§£å†³å®é™…é—®é¢˜ã€‚æ— è®ºæ˜¯æ—¥å¸¸å¼€å‘è¿˜æ˜¯ç³»ç»Ÿç»´æŠ¤ï¼Œéƒ½èƒ½ä»ä¸­æ‰¾åˆ°æœ‰ä»·å€¼çš„å‚è€ƒä¿¡æ¯ã€‚",
      "summary_es": "El proyecto es una colecciÃ³n extensa de recursos tÃ©cnicos, incluyendo listas, manuales, hojas de referencia y herramientas CLI/web. Destaca por su enfoque en DevOps, hacking y administraciÃ³n de sistemas Linux. Es ideal para profesionales que buscan referencias rÃ¡pidas, mejores prÃ¡cticas y soluciones prÃ¡cticas. Su estructura clara y contenido diverso lo convierten en una guÃ­a valiosa para desarrolladores y administradores de sistemas."
    },
    {
      "id": "ohmyzsh/ohmyzsh",
      "source": "github",
      "name": "ohmyzsh",
      "url": "https://github.com/ohmyzsh/ohmyzsh",
      "license": "MIT",
      "lang": "Shell",
      "tags": [
        "cli",
        "cli-app",
        "hacktoberfest",
        "oh-my-zsh",
        "oh-my-zsh-plugin",
        "oh-my-zsh-theme",
        "ohmyzsh",
        "plugin-framework",
        "plugins",
        "productivity",
        "shell",
        "terminal",
        "theme",
        "themes",
        "zsh",
        "zsh-configuration"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 181487,
        "forks": 26217,
        "issues": 504
      },
      "score": 186830.2595298611,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Ohmyzsh æ˜¯ä¸€ä¸ªåŸºäº Zsh çš„ç¤¾åŒºé©±åŠ¨å‹ Shell é…ç½®ç®¡ç†æ¡†æ¶ï¼Œæ‹¥æœ‰è¶…è¿‡ 2400 åè´¡çŒ®è€…ã€‚å®ƒæä¾›äº† 300 å¤šä¸ªå¯é€‰æ’ä»¶ï¼Œæ”¯æŒå¤šç§å¼€å‘ç¯å¢ƒå’Œå·¥å…·ï¼ˆå¦‚ Gitã€Dockerã€Python ç­‰ï¼‰ï¼Œä»¥åŠ 140 å¤šç§ä¸»é¢˜ï¼Œå¸®åŠ©ç”¨æˆ·è‡ªå®šä¹‰ç»ˆç«¯å¤–è§‚ã€‚å†…ç½®çš„è‡ªåŠ¨æ›´æ–°å·¥å…·å¯è½»æ¾è·å–ç¤¾åŒºæœ€æ–°åŠŸèƒ½ã€‚é€‚ç”¨äºå¸Œæœ›æå‡ç»ˆç«¯æ•ˆç‡å’Œç¾è§‚åº¦çš„å¼€å‘è€…å’Œç³»ç»Ÿç®¡ç†å‘˜ã€‚",
      "updated_at": "2025-09-18T18:21:06Z",
      "summary_en": "Oh My Zsh is a community-driven framework for managing Zsh configurations, offering extensive customization and productivity enhancements. It includes over 300 plugins for tools like Git, Docker, and Python, and 140+ themes to personalize the terminal experience. Its auto-update feature ensures users stay current with community contributions. Ideal for developers and power users seeking an efficient, extensible command-line environment.",
      "summary_zh": "Ohmyzsh æ˜¯ä¸€ä¸ªåŸºäº Zsh çš„ç¤¾åŒºé©±åŠ¨å‹ Shell é…ç½®ç®¡ç†æ¡†æ¶ï¼Œæ‹¥æœ‰è¶…è¿‡ 2400 åè´¡çŒ®è€…ã€‚å®ƒæä¾›äº† 300 å¤šä¸ªå¯é€‰æ’ä»¶ï¼Œæ”¯æŒå¤šç§å¼€å‘ç¯å¢ƒå’Œå·¥å…·ï¼ˆå¦‚ Gitã€Dockerã€Python ç­‰ï¼‰ï¼Œä»¥åŠ 140 å¤šç§ä¸»é¢˜ï¼Œå¸®åŠ©ç”¨æˆ·è‡ªå®šä¹‰ç»ˆç«¯å¤–è§‚ã€‚å†…ç½®çš„è‡ªåŠ¨æ›´æ–°å·¥å…·å¯è½»æ¾è·å–ç¤¾åŒºæœ€æ–°åŠŸèƒ½ã€‚é€‚ç”¨äºå¸Œæœ›æå‡ç»ˆç«¯æ•ˆç‡å’Œç¾è§‚åº¦çš„å¼€å‘è€…å’Œç³»ç»Ÿç®¡ç†å‘˜ã€‚",
      "summary_es": "Ohmyzsh es un framework comunitario para gestionar configuraciones de Zsh. Ofrece mÃ¡s de 300 plugins y 140 temas, mejorando productividad en terminal. Incluye herramientas para Git, Docker y actualizaciones automÃ¡ticas. Ideal para desarrolladores que buscan personalizar y optimizar su lÃ­nea de comandos."
    },
    {
      "id": "github/gitignore",
      "source": "github",
      "name": "gitignore",
      "url": "https://github.com/github/gitignore",
      "license": "CC0-1.0",
      "lang": "N/A",
      "tags": [
        "git",
        "gitignore"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 169442,
        "forks": 83000,
        "issues": 319
      },
      "score": 186141.72542492283,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "è¿™æ˜¯ä¸€ä¸ªç”± GitHub å®˜æ–¹ç»´æŠ¤çš„ .gitignore æ¨¡æ¿é›†åˆï¼Œé€‚ç”¨äºå„ç§ç¼–ç¨‹è¯­è¨€ã€æ¡†æ¶å’Œå¼€å‘ç¯å¢ƒã€‚å®ƒå¯ä»¥å¸®åŠ©å¼€å‘è€…åœ¨ Git ç‰ˆæœ¬æ§åˆ¶ä¸­è‡ªåŠ¨å¿½ç•¥ä¸å¿…è¦çš„æ–‡ä»¶ï¼Œå¦‚ç¼–è¯‘äº§ç‰©ã€æ—¥å¿—æ–‡ä»¶æˆ–ä¾èµ–ç›®å½•ï¼Œä»è€Œä¿æŒä»“åº“çš„æ•´æ´ã€‚è¯¥é¡¹ç›®é‡‡ç”¨ CC0-1.0 åè®®ï¼Œå®Œå…¨å¼€æ”¾ä½¿ç”¨ï¼Œå¹¶æ”¯æŒç¤¾åŒºè´¡çŒ®ã€‚æ— è®ºæ˜¯ä¸ªäººé¡¹ç›®è¿˜æ˜¯å›¢é˜Ÿåä½œï¼Œéƒ½å¯ä»¥é€šè¿‡ç›´æ¥å¼•ç”¨æˆ–è‡ªå®šä¹‰è¿™äº›æ¨¡æ¿æ¥æå‡å¼€å‘æ•ˆç‡ã€‚",
      "updated_at": "2025-09-18T17:23:10Z",
      "summary_en": "A comprehensive collection of .gitignore templates for various programming languages, frameworks, and tools. It helps developers exclude unnecessary files from version control, reducing repository clutter and improving performance. Widely used across open-source and private projects to maintain clean Git histories. Essential for any developer working with Git to streamline workflows and avoid committing sensitive or irrelevant files.",
      "summary_zh": "è¿™æ˜¯ä¸€ä¸ªç”± GitHub å®˜æ–¹ç»´æŠ¤çš„ .gitignore æ¨¡æ¿é›†åˆï¼Œé€‚ç”¨äºå„ç§ç¼–ç¨‹è¯­è¨€ã€æ¡†æ¶å’Œå¼€å‘ç¯å¢ƒã€‚å®ƒå¯ä»¥å¸®åŠ©å¼€å‘è€…åœ¨ Git ç‰ˆæœ¬æ§åˆ¶ä¸­è‡ªåŠ¨å¿½ç•¥ä¸å¿…è¦çš„æ–‡ä»¶ï¼Œå¦‚ç¼–è¯‘äº§ç‰©ã€æ—¥å¿—æ–‡ä»¶æˆ–ä¾èµ–ç›®å½•ï¼Œä»è€Œä¿æŒä»“åº“çš„æ•´æ´ã€‚è¯¥é¡¹ç›®é‡‡ç”¨ CC0-1.0 åè®®ï¼Œå®Œå…¨å¼€æ”¾ä½¿ç”¨ï¼Œå¹¶æ”¯æŒç¤¾åŒºè´¡çŒ®ã€‚æ— è®ºæ˜¯ä¸ªäººé¡¹ç›®è¿˜æ˜¯å›¢é˜Ÿåä½œï¼Œéƒ½å¯ä»¥é€šè¿‡ç›´æ¥å¼•ç”¨æˆ–è‡ªå®šä¹‰è¿™äº›æ¨¡æ¿æ¥æå‡å¼€å‘æ•ˆç‡ã€‚",
      "summary_es": "ColecciÃ³n de plantillas .gitignore para mÃºltiples lenguajes y entornos. Simplifica la exclusiÃ³n de archivos innecesarios en repositorios Git, mejorando la limpieza y eficiencia. Ideal para desarrolladores que buscan configuraciones predefinidas y evitar commits accidentales de archivos sensibles o temporales."
    },
    {
      "id": "flutter/flutter",
      "source": "github",
      "name": "flutter",
      "url": "https://github.com/flutter/flutter",
      "license": "BSD-3-Clause",
      "lang": "Dart",
      "tags": [
        "android",
        "app-framework",
        "cross-platform",
        "dart",
        "dart-platform",
        "desktop",
        "flutter",
        "flutter-package",
        "fuchsia",
        "ios",
        "linux-desktop",
        "macos",
        "material-design",
        "mobile",
        "mobile-development",
        "skia",
        "web",
        "web-framework",
        "windows"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 172656,
        "forks": 29224,
        "issues": 12248
      },
      "score": 178600.78684467592,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Flutter æ˜¯ç”± Google å¼€å‘çš„å¼€æº UI æ¡†æ¶ï¼Œä½¿ç”¨ Dart è¯­è¨€ç¼–å†™ï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…é«˜æ•ˆæ„å»ºé«˜è´¨é‡ã€è·¨å¹³å°çš„ç§»åŠ¨ã€Web å’Œæ¡Œé¢åº”ç”¨ã€‚å…¶æ ¸å¿ƒäº®ç‚¹åœ¨äºé«˜æ€§èƒ½çš„æ¸²æŸ“å¼•æ“å’Œä¸°å¯Œçš„ç»„ä»¶åº“ï¼Œæ”¯æŒä¸€å¥—ä»£ç å¤šç«¯éƒ¨ç½²ï¼Œæ˜¾è‘—æå‡å¼€å‘æ•ˆç‡ã€‚Flutter é€‚ç”¨äºéœ€è¦å¿«é€Ÿè¿­ä»£ã€è¿½æ±‚ä¸€è‡´ç”¨æˆ·ä½“éªŒçš„åº”ç”¨åœºæ™¯ï¼Œå°¤å…¶å—åˆ°ç§»åŠ¨åº”ç”¨å¼€å‘è€…çš„é’çã€‚é€šè¿‡çƒ­é‡è½½åŠŸèƒ½ï¼Œå¼€å‘è€…å¯ä»¥å®æ—¶æŸ¥çœ‹ç•Œé¢ä¿®æ”¹æ•ˆæœï¼Œæå¤§ç®€åŒ–äº†è°ƒè¯•å’Œç•Œé¢è®¾è®¡æµç¨‹ã€‚",
      "updated_at": "2025-09-18T19:16:06Z",
      "summary_en": "Flutter is an open-source UI framework for building natively compiled applications for mobile, web, and desktop from a single codebase. It uses the Dart programming language and provides a rich set of pre-designed widgets for creating visually appealing and performant apps. Its hot reload feature accelerates development, enabling real-time updates without restarting the app. Ideal for cross-platform projects, it is widely adopted for creating consistent user experiences across iOS, Android, and other platforms.",
      "summary_zh": "Flutter æ˜¯ç”± Google å¼€å‘çš„å¼€æº UI æ¡†æ¶ï¼Œä½¿ç”¨ Dart è¯­è¨€ç¼–å†™ï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…é«˜æ•ˆæ„å»ºé«˜è´¨é‡ã€è·¨å¹³å°çš„ç§»åŠ¨ã€Web å’Œæ¡Œé¢åº”ç”¨ã€‚å…¶æ ¸å¿ƒäº®ç‚¹åœ¨äºé«˜æ€§èƒ½çš„æ¸²æŸ“å¼•æ“å’Œä¸°å¯Œçš„ç»„ä»¶åº“ï¼Œæ”¯æŒä¸€å¥—ä»£ç å¤šç«¯éƒ¨ç½²ï¼Œæ˜¾è‘—æå‡å¼€å‘æ•ˆç‡ã€‚Flutter é€‚ç”¨äºéœ€è¦å¿«é€Ÿè¿­ä»£ã€è¿½æ±‚ä¸€è‡´ç”¨æˆ·ä½“éªŒçš„åº”ç”¨åœºæ™¯ï¼Œå°¤å…¶å—åˆ°ç§»åŠ¨åº”ç”¨å¼€å‘è€…çš„é’çã€‚é€šè¿‡çƒ­é‡è½½åŠŸèƒ½ï¼Œå¼€å‘è€…å¯ä»¥å®æ—¶æŸ¥çœ‹ç•Œé¢ä¿®æ”¹æ•ˆæœï¼Œæå¤§ç®€åŒ–äº†è°ƒè¯•å’Œç•Œé¢è®¾è®¡æµç¨‹ã€‚",
      "summary_es": "Flutter es un framework de cÃ³digo abierto para crear aplicaciones nativas compiladas, multi-plataforma desde una Ãºnica base de cÃ³digo. Utiliza el lenguaje Dart y ofrece alto rendimiento con renderizado propio. Es ideal para desarrollo mÃ³vil (iOS/Android), web y escritorio, destacando por su hot reload y widgets personalizables."
    },
    {
      "id": "AUTOMATIC1111/stable-diffusion-webui",
      "source": "github",
      "name": "stable-diffusion-webui",
      "url": "https://github.com/AUTOMATIC1111/stable-diffusion-webui",
      "license": "AGPL-3.0",
      "lang": "Python",
      "tags": [
        "ai",
        "ai-art",
        "deep-learning",
        "diffusion",
        "gradio",
        "image-generation",
        "image2image",
        "img2img",
        "pytorch",
        "stable-diffusion",
        "text2image",
        "torch",
        "txt2img",
        "unstable",
        "upscaling",
        "web"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 156514,
        "forks": 29043,
        "issues": 2425
      },
      "score": 162422.56327214508,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Stable Diffusion web UI æ˜¯ä¸€ä¸ªåŸºäº Gradio æ„å»ºçš„ Web ç•Œé¢ï¼Œç”¨äºè¿è¡Œå’Œè‡ªå®šä¹‰ Stable Diffusion å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚å®ƒæ”¯æŒæ–‡æœ¬ç”Ÿæˆå›¾åƒã€å›¾åƒåˆ°å›¾åƒè½¬æ¢ã€å›¾åƒä¿®å¤ç­‰å¤šç§åŠŸèƒ½ï¼Œå¹¶æä¾›äº†ä¸°å¯Œçš„æ’ä»¶å’Œè‡ªå®šä¹‰é€‰é¡¹ã€‚è¯¥é¡¹ç›®é€‚ç”¨äº AI è‰ºæœ¯åˆ›ä½œã€è®¾è®¡è¾…åŠ©å’Œå›¾åƒå¤„ç†å®éªŒç­‰åœºæ™¯ï¼Œç”¨æˆ·æ— éœ€ç¼–å†™ä»£ç å³å¯ä½¿ç”¨é«˜çº§åŠŸèƒ½ã€‚å…¶å¼€æºç‰¹æ€§å…è®¸å¼€å‘è€…æ‰©å±•å’Œä¼˜åŒ–ç•Œé¢ï¼Œé€‚åˆå¯¹ AI ç”Ÿæˆå›¾åƒæ„Ÿå…´è¶£çš„æŠ€æœ¯çˆ±å¥½è€…å’Œåˆ›ä½œè€…ã€‚",
      "updated_at": "2025-09-18T19:05:55Z",
      "summary_en": "Stable Diffusion web UI is a popular open-source interface for generating and manipulating images using AI. It supports text-to-image, image-to-image, and inpainting workflows, making it versatile for creative and practical applications. Built on Gradio and PyTorch, it is user-friendly and highly extensible, appealing to both beginners and developers. Its AGPL-3.0 license ensures open access while encouraging community contributions.",
      "summary_zh": "Stable Diffusion web UI æ˜¯ä¸€ä¸ªåŸºäº Gradio æ„å»ºçš„ Web ç•Œé¢ï¼Œç”¨äºè¿è¡Œå’Œè‡ªå®šä¹‰ Stable Diffusion å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚å®ƒæ”¯æŒæ–‡æœ¬ç”Ÿæˆå›¾åƒã€å›¾åƒåˆ°å›¾åƒè½¬æ¢ã€å›¾åƒä¿®å¤ç­‰å¤šç§åŠŸèƒ½ï¼Œå¹¶æä¾›äº†ä¸°å¯Œçš„æ’ä»¶å’Œè‡ªå®šä¹‰é€‰é¡¹ã€‚è¯¥é¡¹ç›®é€‚ç”¨äº AI è‰ºæœ¯åˆ›ä½œã€è®¾è®¡è¾…åŠ©å’Œå›¾åƒå¤„ç†å®éªŒç­‰åœºæ™¯ï¼Œç”¨æˆ·æ— éœ€ç¼–å†™ä»£ç å³å¯ä½¿ç”¨é«˜çº§åŠŸèƒ½ã€‚å…¶å¼€æºç‰¹æ€§å…è®¸å¼€å‘è€…æ‰©å±•å’Œä¼˜åŒ–ç•Œé¢ï¼Œé€‚åˆå¯¹ AI ç”Ÿæˆå›¾åƒæ„Ÿå…´è¶£çš„æŠ€æœ¯çˆ±å¥½è€…å’Œåˆ›ä½œè€…ã€‚",
      "summary_es": "Interfaz web para Stable Diffusion que permite generar y transformar imÃ¡genes mediante IA. Destaca por su interfaz accesible, mÃºltiples funciones avanzadas y amplia personalizaciÃ³n. Ideal para artistas digitales, investigadores y entusiastas que buscan explorar modelos de difusiÃ³n sin requerir conocimientos tÃ©cnicos profundos."
    },
    {
      "id": "Snailclimb/JavaGuide",
      "source": "github",
      "name": "JavaGuide",
      "url": "https://github.com/Snailclimb/JavaGuide",
      "license": "Apache-2.0",
      "lang": "Java",
      "tags": [
        "algorithms",
        "interview",
        "java",
        "jvm",
        "mysql",
        "redis",
        "spring",
        "system",
        "system-design",
        "zookeeper"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 151793,
        "forks": 45987,
        "issues": 73
      },
      "score": 161090.1819835648,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "JavaGuide æ˜¯ä¸€ä¸ªé¢å‘ Java å¼€å‘è€…çš„å¼€æºå­¦ä¹ ä¸é¢è¯•æŒ‡å—é¡¹ç›®ï¼Œå†…å®¹æ¶µç›– Java æ ¸å¿ƒçŸ¥è¯†ã€JVMã€MySQLã€Redisã€Spring ç­‰å…³é”®æŠ€æœ¯æ ˆã€‚è¯¥é¡¹ç›®ä»¥ç³»ç»ŸåŒ–çš„æ–¹å¼æ•´ç†äº†å¤§é‡é¢è¯•å¸¸è§é—®é¢˜å’ŒçŸ¥è¯†ç‚¹è§£æï¼Œé€‚åˆå‡†å¤‡ Java ç›¸å…³å²—ä½çš„æ±‚èŒè€…ä»¥åŠå¸Œæœ›å·©å›ºæŠ€æœ¯åŸºç¡€çš„å¼€å‘è€…ã€‚å…¶äº®ç‚¹åœ¨äºå†…å®¹å…¨é¢ã€ç»“æ„æ¸…æ™°ï¼Œå¹¶æŒç»­æ›´æ–°ç»´æŠ¤ï¼Œå¸®åŠ©ç”¨æˆ·é«˜æ•ˆæŒæ¡ Java ç”Ÿæ€çš„æ ¸å¿ƒæ¦‚å¿µã€‚æ— è®ºæ˜¯é¢è¯•å‡†å¤‡è¿˜æ˜¯æ—¥å¸¸å­¦ä¹ ï¼ŒJavaGuide éƒ½æ˜¯ä¸€ä¸ªå®ç”¨çš„å‚è€ƒèµ„æºã€‚",
      "updated_at": "2025-09-18T17:47:36Z",
      "summary_en": "JavaGuide is a comprehensive open-source guide for Java developers, covering core knowledge areas like JVM, algorithms, databases, and system design. It serves as a valuable resource for interview preparation and skill enhancement, with practical examples and clear explanations. Its broad applicability makes it suitable for both beginners and experienced programmers looking to deepen their understanding of Java and related technologies. The project is well-maintained and widely adopted in the developer community.",
      "summary_zh": "JavaGuide æ˜¯ä¸€ä¸ªé¢å‘ Java å¼€å‘è€…çš„å¼€æºå­¦ä¹ ä¸é¢è¯•æŒ‡å—é¡¹ç›®ï¼Œå†…å®¹æ¶µç›– Java æ ¸å¿ƒçŸ¥è¯†ã€JVMã€MySQLã€Redisã€Spring ç­‰å…³é”®æŠ€æœ¯æ ˆã€‚è¯¥é¡¹ç›®ä»¥ç³»ç»ŸåŒ–çš„æ–¹å¼æ•´ç†äº†å¤§é‡é¢è¯•å¸¸è§é—®é¢˜å’ŒçŸ¥è¯†ç‚¹è§£æï¼Œé€‚åˆå‡†å¤‡ Java ç›¸å…³å²—ä½çš„æ±‚èŒè€…ä»¥åŠå¸Œæœ›å·©å›ºæŠ€æœ¯åŸºç¡€çš„å¼€å‘è€…ã€‚å…¶äº®ç‚¹åœ¨äºå†…å®¹å…¨é¢ã€ç»“æ„æ¸…æ™°ï¼Œå¹¶æŒç»­æ›´æ–°ç»´æŠ¤ï¼Œå¸®åŠ©ç”¨æˆ·é«˜æ•ˆæŒæ¡ Java ç”Ÿæ€çš„æ ¸å¿ƒæ¦‚å¿µã€‚æ— è®ºæ˜¯é¢è¯•å‡†å¤‡è¿˜æ˜¯æ—¥å¸¸å­¦ä¹ ï¼ŒJavaGuide éƒ½æ˜¯ä¸€ä¸ªå®ç”¨çš„å‚è€ƒèµ„æºã€‚",
      "summary_es": "JavaGuide es una guÃ­a integral para desarrolladores Java, que cubre conocimientos esenciales como algoritmos, JVM, bases de datos y frameworks. Destaca por su enfoque prÃ¡ctico para preparaciÃ³n de entrevistas y aprendizaje autodidacta. Incluye ejemplos claros y temas de diseÃ±o de sistemas. Ideal para estudiantes y profesionales que buscan dominar el ecosistema Java."
    },
    {
      "id": "huggingface/transformers",
      "source": "github",
      "name": "transformers",
      "url": "https://github.com/huggingface/transformers",
      "license": "Apache-2.0",
      "lang": "Python",
      "tags": [
        "audio",
        "deep-learning",
        "deepseek",
        "gemma",
        "glm",
        "hacktoberfest",
        "llm",
        "machine-learning",
        "model-hub",
        "natural-language-processing",
        "nlp",
        "pretrained-models",
        "python",
        "pytorch",
        "pytorch-transformers",
        "qwen",
        "speech-recognition",
        "transformer",
        "vlm"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 149950,
        "forks": 30449,
        "issues": 1980
      },
      "score": 156139.58302523146,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ğŸ¤— Transformers æ˜¯ä¸€ä¸ªåŸºäº Apache-2.0 åè®®çš„å¼€æºæ¡†æ¶ï¼Œä¸“æ³¨äºæä¾›æœ€å…ˆè¿›çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæ¶µç›–æ–‡æœ¬ã€è§†è§‰ã€éŸ³é¢‘å’Œå¤šæ¨¡æ€ä»»åŠ¡ã€‚å®ƒæ”¯æŒæ¨ç†å’Œè®­ç»ƒï¼Œé›†æˆäº†ä¼—å¤šå‰æ²¿æ¨¡å‹å¦‚ DeepSeekã€Gemma å’Œ GLMï¼Œå¹¶æä¾›äº†ç»Ÿä¸€çš„æ¨¡å‹å®šä¹‰æ¥å£ã€‚è¯¥æ¡†æ¶é€‚ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ã€éŸ³é¢‘åˆ†æåŠå¤šæ¨¡æ€ç ”ç©¶ï¼Œå¹¿æ³›åº”ç”¨äºå­¦æœ¯å’Œå·¥ä¸šåœºæ™¯ã€‚å…¶æ¨¡å‹ä¸­å¿ƒï¼ˆModel Hubï¼‰å…è®¸ç”¨æˆ·è½»æ¾å…±äº«å’Œéƒ¨ç½²é¢„è®­ç»ƒæ¨¡å‹ï¼Œæå¤§æå‡äº†å¼€å‘æ•ˆç‡ã€‚",
      "updated_at": "2025-09-18T17:48:03Z",
      "summary_en": "ğŸ¤— Transformers is a widely-used open-source library for state-of-the-art machine learning models across text, vision, audio, and multimodal tasks. It supports both inference and training, offering pre-trained models and tools for fine-tuning. Its strengths include extensive model availability, ease of use, and community-driven improvements. Ideal for researchers and developers in NLP, computer vision, and audio processing.",
      "summary_zh": "ğŸ¤— Transformers æ˜¯ä¸€ä¸ªåŸºäº Apache-2.0 åè®®çš„å¼€æºæ¡†æ¶ï¼Œä¸“æ³¨äºæä¾›æœ€å…ˆè¿›çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæ¶µç›–æ–‡æœ¬ã€è§†è§‰ã€éŸ³é¢‘å’Œå¤šæ¨¡æ€ä»»åŠ¡ã€‚å®ƒæ”¯æŒæ¨ç†å’Œè®­ç»ƒï¼Œé›†æˆäº†ä¼—å¤šå‰æ²¿æ¨¡å‹å¦‚ DeepSeekã€Gemma å’Œ GLMï¼Œå¹¶æä¾›äº†ç»Ÿä¸€çš„æ¨¡å‹å®šä¹‰æ¥å£ã€‚è¯¥æ¡†æ¶é€‚ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ã€éŸ³é¢‘åˆ†æåŠå¤šæ¨¡æ€ç ”ç©¶ï¼Œå¹¿æ³›åº”ç”¨äºå­¦æœ¯å’Œå·¥ä¸šåœºæ™¯ã€‚å…¶æ¨¡å‹ä¸­å¿ƒï¼ˆModel Hubï¼‰å…è®¸ç”¨æˆ·è½»æ¾å…±äº«å’Œéƒ¨ç½²é¢„è®­ç»ƒæ¨¡å‹ï¼Œæå¤§æå‡äº†å¼€å‘æ•ˆç‡ã€‚",
      "summary_es": "Transformers es un framework de cÃ³digo abierto para modelos de aprendizaje profundo en texto, visiÃ³n, audio y multimodal. Ofrece una amplia gama de modelos preentrenados y herramientas para inferencia y entrenamiento. Sus puntos fuertes incluyen flexibilidad, escalabilidad y soporte para mÃºltiples modalidades. Es ampliamente utilizado en procesamiento de lenguaje natural, generaciÃ³n de contenido y anÃ¡lisis multimodal."
    },
    {
      "id": "omni-research/Tarsier2-Recap-7b",
      "source": "hf",
      "name": "Tarsier2-Recap-7b",
      "url": "https://huggingface.co/omni-research/Tarsier2-Recap-7b",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "safetensors",
        "video LLM",
        "arxiv:2501.07888",
        "license:apache-2.0",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 8475547,
        "hf_likes": 17
      },
      "score": 16959.594,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Tarsier2-Recap-7b æ˜¯ä¸€ä¸ªåŸºäº Transformer æ¶æ„çš„è§†é¢‘è¯­è¨€æ¨¡å‹ï¼Œä¸“æ³¨äºè§†é¢‘å†…å®¹ç†è§£ä¸æ‘˜è¦ç”Ÿæˆã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿè§£æè§†é¢‘å¸§åºåˆ—ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆç®€æ´å‡†ç¡®çš„æ–‡å­—æ€»ç»“ï¼Œé€‚ç”¨äºè§†é¢‘å†…å®¹æ£€ç´¢ã€æ™ºèƒ½å‰ªè¾‘è¾…åŠ©ç­‰åœºæ™¯ã€‚å…¶æ ¸å¿ƒäº®ç‚¹åœ¨äºç»“åˆæ—¶åºå»ºæ¨¡ä¸è¯­ä¹‰ç†è§£ï¼Œæ”¯æŒå¯¹é•¿è§†é¢‘çš„é«˜æ•ˆå¤„ç†ï¼ŒåŒæ—¶ä¿æŒè¾ƒä½çš„æ¨ç†å»¶è¿Ÿã€‚è¯¥æ¨¡å‹é€‚ç”¨äºåª’ä½“åˆ¶ä½œã€åœ¨çº¿æ•™è‚²ã€å®‰é˜²ç›‘æ§ç­‰é¢†åŸŸï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿæå–è§†é¢‘å…³é”®ä¿¡æ¯ã€‚",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Tarsier2-Recap-7b is a 7-billion-parameter video language model designed for summarizing and analyzing video content. It excels at generating concise recaps and extracting key information from videos, making it suitable for applications in media analysis, content indexing, and accessibility. Its strengths include efficient processing and robust performance on diverse video datasets. The model is licensed under Apache 2.0, ensuring broad usability for both research and commercial purposes.",
      "summary_zh": "Tarsier2-Recap-7b æ˜¯ä¸€ä¸ªåŸºäº Transformer æ¶æ„çš„è§†é¢‘è¯­è¨€æ¨¡å‹ï¼Œä¸“æ³¨äºè§†é¢‘å†…å®¹ç†è§£ä¸æ‘˜è¦ç”Ÿæˆã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿè§£æè§†é¢‘å¸§åºåˆ—ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆç®€æ´å‡†ç¡®çš„æ–‡å­—æ€»ç»“ï¼Œé€‚ç”¨äºè§†é¢‘å†…å®¹æ£€ç´¢ã€æ™ºèƒ½å‰ªè¾‘è¾…åŠ©ç­‰åœºæ™¯ã€‚å…¶æ ¸å¿ƒäº®ç‚¹åœ¨äºç»“åˆæ—¶åºå»ºæ¨¡ä¸è¯­ä¹‰ç†è§£ï¼Œæ”¯æŒå¯¹é•¿è§†é¢‘çš„é«˜æ•ˆå¤„ç†ï¼ŒåŒæ—¶ä¿æŒè¾ƒä½çš„æ¨ç†å»¶è¿Ÿã€‚è¯¥æ¨¡å‹é€‚ç”¨äºåª’ä½“åˆ¶ä½œã€åœ¨çº¿æ•™è‚²ã€å®‰é˜²ç›‘æ§ç­‰é¢†åŸŸï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿæå–è§†é¢‘å…³é”®ä¿¡æ¯ã€‚",
      "summary_es": "Tarsier2-Recap-7b es un modelo de lenguaje de gran tamaÃ±o especializado en el procesamiento y resumen de contenido de video. Basado en la arquitectura Transformer, destaca por su capacidad para generar descripciones precisas y contextualizadas de secuencias visuales. Sus principales aplicaciones incluyen la automatizaciÃ³n de subtÃ­tulos, anÃ¡lisis de metraje y extracciÃ³n de informaciÃ³n clave en entornos multimedia. Optimizado para eficiencia computacional, es adecuado para implementaciones que requieren equilibrio entre rendimiento y recursos."
    },
    {
      "id": "meta-llama/Llama-3.1-8B-Instruct",
      "source": "hf",
      "name": "Llama-3.1-8B-Instruct",
      "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "facebook",
        "meta",
        "pytorch",
        "llama-3",
        "conversational",
        "en",
        "de",
        "fr",
        "it",
        "pt",
        "hi",
        "es",
        "th",
        "arxiv:2204.05149",
        "base_model:meta-llama/Llama-3.1-8B",
        "base_model:finetune:meta-llama/Llama-3.1-8B",
        "license:llama3.1",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 6885240,
        "hf_likes": 4631
      },
      "score": 16085.98,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Llama-3.1-8B-Instruct æ˜¯ Meta æ¨å‡ºçš„å¼€æºæŒ‡ä»¤å¾®è°ƒè¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Llama 3 æ¶æ„ä¼˜åŒ–ï¼Œä¸“é—¨ç”¨äºå¯¹è¯å’ŒæŒ‡ä»¤è·Ÿéšä»»åŠ¡ã€‚è¯¥æ¨¡å‹å…·æœ‰ 80 äº¿å‚æ•°ï¼Œåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ“…é•¿ç”Ÿæˆè‡ªç„¶ã€è¿è´¯çš„æ–‡æœ¬å“åº”ã€‚å®ƒé€‚ç”¨äºèŠå¤©æœºå™¨äººã€å†…å®¹åˆ›ä½œã€ä»£ç ç”Ÿæˆç­‰å¤šç§åœºæ™¯ï¼Œå¹¶æ”¯æŒ Transformers å’Œ PyTorch æ¡†æ¶é›†æˆã€‚æ¨¡å‹ä»¥è‹±æ–‡ä¸ºä¸»ï¼Œé€‚åˆå¼€å‘è€…æ„å»ºé«˜è´¨é‡çš„ AI å¯¹è¯åº”ç”¨ã€‚",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Llama-3.1-8B-Instruct is an 8-billion-parameter language model optimized for instruction-following tasks. It excels in conversational AI, text generation, and structured reasoning, making it suitable for chatbots, content creation, and educational tools. Built on the robust Llama-3 architecture, it balances performance and efficiency for deployment in resource-constrained environments. Its open availability encourages broad use in research and practical applications.",
      "summary_zh": "Llama-3.1-8B-Instruct æ˜¯ Meta æ¨å‡ºçš„å¼€æºæŒ‡ä»¤å¾®è°ƒè¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Llama 3 æ¶æ„ä¼˜åŒ–ï¼Œä¸“é—¨ç”¨äºå¯¹è¯å’ŒæŒ‡ä»¤è·Ÿéšä»»åŠ¡ã€‚è¯¥æ¨¡å‹å…·æœ‰ 80 äº¿å‚æ•°ï¼Œåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ“…é•¿ç”Ÿæˆè‡ªç„¶ã€è¿è´¯çš„æ–‡æœ¬å“åº”ã€‚å®ƒé€‚ç”¨äºèŠå¤©æœºå™¨äººã€å†…å®¹åˆ›ä½œã€ä»£ç ç”Ÿæˆç­‰å¤šç§åœºæ™¯ï¼Œå¹¶æ”¯æŒ Transformers å’Œ PyTorch æ¡†æ¶é›†æˆã€‚æ¨¡å‹ä»¥è‹±æ–‡ä¸ºä¸»ï¼Œé€‚åˆå¼€å‘è€…æ„å»ºé«˜è´¨é‡çš„ AI å¯¹è¯åº”ç”¨ã€‚",
      "summary_es": "Llama-3.1-8B-Instruct es un modelo de lenguaje de 8 mil millones de parÃ¡metros optimizado para instrucciones y conversaciones. Basado en Transformers, destaca por su eficiencia en generaciÃ³n de texto y su capacidad para diÃ¡logos naturales. Es ideal para aplicaciones de chatbots, asistentes virtuales y automatizaciÃ³n de respuestas en inglÃ©s. Su arquitectura permite un buen equilibrio entre rendimiento y consumo computacional."
    },
    {
      "id": "distilbert/distilbert-base-uncased",
      "source": "hf",
      "name": "distilbert-base-uncased",
      "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "rust",
        "safetensors",
        "distilbert",
        "fill-mask",
        "exbert",
        "en",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "arxiv:1910.01108",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 12201728,
        "hf_likes": 755
      },
      "score": 24780.956000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "DistilBERT-base-uncased æ˜¯ä¸€ä¸ªè½»é‡åŒ–çš„ BERT å˜ä½“ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯å¤§å¹…å‹ç¼©æ¨¡å‹è§„æ¨¡ï¼ŒåŒæ—¶ä¿æŒæ¥è¿‘åŸç‰ˆçš„æ€§èƒ½ã€‚å®ƒä¸“ä¸ºè‹±æ–‡æ–‡æœ¬çš„æ©ç è¯­è¨€å»ºæ¨¡ä»»åŠ¡è®¾è®¡ï¼Œé€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€å®ä½“è¯†åˆ«ç­‰å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†åœºæ™¯ã€‚è¯¥æ¨¡å‹æ”¯æŒå¤šç§ä¸»æµæ¡†æ¶ï¼ŒåŒ…æ‹¬ PyTorchã€TensorFlow å’Œ JAXï¼Œä¾¿äºé›†æˆåˆ°ä¸åŒæŠ€æœ¯æ ˆä¸­ã€‚å…¶é«˜æ•ˆæ¨ç†å’Œè¾ƒä½èµ„æºéœ€æ±‚ä½¿å…¶æˆä¸ºéƒ¨ç½²åœ¨è®¡ç®—å—é™ç¯å¢ƒä¸­çš„ç†æƒ³é€‰æ‹©ã€‚",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "DistilBERT is a distilled version of BERT, designed for efficient natural language understanding. It retains 97% of BERT's performance while being 40% smaller and 60% faster. Ideal for tasks like text classification, sentiment analysis, and masked language modeling, it is well-suited for resource-constrained environments. Supports multiple frameworks including PyTorch, TensorFlow, and JAX.",
      "summary_zh": "DistilBERT-base-uncased æ˜¯ä¸€ä¸ªè½»é‡åŒ–çš„ BERT å˜ä½“ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯å¤§å¹…å‹ç¼©æ¨¡å‹è§„æ¨¡ï¼ŒåŒæ—¶ä¿æŒæ¥è¿‘åŸç‰ˆçš„æ€§èƒ½ã€‚å®ƒä¸“ä¸ºè‹±æ–‡æ–‡æœ¬çš„æ©ç è¯­è¨€å»ºæ¨¡ä»»åŠ¡è®¾è®¡ï¼Œé€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€å®ä½“è¯†åˆ«ç­‰å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†åœºæ™¯ã€‚è¯¥æ¨¡å‹æ”¯æŒå¤šç§ä¸»æµæ¡†æ¶ï¼ŒåŒ…æ‹¬ PyTorchã€TensorFlow å’Œ JAXï¼Œä¾¿äºé›†æˆåˆ°ä¸åŒæŠ€æœ¯æ ˆä¸­ã€‚å…¶é«˜æ•ˆæ¨ç†å’Œè¾ƒä½èµ„æºéœ€æ±‚ä½¿å…¶æˆä¸ºéƒ¨ç½²åœ¨è®¡ç®—å—é™ç¯å¢ƒä¸­çš„ç†æƒ³é€‰æ‹©ã€‚",
      "summary_es": "DistilBERT es un modelo de lenguaje basado en BERT, optimizado para reducir su tamaÃ±o y tiempo de inferencia manteniendo alta precisiÃ³n. Es ideal para tareas de procesamiento de lenguaje natural como clasificaciÃ³n de texto, anÃ¡lisis de sentimientos y relleno de mÃ¡scaras. Su eficiencia lo hace adecuado para entornos con recursos limitados o aplicaciones que requieren baja latencia."
    },
    {
      "id": "FacebookAI/roberta-large",
      "source": "hf",
      "name": "roberta-large",
      "url": "https://huggingface.co/FacebookAI/roberta-large",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "onnx",
        "safetensors",
        "roberta",
        "fill-mask",
        "exbert",
        "en",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "arxiv:1907.11692",
        "arxiv:1806.02847",
        "license:mit",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 12171005,
        "hf_likes": 245
      },
      "score": 24464.510000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "RoBERTa-largeæ˜¯åŸºäºBERTæ¶æ„ä¼˜åŒ–çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œç”±Facebook AIå¼€å‘ã€‚å®ƒåœ¨BERTåŸºç¡€ä¸Šé€šè¿‡ç§»é™¤ä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡ã€é‡‡ç”¨æ›´å¤§æ‰¹æ¬¡è®­ç»ƒå’Œæ›´é•¿çš„åºåˆ—è¿›è¡Œæ”¹è¿›ï¼Œæå‡äº†è¯­è¨€ç†è§£èƒ½åŠ›ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€å®ä½“è¯†åˆ«ã€è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—ç­‰å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œå°¤å…¶æ“…é•¿å¤„ç†è‹±æ–‡æ–‡æœ¬çš„æ©ç è¯­è¨€å»ºæ¨¡ã€‚æ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…æ‹¬PyTorchã€TensorFlowå’ŒJAXã€‚",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "RoBERTa-large is a robust transformer-based language model optimized for masked language modeling. It excels in tasks like text classification, named entity recognition, and question answering, offering strong performance across various benchmarks. With support for multiple frameworks (PyTorch, TensorFlow, JAX, ONNX), it is highly adaptable for research and production use. Its pre-trained nature makes it ideal for fine-tuning on domain-specific datasets with minimal data.",
      "summary_zh": "RoBERTa-largeæ˜¯åŸºäºBERTæ¶æ„ä¼˜åŒ–çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œç”±Facebook AIå¼€å‘ã€‚å®ƒåœ¨BERTåŸºç¡€ä¸Šé€šè¿‡ç§»é™¤ä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡ã€é‡‡ç”¨æ›´å¤§æ‰¹æ¬¡è®­ç»ƒå’Œæ›´é•¿çš„åºåˆ—è¿›è¡Œæ”¹è¿›ï¼Œæå‡äº†è¯­è¨€ç†è§£èƒ½åŠ›ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€å®ä½“è¯†åˆ«ã€è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—ç­‰å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œå°¤å…¶æ“…é•¿å¤„ç†è‹±æ–‡æ–‡æœ¬çš„æ©ç è¯­è¨€å»ºæ¨¡ã€‚æ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…æ‹¬PyTorchã€TensorFlowå’ŒJAXã€‚",
      "summary_es": "RoBERTa-large es un modelo de lenguaje basado en Transformers optimizado para tareas de comprensiÃ³n de texto. Destaca por su entrenamiento robusto sin tareas de predicciÃ³n de oraciones, mejorando el rendimiento en clasificaciÃ³n, inferencia y relleno de mÃ¡scaras. Es ampliamente utilizado en procesamiento de lenguaje natural (PLN) para anÃ¡lisis de sentimientos, respuesta a preguntas y resumen. Su arquitectura grande permite un alto rendimiento en aplicaciones que requieren precisiÃ³n y contexto lingÃ¼Ã­stico profundo."
    },
    {
      "id": "amazon/chronos-t5-small",
      "source": "hf",
      "name": "chronos-t5-small",
      "url": "https://huggingface.co/amazon/chronos-t5-small",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "t5",
        "text2text-generation",
        "time series",
        "forecasting",
        "pretrained models",
        "foundation models",
        "time series foundation models",
        "time-series",
        "time-series-forecasting",
        "arxiv:2403.07815",
        "arxiv:1910.10683",
        "license:apache-2.0",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 11891514,
        "hf_likes": 131
      },
      "score": 23848.528000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Chronos-T5-smallæ˜¯äºšé©¬é€ŠåŸºäºT5æ¶æ„å¼€å‘çš„æ—¶é—´åºåˆ—é¢„æµ‹åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡å°†æ—¶é—´åºåˆ—æ•°æ®è½¬æ¢ä¸ºæ–‡æœ¬æ ‡è®°åºåˆ—ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°æ–‡æœ¬è½¬æ¢èƒ½åŠ›è¿›è¡Œå¤šæ­¥é¢„æµ‹ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºæ— éœ€é¢†åŸŸç‰¹å®šç‰¹å¾å·¥ç¨‹ï¼Œå¯ç›´æ¥å¤„ç†ä¸åŒé¢‘ç‡å’Œè§„æ¨¡çš„æ—¶é—´åºåˆ—æ•°æ®ã€‚æ¨¡å‹é€‚ç”¨äºé›¶å”®é”€é‡é¢„æµ‹ã€èƒ½æºè´Ÿè·é¢„æµ‹ã€ç»æµæŒ‡æ ‡åˆ†æç­‰é€šç”¨åœºæ™¯ï¼Œä¸ºæ—¶é—´åºåˆ—åˆ†ææä¾›äº†é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬çš„é¢„æµ‹è§£å†³æ–¹æ¡ˆã€‚",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Chronos-T5-small is a compact pretrained foundation model for time series forecasting, based on the T5 architecture. It excels at converting time series data into text-like sequences for accurate predictions across various domains like finance, energy, and IoT. Its strengths include strong zero-shot performance, scalability, and ease of fine-tuning with minimal data. It is widely applicable for both univariate and multivariate forecasting tasks, offering a flexible and efficient solution for real-world time series analysis.",
      "summary_zh": "Chronos-T5-smallæ˜¯äºšé©¬é€ŠåŸºäºT5æ¶æ„å¼€å‘çš„æ—¶é—´åºåˆ—é¢„æµ‹åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡å°†æ—¶é—´åºåˆ—æ•°æ®è½¬æ¢ä¸ºæ–‡æœ¬æ ‡è®°åºåˆ—ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°æ–‡æœ¬è½¬æ¢èƒ½åŠ›è¿›è¡Œå¤šæ­¥é¢„æµ‹ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºæ— éœ€é¢†åŸŸç‰¹å®šç‰¹å¾å·¥ç¨‹ï¼Œå¯ç›´æ¥å¤„ç†ä¸åŒé¢‘ç‡å’Œè§„æ¨¡çš„æ—¶é—´åºåˆ—æ•°æ®ã€‚æ¨¡å‹é€‚ç”¨äºé›¶å”®é”€é‡é¢„æµ‹ã€èƒ½æºè´Ÿè·é¢„æµ‹ã€ç»æµæŒ‡æ ‡åˆ†æç­‰é€šç”¨åœºæ™¯ï¼Œä¸ºæ—¶é—´åºåˆ—åˆ†ææä¾›äº†é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬çš„é¢„æµ‹è§£å†³æ–¹æ¡ˆã€‚",
      "summary_es": "Chronos-T5-small es un modelo de series temporales basado en T5, preentrenado para predicciÃ³n. Transforma datos numÃ©ricos en secuencias de tokens para generar pronÃ³sticos precisos. Es ideal para aplicaciones como demanda energÃ©tica, finanzas o IoT. Su arquitectura eficiente permite integraciÃ³n sencilla en pipelines existentes."
    },
    {
      "id": "google/electra-base-discriminator",
      "source": "hf",
      "name": "electra-base-discriminator",
      "url": "https://huggingface.co/google/electra-base-discriminator",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "rust",
        "electra",
        "pretraining",
        "en",
        "arxiv:1406.2661",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 11457730,
        "hf_likes": 64
      },
      "score": 22947.46,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ELECTRA-base-discriminatoræ˜¯ç”±Googleå¼€å‘çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨åˆ¤åˆ«å¼é¢„è®­ç»ƒæ–¹æ³•æ›¿ä»£ä¼ ç»Ÿçš„ç”Ÿæˆå¼é¢„è®­ç»ƒã€‚è¯¥æ¨¡å‹é€šè¿‡åŒºåˆ†è¾“å…¥æ–‡æœ¬ä¸­çš„åŸå§‹tokenä¸æ›¿æ¢tokenè¿›è¡Œè®­ç»ƒï¼Œæ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡å’Œä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ã€‚é€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æç­‰å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚å…¶æ¶æ„è½»é‡é«˜æ•ˆï¼Œåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶é€‚åˆéœ€è¦é«˜ç²¾åº¦å’Œå¿«é€Ÿæ¨ç†çš„åœºæ™¯ã€‚æ”¯æŒå¤šç§ä¸»æµæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…æ‹¬PyTorchã€TensorFlowå’ŒJAXã€‚",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "ELECTRA-base-discriminator is a pre-trained transformer model designed for discriminative tasks, such as identifying whether input tokens are original or replaced. It excels in natural language understanding, offering efficient fine-tuning for downstream applications like text classification, named entity recognition, and question answering. Built on the ELECTRA architecture, it provides strong performance with reduced computational costs compared to generative pre-training. Suitable for researchers and developers working with English text in PyTorch, TensorFlow, or JAX environments.",
      "summary_zh": "ELECTRA-base-discriminatoræ˜¯ç”±Googleå¼€å‘çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨åˆ¤åˆ«å¼é¢„è®­ç»ƒæ–¹æ³•æ›¿ä»£ä¼ ç»Ÿçš„ç”Ÿæˆå¼é¢„è®­ç»ƒã€‚è¯¥æ¨¡å‹é€šè¿‡åŒºåˆ†è¾“å…¥æ–‡æœ¬ä¸­çš„åŸå§‹tokenä¸æ›¿æ¢tokenè¿›è¡Œè®­ç»ƒï¼Œæ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡å’Œä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ã€‚é€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æç­‰å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚å…¶æ¶æ„è½»é‡é«˜æ•ˆï¼Œåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶é€‚åˆéœ€è¦é«˜ç²¾åº¦å’Œå¿«é€Ÿæ¨ç†çš„åœºæ™¯ã€‚æ”¯æŒå¤šç§ä¸»æµæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…æ‹¬PyTorchã€TensorFlowå’ŒJAXã€‚",
      "summary_es": "ELECTRA-base-discriminator es un modelo de lenguaje preentrenado que utiliza un mÃ©todo de discriminaciÃ³n para el aprendizaje. Destaca por su eficiencia en tareas de comprensiÃ³n del lenguaje y detecciÃ³n de tokens reemplazados. Es ideal para clasificaciÃ³n de texto, anÃ¡lisis sintÃ¡ctico y fine-tuning en dominios especÃ­ficos. Soporta mÃºltiples frameworks como PyTorch, TensorFlow y JAX."
    },
    {
      "id": "prajjwal1/bert-tiny",
      "source": "hf",
      "name": "bert-tiny",
      "url": "https://huggingface.co/prajjwal1/bert-tiny",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "BERT",
        "MNLI",
        "NLI",
        "transformer",
        "pre-training",
        "en",
        "arxiv:1908.08962",
        "arxiv:2110.01518",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 10154678,
        "hf_likes": 127
      },
      "score": 20372.856,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "bert-tinyæ˜¯ä¸€ä¸ªè½»é‡çº§BERTæ¨¡å‹ï¼Œä¸“ä¸ºèµ„æºå—é™ç¯å¢ƒè®¾è®¡ã€‚å®ƒåŸºäºBERTæ¶æ„ï¼Œä½†æ˜¾è‘—å‡å°‘äº†å‚æ•°é‡ï¼Œåœ¨ä¿æŒåˆç†æ€§èƒ½çš„åŒæ—¶å¤§å¹…æå‡æ¨ç†é€Ÿåº¦ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€è‡ªç„¶è¯­è¨€æ¨ç†ï¼ˆNLIï¼‰ç­‰ä¸‹æ¸¸ä»»åŠ¡ï¼Œå°¤å…¶é€‚åˆç§»åŠ¨è®¾å¤‡æˆ–è¾¹ç¼˜è®¡ç®—åœºæ™¯ã€‚æ”¯æŒPyTorchæ¡†æ¶ï¼Œé¢„è®­ç»ƒæƒé‡å¯ç›´æ¥ç”¨äºå¾®è°ƒï¼Œæ˜¯é«˜æ•ˆNLPåº”ç”¨çš„å®ç”¨é€‰æ‹©ã€‚",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "BERT-Tiny is a compact, efficient variant of the BERT model, designed for resource-constrained environments. It is pre-trained on English text and fine-tuned for natural language inference tasks like MNLI. Its small size makes it suitable for on-device applications, edge computing, and rapid prototyping. While less accurate than larger models, it offers a strong balance of performance and efficiency for lightweight NLP needs.",
      "summary_zh": "bert-tinyæ˜¯ä¸€ä¸ªè½»é‡çº§BERTæ¨¡å‹ï¼Œä¸“ä¸ºèµ„æºå—é™ç¯å¢ƒè®¾è®¡ã€‚å®ƒåŸºäºBERTæ¶æ„ï¼Œä½†æ˜¾è‘—å‡å°‘äº†å‚æ•°é‡ï¼Œåœ¨ä¿æŒåˆç†æ€§èƒ½çš„åŒæ—¶å¤§å¹…æå‡æ¨ç†é€Ÿåº¦ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€è‡ªç„¶è¯­è¨€æ¨ç†ï¼ˆNLIï¼‰ç­‰ä¸‹æ¸¸ä»»åŠ¡ï¼Œå°¤å…¶é€‚åˆç§»åŠ¨è®¾å¤‡æˆ–è¾¹ç¼˜è®¡ç®—åœºæ™¯ã€‚æ”¯æŒPyTorchæ¡†æ¶ï¼Œé¢„è®­ç»ƒæƒé‡å¯ç›´æ¥ç”¨äºå¾®è°ƒï¼Œæ˜¯é«˜æ•ˆNLPåº”ç”¨çš„å®ç”¨é€‰æ‹©ã€‚",
      "summary_es": "BERT-tiny es un modelo de lenguaje ligero basado en la arquitectura BERT, optimizado para tareas de inferencia en lenguaje natural (NLI) como MNLI. Su principal fortaleza es la eficiencia computacional, manteniendo un rendimiento sÃ³lido en clasificaciÃ³n de texto y comprensiÃ³n contextual. Ideal para entornos con recursos limitados o aplicaciones que requieren baja latencia."
    },
    {
      "id": "trpakov/vit-face-expression",
      "source": "hf",
      "name": "vit-face-expression",
      "url": "https://huggingface.co/trpakov/vit-face-expression",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "vit",
        "image-classification",
        "doi:10.57967/hf/2289",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 8073901,
        "hf_likes": 78
      },
      "score": 16186.802,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "vit-face-expressionæ˜¯åŸºäºVision Transformerï¼ˆViTï¼‰æ¶æ„çš„é¢éƒ¨è¡¨æƒ…åˆ†ç±»æ¨¡å‹ï¼Œç”±trpakovå¼€å‘å¹¶æ‰˜ç®¡äºHugging Faceå¹³å°ã€‚è¯¥æ¨¡å‹ä½¿ç”¨Apache 2.0å¼€æºåè®®ï¼Œæ”¯æŒONNXå’ŒPyTorchæ ¼å¼ï¼Œé€‚ç”¨äºå›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œèƒ½å¤Ÿè¯†åˆ«å¤šç§äººç±»é¢éƒ¨è¡¨æƒ…ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºç»“åˆäº†Transformerçš„å…¨å±€å»ºæ¨¡èƒ½åŠ›ä¸é«˜æ•ˆçš„ç‰¹å¾æå–ï¼Œé€‚ç”¨äºæƒ…æ„Ÿåˆ†æã€äººæœºäº¤äº’å’Œå¿ƒç†å­¦ç ”ç©¶ç­‰åœºæ™¯ã€‚æ¨¡å‹å…¼å®¹AutoTrainå’Œç«¯éƒ¨ç½²ï¼Œé€‚åˆéœ€è¦é«˜ç²¾åº¦è¡¨æƒ…è¯†åˆ«çš„æŠ€æœ¯å›¢é˜Ÿé›†æˆä½¿ç”¨ã€‚",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "A Vision Transformer (ViT) model fine-tuned for facial expression recognition. It classifies images into common emotion categories, useful for applications in human-computer interaction, psychology research, and sentiment analysis. Built on PyTorch and ONNX, it supports efficient inference and deployment. Compatible with Hugging Face Transformers and AutoTrain, it is suitable for both research and production use.",
      "summary_zh": "vit-face-expressionæ˜¯åŸºäºVision Transformerï¼ˆViTï¼‰æ¶æ„çš„é¢éƒ¨è¡¨æƒ…åˆ†ç±»æ¨¡å‹ï¼Œç”±trpakovå¼€å‘å¹¶æ‰˜ç®¡äºHugging Faceå¹³å°ã€‚è¯¥æ¨¡å‹ä½¿ç”¨Apache 2.0å¼€æºåè®®ï¼Œæ”¯æŒONNXå’ŒPyTorchæ ¼å¼ï¼Œé€‚ç”¨äºå›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œèƒ½å¤Ÿè¯†åˆ«å¤šç§äººç±»é¢éƒ¨è¡¨æƒ…ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºç»“åˆäº†Transformerçš„å…¨å±€å»ºæ¨¡èƒ½åŠ›ä¸é«˜æ•ˆçš„ç‰¹å¾æå–ï¼Œé€‚ç”¨äºæƒ…æ„Ÿåˆ†æã€äººæœºäº¤äº’å’Œå¿ƒç†å­¦ç ”ç©¶ç­‰åœºæ™¯ã€‚æ¨¡å‹å…¼å®¹AutoTrainå’Œç«¯éƒ¨ç½²ï¼Œé€‚åˆéœ€è¦é«˜ç²¾åº¦è¡¨æƒ…è¯†åˆ«çš„æŠ€æœ¯å›¢é˜Ÿé›†æˆä½¿ç”¨ã€‚",
      "summary_es": "Modelo de clasificaciÃ³n de expresiones faciales basado en Vision Transformer (ViT). Detecta emociones como alegrÃ­a, tristeza o enfado en imÃ¡genes. Destaca por su precisiÃ³n y velocidad usando arquitecturas transformer. Ãštil para anÃ¡lisis de comportamiento humano e interacciÃ³n persona-computadora."
    },
    {
      "id": "BAAI/bge-base-en-v1.5",
      "source": "hf",
      "name": "bge-base-en-v1.5",
      "url": "https://huggingface.co/BAAI/bge-base-en-v1.5",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "sentence-transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "bert",
        "feature-extraction",
        "sentence-similarity",
        "transformers",
        "mteb",
        "en",
        "arxiv:2401.03462",
        "arxiv:2312.15503",
        "arxiv:2311.13534",
        "arxiv:2310.07554",
        "arxiv:2309.07597",
        "license:mit",
        "model-index",
        "autotrain_compatible",
        "text-embeddings-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 7434960,
        "hf_likes": 347
      },
      "score": 15043.42,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "bge-base-en-v1.5 æ˜¯ä¸€ä¸ªåŸºäº BERT æ¶æ„çš„è‹±æ–‡æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œç”±åŒ—äº¬æ™ºæºäººå·¥æ™ºèƒ½ç ”ç©¶é™¢ï¼ˆBAAIï¼‰å¼€å‘ã€‚è¯¥æ¨¡å‹ä¸»è¦ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„å¥å­æˆ–æ®µè½çº§å‘é‡è¡¨ç¤ºï¼Œé€‚ç”¨äºè¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—ã€ä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬èšç±»ç­‰ä»»åŠ¡ã€‚å…¶äº®ç‚¹åœ¨äºé€šè¿‡å¤§è§„æ¨¡å¯¹æ¯”å­¦ä¹ ä¼˜åŒ–ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ï¼ˆå¦‚ MTEBï¼‰ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰è¯­ä¹‰ç»†èŠ‚ã€‚é€‚ç”¨äºéœ€è¦é«˜æ•ˆä¸”ç²¾å‡†çš„è‹±æ–‡æ–‡æœ¬è¡¨ç¤ºåœºæ™¯ï¼Œå¦‚æœç´¢å¼•æ“ã€æ¨èç³»ç»Ÿå’Œæ–‡æ¡£åˆ†æå·¥å…·ã€‚",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "BGE-base-en-v1.5 is a BERT-based English sentence embedding model optimized for semantic similarity and retrieval tasks. It excels in generating dense vector representations for text, making it suitable for search, clustering, and recommendation systems. With strong performance on benchmarks like MTEB, it is widely used in both research and production environments. The model supports multiple deployment formats, including PyTorch, ONNX, and SafeTensors.",
      "summary_zh": "bge-base-en-v1.5 æ˜¯ä¸€ä¸ªåŸºäº BERT æ¶æ„çš„è‹±æ–‡æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œç”±åŒ—äº¬æ™ºæºäººå·¥æ™ºèƒ½ç ”ç©¶é™¢ï¼ˆBAAIï¼‰å¼€å‘ã€‚è¯¥æ¨¡å‹ä¸»è¦ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„å¥å­æˆ–æ®µè½çº§å‘é‡è¡¨ç¤ºï¼Œé€‚ç”¨äºè¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—ã€ä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬èšç±»ç­‰ä»»åŠ¡ã€‚å…¶äº®ç‚¹åœ¨äºé€šè¿‡å¤§è§„æ¨¡å¯¹æ¯”å­¦ä¹ ä¼˜åŒ–ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ï¼ˆå¦‚ MTEBï¼‰ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰è¯­ä¹‰ç»†èŠ‚ã€‚é€‚ç”¨äºéœ€è¦é«˜æ•ˆä¸”ç²¾å‡†çš„è‹±æ–‡æ–‡æœ¬è¡¨ç¤ºåœºæ™¯ï¼Œå¦‚æœç´¢å¼•æ“ã€æ¨èç³»ç»Ÿå’Œæ–‡æ¡£åˆ†æå·¥å…·ã€‚",
      "summary_es": "Modelo de incrustaciÃ³n de texto BGE base en inglÃ©s. Genera representaciones vectoriales densas para bÃºsqueda semÃ¡ntica y similitud textual. Destaca por su eficiencia en recuperaciÃ³n de informaciÃ³n y clustering. Ideal para aplicaciones de bÃºsqueda contextual y anÃ¡lisis de similitud en documentos."
    }
  ]
}