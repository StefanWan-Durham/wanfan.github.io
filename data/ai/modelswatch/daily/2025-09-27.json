{
  "version": 1,
  "date": "2025-09-27",
  "updated_at": "2025-09-26T22:06:33.382Z",
  "items": [
    {
      "id": "trimstray/the-book-of-secret-knowledge",
      "source": "github",
      "name": "the-book-of-secret-knowledge",
      "url": "https://github.com/trimstray/the-book-of-secret-knowledge",
      "license": "MIT",
      "lang": "N/A",
      "tags": [
        "awesome",
        "awesome-list",
        "bsd",
        "cheatsheets",
        "devops",
        "guidelines",
        "hacking",
        "hacks",
        "howtos",
        "linux",
        "lists",
        "manuals",
        "one-liners",
        "pentesters",
        "resources",
        "search-engines",
        "security",
        "security-researchers",
        "sysops"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 187002,
        "forks": 11568,
        "issues": 99
      },
      "score": 189415.59730675156,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ã€Šç§˜å¯†çŸ¥è¯†ä¹‹ä¹¦ã€‹æ˜¯ä¸€ä¸ªç³»ç»Ÿç®¡ç†ä¸ç½‘ç»œå®‰å…¨é¢†åŸŸçš„ç»¼åˆèµ„æºé›†åˆï¼Œæ”¶å½•äº†å¤§é‡å®ç”¨æ¸…å•ã€é€ŸæŸ¥è¡¨ã€æ“ä½œæŒ‡å—å’Œå·¥å…·æ¨èã€‚å†…å®¹æ¶µç›–Linuxç³»ç»Ÿè¿ç»´ã€DevOpså®è·µã€å®‰å…¨æ”»é˜²æŠ€å·§åŠå„ç±»å‘½ä»¤è¡Œå·¥å…·ä½¿ç”¨æ–¹æ³•ï¼Œé€‚åˆè¿ç»´å·¥ç¨‹å¸ˆå’Œå®‰å…¨ç ”ç©¶äººå‘˜å¿«é€ŸæŸ¥é˜…ã€‚é¡¹ç›®ä»¥åˆ†ç±»æ¸…æ™°ã€å†…å®¹å®ç”¨è‘—ç§°ï¼ŒåŒ…å«å¤§é‡å•è¡Œå‘½ä»¤å’Œå®æˆ˜æŠ€å·§ï¼Œèƒ½æœ‰æ•ˆæå‡å·¥ä½œæ•ˆç‡ã€‚æ‰€æœ‰èµ„æºå‡ç»è¿‡ç¤¾åŒºéªŒè¯ï¼Œå¯ä½œä¸ºæ—¥å¸¸æŠ€æœ¯å·¥ä½œçš„å‚è€ƒæ‰‹å†Œä½¿ç”¨ã€‚",
      "updated_at": "2025-09-21T12:05:44Z",
      "summary_en": "A curated collection of resources for system administrators, DevOps engineers, and security professionals. It compiles cheatsheets, how-tos, tools, and guidelines covering Linux, networking, and security practices. The repository serves as a quick reference for troubleshooting, automation, and hardening systems. Its strength lies in community-driven, practical content applicable to daily operations and learning.",
      "summary_zh": "ã€Šç§˜å¯†çŸ¥è¯†ä¹‹ä¹¦ã€‹æ˜¯ä¸€ä¸ªç³»ç»Ÿç®¡ç†ä¸ç½‘ç»œå®‰å…¨é¢†åŸŸçš„ç»¼åˆèµ„æºé›†åˆï¼Œæ”¶å½•äº†å¤§é‡å®ç”¨æ¸…å•ã€é€ŸæŸ¥è¡¨ã€æ“ä½œæŒ‡å—å’Œå·¥å…·æ¨èã€‚å†…å®¹æ¶µç›–Linuxç³»ç»Ÿè¿ç»´ã€DevOpså®è·µã€å®‰å…¨æ”»é˜²æŠ€å·§åŠå„ç±»å‘½ä»¤è¡Œå·¥å…·ä½¿ç”¨æ–¹æ³•ï¼Œé€‚åˆè¿ç»´å·¥ç¨‹å¸ˆå’Œå®‰å…¨ç ”ç©¶äººå‘˜å¿«é€ŸæŸ¥é˜…ã€‚é¡¹ç›®ä»¥åˆ†ç±»æ¸…æ™°ã€å†…å®¹å®ç”¨è‘—ç§°ï¼ŒåŒ…å«å¤§é‡å•è¡Œå‘½ä»¤å’Œå®æˆ˜æŠ€å·§ï¼Œèƒ½æœ‰æ•ˆæå‡å·¥ä½œæ•ˆç‡ã€‚æ‰€æœ‰èµ„æºå‡ç»è¿‡ç¤¾åŒºéªŒè¯ï¼Œå¯ä½œä¸ºæ—¥å¸¸æŠ€æœ¯å·¥ä½œçš„å‚è€ƒæ‰‹å†Œä½¿ç”¨ã€‚",
      "summary_es": "Resumen: Compendio colaborativo de recursos tÃ©cnicos para administradores de sistemas y DevOps. Incluye listas de comandos, guÃ­as de configuraciÃ³n, herramientas CLI y buenas prÃ¡cticas para entornos Unix/Linux. Destaca por su enfoque prÃ¡ctico y contenido actualizado constantemente por la comunidad. Ideal como referencia rÃ¡pida para troubleshooting y automatizaciÃ³n.",
      "reason_label": "security_safety",
      "reason_text": "å®‰å…¨ä¸å¯¹é½ç›¸å…³æ›´æ–°ï¼šthe-book-of-secret-knowledge"
    },
    {
      "id": "avelino/awesome-go",
      "source": "github",
      "name": "awesome-go",
      "url": "https://github.com/avelino/awesome-go",
      "license": "MIT",
      "lang": "Go",
      "tags": [
        "awesome",
        "awesome-list",
        "go",
        "golang",
        "golang-library",
        "hacktoberfest"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 152834,
        "forks": 12576,
        "issues": 155
      },
      "score": 155449.1972681713,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "awesome-go æ˜¯ä¸€ä¸ªç²¾å¿ƒæ•´ç†çš„ Go è¯­è¨€èµ„æºç²¾é€‰åˆ—è¡¨ï¼Œæ”¶å½•äº†å¤§é‡é«˜è´¨é‡çš„æ¡†æ¶ã€åº“å’Œè½¯ä»¶é¡¹ç›®ã€‚è¯¥é¡¹ç›®æŒ‰ç…§åŠŸèƒ½é¢†åŸŸåˆ†ç±»ï¼Œè¦†ç›–ç½‘ç»œç¼–ç¨‹ã€æ•°æ®åº“æ“ä½œã€Webå¼€å‘ã€å‘½ä»¤è¡Œå·¥å…·ç­‰å¸¸è§åº”ç”¨åœºæ™¯ã€‚ä½œä¸ºå¼€å‘è€…å¸¸ç”¨çš„å‚è€ƒç›®å½•ï¼Œå®ƒèƒ½æœ‰æ•ˆå¸®åŠ©ç”¨æˆ·å¿«é€Ÿå‘ç°å’Œé€‰ç”¨å¯é çš„ Go ç”Ÿæ€ç»„ä»¶ã€‚æ— è®ºæ˜¯å…¥é—¨å­¦ä¹ è¿˜æ˜¯é¡¹ç›®å¼€å‘ï¼Œawesome-go éƒ½ä¸º Go è¯­è¨€å¼€å‘è€…æä¾›äº†å®ç”¨ä¸”æŒç»­æ›´æ–°çš„èµ„æºç´¢å¼•ã€‚",
      "updated_at": "2025-09-21T12:05:43Z",
      "summary_en": "A curated collection of high-quality Go frameworks, libraries, and software. It serves as a comprehensive reference for developers seeking reliable tools for building applications in Go. The list is community-maintained and covers a wide range of use cases, from web development to system tools. Ideal for both beginners exploring the ecosystem and experienced developers looking for best-in-class solutions.",
      "summary_zh": "awesome-go æ˜¯ä¸€ä¸ªç²¾å¿ƒæ•´ç†çš„ Go è¯­è¨€èµ„æºç²¾é€‰åˆ—è¡¨ï¼Œæ”¶å½•äº†å¤§é‡é«˜è´¨é‡çš„æ¡†æ¶ã€åº“å’Œè½¯ä»¶é¡¹ç›®ã€‚è¯¥é¡¹ç›®æŒ‰ç…§åŠŸèƒ½é¢†åŸŸåˆ†ç±»ï¼Œè¦†ç›–ç½‘ç»œç¼–ç¨‹ã€æ•°æ®åº“æ“ä½œã€Webå¼€å‘ã€å‘½ä»¤è¡Œå·¥å…·ç­‰å¸¸è§åº”ç”¨åœºæ™¯ã€‚ä½œä¸ºå¼€å‘è€…å¸¸ç”¨çš„å‚è€ƒç›®å½•ï¼Œå®ƒèƒ½æœ‰æ•ˆå¸®åŠ©ç”¨æˆ·å¿«é€Ÿå‘ç°å’Œé€‰ç”¨å¯é çš„ Go ç”Ÿæ€ç»„ä»¶ã€‚æ— è®ºæ˜¯å…¥é—¨å­¦ä¹ è¿˜æ˜¯é¡¹ç›®å¼€å‘ï¼Œawesome-go éƒ½ä¸º Go è¯­è¨€å¼€å‘è€…æä¾›äº†å®ç”¨ä¸”æŒç»­æ›´æ–°çš„èµ„æºç´¢å¼•ã€‚",
      "summary_es": "Lista curada de frameworks, bibliotecas y software destacados para Go. Incluye herramientas para desarrollo web, sistemas, bases de datos y mÃ¡s. Ideal para descubrir recursos probados por la comunidad. Facilita el inicio de proyectos y la adopciÃ³n de mejores prÃ¡cticas en Go.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼šawesome-go"
    },
    {
      "id": "twbs/bootstrap",
      "source": "github",
      "name": "bootstrap",
      "url": "https://github.com/twbs/bootstrap",
      "license": "MIT",
      "lang": "MDX",
      "tags": [
        "bootstrap",
        "css",
        "css-framework",
        "html",
        "javascript",
        "sass",
        "scss"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 173438,
        "forks": 79163,
        "issues": 578
      },
      "score": 189370.34441323302,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Bootstrapæ˜¯GitHubä¸Šæœ€å—æ¬¢è¿çš„å‰ç«¯å¼€å‘æ¡†æ¶ï¼Œé‡‡ç”¨MITå¼€æºåè®®ã€‚å®ƒåŸºäºHTMLã€CSSå’ŒJavaScriptï¼Œæä¾›ä¸°å¯Œçš„å“åº”å¼ç»„ä»¶ä¸å·¥å…·é›†ï¼Œæ”¯æŒSasså®šåˆ¶åŒ–å¼€å‘ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºç§»åŠ¨ä¼˜å…ˆçš„è®¾è®¡ç†å¿µï¼Œèƒ½å¤Ÿå¿«é€Ÿæ„å»ºé€‚é…å¤šç«¯è®¾å¤‡çš„ç°ä»£åŒ–ç½‘é¡µç•Œé¢ã€‚é€šè¿‡é¢„ç½®çš„æ …æ ¼ç³»ç»Ÿå’ŒUIç»„ä»¶ï¼Œå¼€å‘è€…å¯æ˜¾è‘—å‡å°‘é‡å¤ä»£ç ç¼–å†™ï¼Œæå‡å¼€å‘æ•ˆç‡ã€‚é€‚ç”¨äºä¼ä¸šå®˜ç½‘ã€ç®¡ç†åå°ã€ç§»åŠ¨ç«¯åº”ç”¨ç­‰å¤šç§Webé¡¹ç›®åœºæ™¯ã€‚",
      "updated_at": "2025-09-21T10:16:29Z",
      "summary_en": "Bootstrap is a leading open-source front-end framework for building responsive, mobile-first websites. It provides a comprehensive set of CSS and JavaScript components, such as grids, buttons, and modals, to streamline web development. Its key strengths include cross-browser compatibility, extensive documentation, and a flexible grid system. It is widely applicable for rapid prototyping, consistent UI design, and projects requiring quick deployment of modern, scalable interfaces.",
      "summary_zh": "Bootstrapæ˜¯GitHubä¸Šæœ€å—æ¬¢è¿çš„å‰ç«¯å¼€å‘æ¡†æ¶ï¼Œé‡‡ç”¨MITå¼€æºåè®®ã€‚å®ƒåŸºäºHTMLã€CSSå’ŒJavaScriptï¼Œæä¾›ä¸°å¯Œçš„å“åº”å¼ç»„ä»¶ä¸å·¥å…·é›†ï¼Œæ”¯æŒSasså®šåˆ¶åŒ–å¼€å‘ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºç§»åŠ¨ä¼˜å…ˆçš„è®¾è®¡ç†å¿µï¼Œèƒ½å¤Ÿå¿«é€Ÿæ„å»ºé€‚é…å¤šç«¯è®¾å¤‡çš„ç°ä»£åŒ–ç½‘é¡µç•Œé¢ã€‚é€šè¿‡é¢„ç½®çš„æ …æ ¼ç³»ç»Ÿå’ŒUIç»„ä»¶ï¼Œå¼€å‘è€…å¯æ˜¾è‘—å‡å°‘é‡å¤ä»£ç ç¼–å†™ï¼Œæå‡å¼€å‘æ•ˆç‡ã€‚é€‚ç”¨äºä¼ä¸šå®˜ç½‘ã€ç®¡ç†åå°ã€ç§»åŠ¨ç«¯åº”ç”¨ç­‰å¤šç§Webé¡¹ç›®åœºæ™¯ã€‚",
      "summary_es": "Bootstrap es un framework front-end lÃ­der para crear sitios web responsivos y mobile-first. Utiliza HTML, CSS y JavaScript, con soporte para Sass. Sus puntos fuertes incluyen un sistema de grillas flexible, componentes predefinidos y amplia documentaciÃ³n. Ideal para prototipado rÃ¡pido y desarrollo de interfaces consistentes en mÃºltiples dispositivos.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼šbootstrap"
    },
    {
      "id": "ohmyzsh/ohmyzsh",
      "source": "github",
      "name": "ohmyzsh",
      "url": "https://github.com/ohmyzsh/ohmyzsh",
      "license": "MIT",
      "lang": "Shell",
      "tags": [
        "cli",
        "cli-app",
        "hacktoberfest",
        "oh-my-zsh",
        "oh-my-zsh-plugin",
        "oh-my-zsh-theme",
        "ohmyzsh",
        "plugin-framework",
        "plugins",
        "productivity",
        "shell",
        "terminal",
        "theme",
        "themes",
        "zsh",
        "zsh-configuration"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 181538,
        "forks": 26223,
        "issues": 504
      },
      "score": 186882.29854131944,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Oh My Zsh æ˜¯ä¸€ä¸ªåŸºäº Zsh çš„ç¤¾åŒºé©±åŠ¨é…ç½®ç®¡ç†æ¡†æ¶ï¼Œæ—¨åœ¨æå‡å‘½ä»¤è¡Œä½¿ç”¨ä½“éªŒã€‚å®ƒæä¾›äº†è¶…è¿‡ 300 ä¸ªå¯é€‰æ’ä»¶ï¼Œæ”¯æŒ Gitã€Dockerã€Python ç­‰å¸¸ç”¨å¼€å‘å·¥å…·ï¼Œå¹¶åŒ…å« 140 å¤šç§ä¸»é¢˜ä¾›ç”¨æˆ·è‡ªå®šä¹‰ç»ˆç«¯å¤–è§‚ã€‚è¯¥æ¡†æ¶å†…ç½®è‡ªåŠ¨æ›´æ–°å·¥å…·ï¼Œä¾¿äºç”¨æˆ·åŠæ—¶è·å–ç¤¾åŒºæœ€æ–°åŠŸèƒ½ã€‚é€‚ç”¨äºå¸Œæœ›æé«˜ç»ˆç«¯æ•ˆç‡ã€ç®€åŒ–é…ç½®æµç¨‹çš„å¼€å‘è€…å’Œç³»ç»Ÿç®¡ç†å‘˜ã€‚",
      "updated_at": "2025-09-21T09:56:40Z",
      "summary_en": "Oh My Zsh is a community-driven framework for managing Zsh shell configurations. It offers over 300 plugins for tools like Git, Docker, and Python, plus 140+ themes to customize the terminal interface. Its auto-update feature simplifies maintenance, and the plugin framework enhances productivity for developers and power users. It is widely used for streamlining command-line workflows.",
      "summary_zh": "Oh My Zsh æ˜¯ä¸€ä¸ªåŸºäº Zsh çš„ç¤¾åŒºé©±åŠ¨é…ç½®ç®¡ç†æ¡†æ¶ï¼Œæ—¨åœ¨æå‡å‘½ä»¤è¡Œä½¿ç”¨ä½“éªŒã€‚å®ƒæä¾›äº†è¶…è¿‡ 300 ä¸ªå¯é€‰æ’ä»¶ï¼Œæ”¯æŒ Gitã€Dockerã€Python ç­‰å¸¸ç”¨å¼€å‘å·¥å…·ï¼Œå¹¶åŒ…å« 140 å¤šç§ä¸»é¢˜ä¾›ç”¨æˆ·è‡ªå®šä¹‰ç»ˆç«¯å¤–è§‚ã€‚è¯¥æ¡†æ¶å†…ç½®è‡ªåŠ¨æ›´æ–°å·¥å…·ï¼Œä¾¿äºç”¨æˆ·åŠæ—¶è·å–ç¤¾åŒºæœ€æ–°åŠŸèƒ½ã€‚é€‚ç”¨äºå¸Œæœ›æé«˜ç»ˆç«¯æ•ˆç‡ã€ç®€åŒ–é…ç½®æµç¨‹çš„å¼€å‘è€…å’Œç³»ç»Ÿç®¡ç†å‘˜ã€‚",
      "summary_es": "Ohmyzsh es un marco de configuraciÃ³n para la shell zsh, impulsado por la comunidad. Ofrece mÃ¡s de 300 complementos y 140 temas para personalizar y mejorar la lÃ­nea de comandos. Facilita la gestiÃ³n de configuraciones, automatizaciÃ³n de tareas y mejora la productividad en entornos de desarrollo. Ideal para usuarios que buscan optimizar su flujo de trabajo en terminal.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼šohmyzsh"
    },
    {
      "id": "github/gitignore",
      "source": "github",
      "name": "gitignore",
      "url": "https://github.com/github/gitignore",
      "license": "CC0-1.0",
      "lang": "N/A",
      "tags": [
        "git",
        "gitignore"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 169503,
        "forks": 82999,
        "issues": 318
      },
      "score": 186202.62620335646,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "è¿™æ˜¯ä¸€ä¸ªç”±GitHubå®˜æ–¹ç»´æŠ¤çš„.gitignoreæ¨¡æ¿é›†åˆï¼Œæ”¶å½•äº†é’ˆå¯¹ä¸åŒç¼–ç¨‹è¯­è¨€ã€å¼€å‘æ¡†æ¶ã€æ“ä½œç³»ç»Ÿå’Œå·¥å…·çš„é…ç½®æ–‡ä»¶æ¨¡æ¿ã€‚é¡¹ç›®é‡‡ç”¨CC0åè®®ï¼Œå…è®¸ç”¨æˆ·è‡ªç”±ä½¿ç”¨å’Œä¿®æ”¹ã€‚é€šè¿‡é€‰æ‹©åˆé€‚çš„æ¨¡æ¿ï¼Œå¼€å‘è€…å¯ä»¥å¿«é€Ÿç”Ÿæˆ.gitignoreæ–‡ä»¶ï¼Œæœ‰æ•ˆé¿å…å°†ä¸´æ—¶æ–‡ä»¶ã€ç¼–è¯‘äº§ç‰©æˆ–æ•æ„Ÿä¿¡æ¯è¯¯æäº¤åˆ°Gitä»“åº“ã€‚è¯¥é¡¹ç›®æå¤§ç®€åŒ–äº†Gitç‰ˆæœ¬æ§åˆ¶ä¸­çš„æ–‡ä»¶æ’é™¤é…ç½®ï¼Œå°¤å…¶é€‚åˆéœ€è¦å¿«é€Ÿåˆå§‹åŒ–æ–°é¡¹ç›®çš„å¼€å‘è€…ä½¿ç”¨ã€‚",
      "updated_at": "2025-09-21T10:51:49Z",
      "summary_en": "A comprehensive collection of .gitignore templates for various programming languages, frameworks, and tools. It helps developers exclude unnecessary files from version control, reducing repository clutter and preventing sensitive data leaks. Ideal for any Git-based project to maintain clean commits and improve collaboration. Widely adopted for its accuracy and extensive coverage across diverse tech stacks.",
      "summary_zh": "è¿™æ˜¯ä¸€ä¸ªç”±GitHubå®˜æ–¹ç»´æŠ¤çš„.gitignoreæ¨¡æ¿é›†åˆï¼Œæ”¶å½•äº†é’ˆå¯¹ä¸åŒç¼–ç¨‹è¯­è¨€ã€å¼€å‘æ¡†æ¶ã€æ“ä½œç³»ç»Ÿå’Œå·¥å…·çš„é…ç½®æ–‡ä»¶æ¨¡æ¿ã€‚é¡¹ç›®é‡‡ç”¨CC0åè®®ï¼Œå…è®¸ç”¨æˆ·è‡ªç”±ä½¿ç”¨å’Œä¿®æ”¹ã€‚é€šè¿‡é€‰æ‹©åˆé€‚çš„æ¨¡æ¿ï¼Œå¼€å‘è€…å¯ä»¥å¿«é€Ÿç”Ÿæˆ.gitignoreæ–‡ä»¶ï¼Œæœ‰æ•ˆé¿å…å°†ä¸´æ—¶æ–‡ä»¶ã€ç¼–è¯‘äº§ç‰©æˆ–æ•æ„Ÿä¿¡æ¯è¯¯æäº¤åˆ°Gitä»“åº“ã€‚è¯¥é¡¹ç›®æå¤§ç®€åŒ–äº†Gitç‰ˆæœ¬æ§åˆ¶ä¸­çš„æ–‡ä»¶æ’é™¤é…ç½®ï¼Œå°¤å…¶é€‚åˆéœ€è¦å¿«é€Ÿåˆå§‹åŒ–æ–°é¡¹ç›®çš„å¼€å‘è€…ä½¿ç”¨ã€‚",
      "summary_es": "El proyecto gitignore ofrece una colecciÃ³n de plantillas para archivos .gitignore, organizadas por lenguajes, entornos y herramientas. Su principal utilidad es evitar que archivos innecesarios (como dependencias, logs o binarios) sean rastreados por Git. Esencial para mantener repositorios limpios, se integra fÃ¡cilmente en proyectos nuevos o existentes. Su amplia cobertura y mantenimiento comunitario lo convierten en un recurso estÃ¡ndar para desarrolladores.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼šgitignore"
    },
    {
      "id": "flutter/flutter",
      "source": "github",
      "name": "flutter",
      "url": "https://github.com/flutter/flutter",
      "license": "BSD-3-Clause",
      "lang": "Dart",
      "tags": [
        "android",
        "app-framework",
        "cross-platform",
        "dart",
        "dart-platform",
        "desktop",
        "flutter",
        "flutter-package",
        "fuchsia",
        "ios",
        "linux-desktop",
        "macos",
        "material-design",
        "mobile",
        "mobile-development",
        "skia",
        "web",
        "web-framework",
        "windows"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 173028,
        "forks": 29244,
        "issues": 12256
      },
      "score": 178976.56732989967,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Flutteræ˜¯Googleæ¨å‡ºçš„å¼€æºUIå·¥å…·åŒ…ï¼Œç”¨äºæ„å»ºé«˜è´¨é‡çš„åŸç”Ÿç•Œé¢åº”ç”¨ã€‚å®ƒé‡‡ç”¨Dartè¯­è¨€å¼€å‘ï¼Œé€šè¿‡è‡ªç»˜å¼•æ“å®ç°è·¨å¹³å°ä¸€è‡´æ€§ï¼Œæ”¯æŒiOSã€Androidã€WebåŠæ¡Œé¢ç«¯ã€‚å…¶çƒ­é‡è½½åŠŸèƒ½å¯å®æ—¶é¢„è§ˆä¿®æ”¹æ•ˆæœï¼Œå¤§å¹…æå‡å¼€å‘æ•ˆç‡ã€‚é€‚ç”¨äºéœ€è¦å¿«é€Ÿè¿­ä»£ã€è¿½æ±‚é«˜æ€§èƒ½å’Œç»Ÿä¸€è§†è§‰ä½“éªŒçš„ç§»åŠ¨åŠå¤šç«¯åº”ç”¨å¼€å‘åœºæ™¯ã€‚",
      "updated_at": "2025-09-21T10:26:23Z",
      "summary_en": "Flutter is an open-source UI framework for building natively compiled applications for mobile, web, and desktop from a single codebase. It uses the Dart language and provides a rich set of pre-designed widgets for creating visually appealing, high-performance apps. Key strengths include fast development with hot reload, consistent UI across platforms, and strong community support. It is widely used for cross-platform mobile apps and expanding to desktop and embedded devices.",
      "summary_zh": "Flutteræ˜¯Googleæ¨å‡ºçš„å¼€æºUIå·¥å…·åŒ…ï¼Œç”¨äºæ„å»ºé«˜è´¨é‡çš„åŸç”Ÿç•Œé¢åº”ç”¨ã€‚å®ƒé‡‡ç”¨Dartè¯­è¨€å¼€å‘ï¼Œé€šè¿‡è‡ªç»˜å¼•æ“å®ç°è·¨å¹³å°ä¸€è‡´æ€§ï¼Œæ”¯æŒiOSã€Androidã€WebåŠæ¡Œé¢ç«¯ã€‚å…¶çƒ­é‡è½½åŠŸèƒ½å¯å®æ—¶é¢„è§ˆä¿®æ”¹æ•ˆæœï¼Œå¤§å¹…æå‡å¼€å‘æ•ˆç‡ã€‚é€‚ç”¨äºéœ€è¦å¿«é€Ÿè¿­ä»£ã€è¿½æ±‚é«˜æ€§èƒ½å’Œç»Ÿä¸€è§†è§‰ä½“éªŒçš„ç§»åŠ¨åŠå¤šç«¯åº”ç”¨å¼€å‘åœºæ™¯ã€‚",
      "summary_es": "Flutter es un framework de cÃ³digo abierto para crear aplicaciones nativas compiladas desde un Ãºnico cÃ³digo base. Utiliza el lenguaje Dart y ofrece alto rendimiento con renderizado propio. Sus casos de uso principales incluyen desarrollo mÃ³vil (iOS/Android), escritorio y web. Destaca por su hot reload, widgets personalizables y amplia comunidad.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼šflutter"
    },
    {
      "id": "AUTOMATIC1111/stable-diffusion-webui",
      "source": "github",
      "name": "stable-diffusion-webui",
      "url": "https://github.com/AUTOMATIC1111/stable-diffusion-webui",
      "license": "AGPL-3.0",
      "lang": "Python",
      "tags": [
        "ai",
        "ai-art",
        "deep-learning",
        "diffusion",
        "gradio",
        "image-generation",
        "image2image",
        "img2img",
        "pytorch",
        "stable-diffusion",
        "text2image",
        "torch",
        "txt2img",
        "unstable",
        "upscaling",
        "web"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 156589,
        "forks": 29054,
        "issues": 2425
      },
      "score": 162499.73307064042,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Stable Diffusion web UI æ˜¯åŸºäº Stable Diffusion æ¨¡å‹çš„å›¾å½¢åŒ–å¼€æºå·¥å…·ï¼Œé€šè¿‡ Gradio æ¡†æ¶æä¾›ç›´è§‚çš„ Web ç•Œé¢ï¼Œå¤§å¹…é™ä½äº† AI å›¾åƒç”Ÿæˆçš„ä½¿ç”¨é—¨æ§›ã€‚è¯¥é¡¹ç›®æ”¯æŒæ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ã€å›¾åƒä¿®å¤ã€è‡ªå®šä¹‰æ¨¡å‹åŠ è½½ç­‰ä¸°å¯ŒåŠŸèƒ½ï¼Œå¹¶å†…ç½®äº†æç¤ºè¯è¡¥å…¨ã€å‚æ•°è°ƒä¼˜ç­‰å®ç”¨å·¥å…·ã€‚å…¶æ¨¡å—åŒ–è®¾è®¡ä¾¿äºç”¨æˆ·å®‰è£…æ‰©å±•æ’ä»¶ï¼Œæ»¡è¶³ä¸ªæ€§åŒ–åˆ›ä½œéœ€æ±‚ã€‚é€‚ç”¨äºæ•°å­—è‰ºæœ¯åˆ›ä½œã€è®¾è®¡åŸå‹ç”Ÿæˆã€AI æŠ€æœ¯ç ”ç©¶ç­‰åœºæ™¯ï¼Œä¸ºå¼€å‘è€…ä¸åˆ›ä½œè€…æä¾›äº†é«˜åº¦å¯å®šåˆ¶çš„ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆã€‚",
      "updated_at": "2025-09-21T11:37:59Z",
      "task_keys": [
        "text_to_image"
      ],
      "summary_en": "Stable Diffusion web UI is a popular open-source interface for running Stable Diffusion models locally. It enables users to generate, edit, and manipulate images via text prompts and various tools like img2img and inpainting. Built with Gradio and PyTorch, it supports extensive customization, extensions, and GPU acceleration. This tool is widely used by artists, researchers, and hobbyists for creative projects and AI experimentation.",
      "summary_zh": "Stable Diffusion web UI æ˜¯åŸºäº Stable Diffusion æ¨¡å‹çš„å›¾å½¢åŒ–å¼€æºå·¥å…·ï¼Œé€šè¿‡ Gradio æ¡†æ¶æä¾›ç›´è§‚çš„ Web ç•Œé¢ï¼Œå¤§å¹…é™ä½äº† AI å›¾åƒç”Ÿæˆçš„ä½¿ç”¨é—¨æ§›ã€‚è¯¥é¡¹ç›®æ”¯æŒæ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ã€å›¾åƒä¿®å¤ã€è‡ªå®šä¹‰æ¨¡å‹åŠ è½½ç­‰ä¸°å¯ŒåŠŸèƒ½ï¼Œå¹¶å†…ç½®äº†æç¤ºè¯è¡¥å…¨ã€å‚æ•°è°ƒä¼˜ç­‰å®ç”¨å·¥å…·ã€‚å…¶æ¨¡å—åŒ–è®¾è®¡ä¾¿äºç”¨æˆ·å®‰è£…æ‰©å±•æ’ä»¶ï¼Œæ»¡è¶³ä¸ªæ€§åŒ–åˆ›ä½œéœ€æ±‚ã€‚é€‚ç”¨äºæ•°å­—è‰ºæœ¯åˆ›ä½œã€è®¾è®¡åŸå‹ç”Ÿæˆã€AI æŠ€æœ¯ç ”ç©¶ç­‰åœºæ™¯ï¼Œä¸ºå¼€å‘è€…ä¸åˆ›ä½œè€…æä¾›äº†é«˜åº¦å¯å®šåˆ¶çš„ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆã€‚",
      "summary_es": "Interfaz web para Stable Diffusion que permite generar y transformar imÃ¡genes mediante IA. Soporta mÃºltiples modelos, personalizaciÃ³n de parÃ¡metros y extensiones. Destaca por su interfaz accesible, funciones avanzadas como inpainting y controlNet, y activa comunidad. Ideal para artistas digitales, diseÃ±adores e investigadores en creaciÃ³n visual.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼šstable-diffusion-webui"
    },
    {
      "id": "Snailclimb/JavaGuide",
      "source": "github",
      "name": "JavaGuide",
      "url": "https://github.com/Snailclimb/JavaGuide",
      "license": "Apache-2.0",
      "lang": "Java",
      "tags": [
        "algorithms",
        "interview",
        "java",
        "jvm",
        "mysql",
        "redis",
        "spring",
        "system",
        "system-design",
        "zookeeper"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 151818,
        "forks": 45986,
        "issues": 74
      },
      "score": 161115.12300119599,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "JavaGuide æ˜¯ä¸€ä»½é¢å‘ Java å¼€å‘è€…çš„ç»¼åˆæ€§å­¦ä¹ ä¸é¢è¯•æŒ‡å—ï¼Œå†…å®¹è¦†ç›– Java æ ¸å¿ƒçŸ¥è¯†ã€JVMã€å¸¸ç”¨æ¡†æ¶ï¼ˆå¦‚ Springï¼‰ã€æ•°æ®åº“ï¼ˆMySQLã€Redisï¼‰åŠç³»ç»Ÿè®¾è®¡ç­‰å…³é”®æŠ€æœ¯é¢†åŸŸã€‚è¯¥é¡¹ç›®ç»“æ„æ¸…æ™°ã€å†…å®¹å®ç”¨ï¼Œæ—¢é€‚åˆç³»ç»Ÿå­¦ä¹  Java æŠ€æœ¯æ ˆï¼Œä¹Ÿå¯ä½œä¸ºæ±‚èŒé¢è¯•å‰çš„å¤ä¹ èµ„æ–™ã€‚å…¶äº®ç‚¹åœ¨äºæŒç»­æ›´æ–°ï¼Œç´§è·ŸæŠ€æœ¯è¶‹åŠ¿ï¼Œå¹¶æä¾›äº†å¤§é‡é¢è¯•å¸¸è§é—®é¢˜ä¸è§£ç­”ã€‚æ— è®ºæ˜¯åˆå­¦è€…å¤¯å®åŸºç¡€ï¼Œè¿˜æ˜¯ä¸­é«˜çº§å¼€å‘è€…æŸ¥æ¼è¡¥ç¼ºï¼ŒJavaGuide éƒ½æ˜¯ä¸€ä¸ªå¯é çš„çŸ¥è¯†åº“å’Œå‚è€ƒå·¥å…·ã€‚",
      "updated_at": "2025-09-21T11:33:38Z",
      "summary_en": "JavaGuide is a comprehensive open-source guide for Java developers, focusing on core knowledge areas like JVM, Spring, MySQL, and system design. It serves as a study resource and interview preparation tool, covering algorithms, Redis, and ZooKeeper. With high popularity and an Apache-2.0 license, it is widely applicable for learning and career advancement in Java development.",
      "summary_zh": "JavaGuide æ˜¯ä¸€ä»½é¢å‘ Java å¼€å‘è€…çš„ç»¼åˆæ€§å­¦ä¹ ä¸é¢è¯•æŒ‡å—ï¼Œå†…å®¹è¦†ç›– Java æ ¸å¿ƒçŸ¥è¯†ã€JVMã€å¸¸ç”¨æ¡†æ¶ï¼ˆå¦‚ Springï¼‰ã€æ•°æ®åº“ï¼ˆMySQLã€Redisï¼‰åŠç³»ç»Ÿè®¾è®¡ç­‰å…³é”®æŠ€æœ¯é¢†åŸŸã€‚è¯¥é¡¹ç›®ç»“æ„æ¸…æ™°ã€å†…å®¹å®ç”¨ï¼Œæ—¢é€‚åˆç³»ç»Ÿå­¦ä¹  Java æŠ€æœ¯æ ˆï¼Œä¹Ÿå¯ä½œä¸ºæ±‚èŒé¢è¯•å‰çš„å¤ä¹ èµ„æ–™ã€‚å…¶äº®ç‚¹åœ¨äºæŒç»­æ›´æ–°ï¼Œç´§è·ŸæŠ€æœ¯è¶‹åŠ¿ï¼Œå¹¶æä¾›äº†å¤§é‡é¢è¯•å¸¸è§é—®é¢˜ä¸è§£ç­”ã€‚æ— è®ºæ˜¯åˆå­¦è€…å¤¯å®åŸºç¡€ï¼Œè¿˜æ˜¯ä¸­é«˜çº§å¼€å‘è€…æŸ¥æ¼è¡¥ç¼ºï¼ŒJavaGuide éƒ½æ˜¯ä¸€ä¸ªå¯é çš„çŸ¥è¯†åº“å’Œå‚è€ƒå·¥å…·ã€‚",
      "summary_es": "JavaGuide es una guÃ­a integral para aprendizaje y entrevistas de Java. Cubre conocimientos esenciales como JVM, Spring, MySQL, Redis y diseÃ±o de sistemas. Ideal para desarrolladores que buscan reforzar fundamentos o prepararse para procesos tÃ©cnicos. Incluye algoritmos y ejemplos prÃ¡cticos para dominar tecnologÃ­as clave del ecosistema Java.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼šJavaGuide"
    },
    {
      "id": "huggingface/transformers",
      "source": "github",
      "name": "transformers",
      "url": "https://github.com/huggingface/transformers",
      "license": "Apache-2.0",
      "lang": "Python",
      "tags": [
        "audio",
        "deep-learning",
        "deepseek",
        "gemma",
        "glm",
        "hacktoberfest",
        "llm",
        "machine-learning",
        "model-hub",
        "natural-language-processing",
        "nlp",
        "pretrained-models",
        "python",
        "pytorch",
        "pytorch-transformers",
        "qwen",
        "speech-recognition",
        "transformer",
        "vlm"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 150037,
        "forks": 30477,
        "issues": 1988
      },
      "score": 156232.35062465278,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ğŸ¤— Transformers æ˜¯ç”± Hugging Face å¼€æºçš„æœºå™¨å­¦ä¹ åº“ï¼Œæä¾›ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€éŸ³é¢‘å’Œå¤šæ¨¡æ€ä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹ä¸è®­ç»ƒæ¡†æ¶ã€‚å®ƒæ”¯æŒåŒ…æ‹¬ BERTã€GPTã€T5 ç­‰åœ¨å†…çš„å¤šç§å‰æ²¿æ¨¡å‹ç»“æ„ï¼Œå¹¶å†…ç½®æ¨¡å‹ä¸­å¿ƒï¼ˆModel Hubï¼‰ï¼Œä¾¿äºç”¨æˆ·å¿«é€ŸåŠ è½½å’Œå…±äº«æ¨¡å‹ã€‚è¯¥åº“ç»Ÿä¸€äº†ä¸åŒæ¨¡æ€æ¨¡å‹çš„è°ƒç”¨æ¥å£ï¼Œæ”¯æŒä»æ¨ç†åˆ°å…¨æµç¨‹è®­ç»ƒï¼Œå¤§å¹…é™ä½äº†ç ”ç©¶å’Œå·¥ç¨‹è½åœ°çš„é—¨æ§›ã€‚Transformers é€‚ç”¨äºæ–‡æœ¬ç”Ÿæˆã€æƒ…æ„Ÿåˆ†æã€å›¾åƒåˆ†ç±»ã€è¯­éŸ³è¯†åˆ«ç­‰å¹¿æ³›åœºæ™¯ï¼Œæ˜¯ AI å¼€å‘è€…ä¸ç ”ç©¶äººå‘˜å¸¸ç”¨çš„æ ¸å¿ƒå·¥å…·ä¹‹ä¸€ã€‚",
      "updated_at": "2025-09-21T11:45:34Z",
      "summary_en": "ğŸ¤— Transformers is a versatile open-source library for state-of-the-art machine learning models across text, vision, audio, and multimodal tasks. It supports both inference and training, offering a unified API for models like LLMs, GLM, and DeepSeek. Strengths include a vast model hub, ease of use, and broad applicability in NLP, computer vision, and audio processing. Ideal for researchers and developers building or deploying cutting-edge AI applications.",
      "summary_zh": "ğŸ¤— Transformers æ˜¯ç”± Hugging Face å¼€æºçš„æœºå™¨å­¦ä¹ åº“ï¼Œæä¾›ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€éŸ³é¢‘å’Œå¤šæ¨¡æ€ä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹ä¸è®­ç»ƒæ¡†æ¶ã€‚å®ƒæ”¯æŒåŒ…æ‹¬ BERTã€GPTã€T5 ç­‰åœ¨å†…çš„å¤šç§å‰æ²¿æ¨¡å‹ç»“æ„ï¼Œå¹¶å†…ç½®æ¨¡å‹ä¸­å¿ƒï¼ˆModel Hubï¼‰ï¼Œä¾¿äºç”¨æˆ·å¿«é€ŸåŠ è½½å’Œå…±äº«æ¨¡å‹ã€‚è¯¥åº“ç»Ÿä¸€äº†ä¸åŒæ¨¡æ€æ¨¡å‹çš„è°ƒç”¨æ¥å£ï¼Œæ”¯æŒä»æ¨ç†åˆ°å…¨æµç¨‹è®­ç»ƒï¼Œå¤§å¹…é™ä½äº†ç ”ç©¶å’Œå·¥ç¨‹è½åœ°çš„é—¨æ§›ã€‚Transformers é€‚ç”¨äºæ–‡æœ¬ç”Ÿæˆã€æƒ…æ„Ÿåˆ†æã€å›¾åƒåˆ†ç±»ã€è¯­éŸ³è¯†åˆ«ç­‰å¹¿æ³›åœºæ™¯ï¼Œæ˜¯ AI å¼€å‘è€…ä¸ç ”ç©¶äººå‘˜å¸¸ç”¨çš„æ ¸å¿ƒå·¥å…·ä¹‹ä¸€ã€‚",
      "summary_es": "Transformers es una biblioteca de cÃ³digo abierto que proporciona modelos de Ãºltima generaciÃ³n para procesamiento de lenguaje natural, visiÃ³n por computadora, audio y multimodal. Ofrece una API unificada para mÃ¡s de 100,000 modelos preentrenados, facilitando tareas como clasificaciÃ³n, traducciÃ³n y generaciÃ³n de texto. Sus puntos fuertes incluyen soporte para frameworks como PyTorch y TensorFlow, y herramientas para fine-tuning. Es ampliamente usado en investigaciÃ³n y aplicaciones industriales de IA.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼štransformers"
    },
    {
      "id": "omni-research/Tarsier2-Recap-7b",
      "source": "hf",
      "name": "Tarsier2-Recap-7b",
      "url": "https://huggingface.co/omni-research/Tarsier2-Recap-7b",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "safetensors",
        "video LLM",
        "arxiv:2501.07888",
        "license:apache-2.0",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8924832,
        "likes_total": 18
      },
      "score": 17858.664,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Tarsier2-Recap-7b æ˜¯ä¸€æ¬¾ä¸“æ³¨äºè§†é¢‘å†…å®¹ç†è§£çš„ 70 äº¿å‚æ•°å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Apache 2.0 å¼€æºåè®®å‘å¸ƒã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿå¯¹è§†é¢‘å†…å®¹è¿›è¡Œå¤šæ¨¡æ€ç†è§£ï¼Œå¹¶ç”Ÿæˆç®€æ´çš„æ–‡æœ¬æ‘˜è¦ï¼Œé€‚ç”¨äºè§†é¢‘è‡ªåŠ¨æ‘˜è¦ã€å†…å®¹æ£€ç´¢ç­‰åœºæ™¯ã€‚å…¶äº®ç‚¹åœ¨äºç»“åˆè§†è§‰ä¸è¯­è¨€ä¿¡æ¯ï¼Œå®ç°å¯¹é•¿è§†é¢‘å…³é”®ä¿¡æ¯çš„æœ‰æ•ˆæå–ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºéœ€è¦é«˜æ•ˆå¤„ç†è§†é¢‘å†…å®¹çš„æ™ºèƒ½åº”ç”¨ï¼Œå¦‚è§†é¢‘å¹³å°å†…å®¹ç®¡ç†æˆ–è¾…åŠ©åˆ›ä½œå·¥å…·ã€‚",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Tarsier2-Recap-7b is a 7-billion-parameter video language model designed for generating summaries from video content. It excels at processing visual inputs to produce concise textual recaps, making it suitable for applications like video indexing, content analysis, and accessibility tools. Strengths include efficient handling of multimodal data under the Apache 2.0 license. The model is applicable for developers building automated summarization systems for video platforms or research.",
      "summary_zh": "Tarsier2-Recap-7b æ˜¯ä¸€æ¬¾ä¸“æ³¨äºè§†é¢‘å†…å®¹ç†è§£çš„ 70 äº¿å‚æ•°å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Apache 2.0 å¼€æºåè®®å‘å¸ƒã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿå¯¹è§†é¢‘å†…å®¹è¿›è¡Œå¤šæ¨¡æ€ç†è§£ï¼Œå¹¶ç”Ÿæˆç®€æ´çš„æ–‡æœ¬æ‘˜è¦ï¼Œé€‚ç”¨äºè§†é¢‘è‡ªåŠ¨æ‘˜è¦ã€å†…å®¹æ£€ç´¢ç­‰åœºæ™¯ã€‚å…¶äº®ç‚¹åœ¨äºç»“åˆè§†è§‰ä¸è¯­è¨€ä¿¡æ¯ï¼Œå®ç°å¯¹é•¿è§†é¢‘å…³é”®ä¿¡æ¯çš„æœ‰æ•ˆæå–ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºéœ€è¦é«˜æ•ˆå¤„ç†è§†é¢‘å†…å®¹çš„æ™ºèƒ½åº”ç”¨ï¼Œå¦‚è§†é¢‘å¹³å°å†…å®¹ç®¡ç†æˆ–è¾…åŠ©åˆ›ä½œå·¥å…·ã€‚",
      "summary_es": "Tarsier2-Recap-7b es un modelo de lenguaje visual de 7B parÃ¡metros especializado en resumir contenido de vÃ­deo. Procesa marcos de vÃ­deo y genera descripciones textuales concisas. Su punto fuerte es la eficiencia computacional para tareas de resumen visual. Es Ãºtil para aplicaciones como indexaciÃ³n automÃ¡tica de vÃ­deos o generaciÃ³n de subtÃ­tulos.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼šTarsier2-Recap-7b"
    },
    {
      "id": "meta-llama/Llama-3.1-8B-Instruct",
      "source": "hf",
      "name": "Llama-3.1-8B-Instruct",
      "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "facebook",
        "meta",
        "pytorch",
        "llama-3",
        "conversational",
        "en",
        "de",
        "fr",
        "it",
        "pt",
        "hi",
        "es",
        "th",
        "arxiv:2204.05149",
        "base_model:meta-llama/Llama-3.1-8B",
        "base_model:finetune:meta-llama/Llama-3.1-8B",
        "license:llama3.1",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 6846729,
        "likes_total": 4641
      },
      "score": 16013.958,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Metaæ¨å‡ºçš„Llama-3.1-8B-Instructæ˜¯åŸºäºLlama 3æ¶æ„ä¼˜åŒ–çš„80äº¿å‚æ•°æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹ã€‚è¯¥æ¨¡å‹ä¸“ä¸ºå¯¹è¯äº¤äº’è®¾è®¡ï¼Œæ”¯æŒå¤šè½®ä¸Šä¸‹æ–‡ç†è§£ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·æŒ‡ä»¤ç”Ÿæˆè¿è´¯çš„æ–‡æœ¬å›å¤ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå¹³è¡¡äº†æ€§èƒ½ä¸èµ„æºæ¶ˆè€—ï¼Œåœ¨ä¿æŒè¾ƒå¼ºè¯­è¨€ç†è§£èƒ½åŠ›çš„åŒæ—¶é™ä½éƒ¨ç½²é—¨æ§›ã€‚é€‚ç”¨äºèŠå¤©æœºå™¨äººã€æ™ºèƒ½åŠ©æ‰‹ç­‰éœ€è¦å®æ—¶äº¤äº’çš„åœºæ™¯ï¼Œä¹Ÿå¯ä½œä¸ºè½»é‡çº§åŸºåº§æ¨¡å‹ä¾›ç ”ç©¶è€…è¿›è¡ŒäºŒæ¬¡å¼€å‘ã€‚æ¨¡å‹åŸºäºTransformeræ¶æ„ï¼Œä½¿ç”¨PyTorchæ¡†æ¶å’ŒSafeTensorsæ ¼å¼å‘å¸ƒã€‚",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Llama-3.1-8B-Instruct is an 8-billion-parameter language model from Meta, fine-tuned for instruction-following and conversational tasks. It excels in generating coherent, context-aware responses for applications like chatbots, virtual assistants, and content creation. Built on the robust Llama 3.1 architecture, it offers strong performance in English while being relatively lightweight. The model is suitable for developers needing efficient, open-ended text generation without extensive computational resources.",
      "summary_zh": "Metaæ¨å‡ºçš„Llama-3.1-8B-Instructæ˜¯åŸºäºLlama 3æ¶æ„ä¼˜åŒ–çš„80äº¿å‚æ•°æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹ã€‚è¯¥æ¨¡å‹ä¸“ä¸ºå¯¹è¯äº¤äº’è®¾è®¡ï¼Œæ”¯æŒå¤šè½®ä¸Šä¸‹æ–‡ç†è§£ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·æŒ‡ä»¤ç”Ÿæˆè¿è´¯çš„æ–‡æœ¬å›å¤ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå¹³è¡¡äº†æ€§èƒ½ä¸èµ„æºæ¶ˆè€—ï¼Œåœ¨ä¿æŒè¾ƒå¼ºè¯­è¨€ç†è§£èƒ½åŠ›çš„åŒæ—¶é™ä½éƒ¨ç½²é—¨æ§›ã€‚é€‚ç”¨äºèŠå¤©æœºå™¨äººã€æ™ºèƒ½åŠ©æ‰‹ç­‰éœ€è¦å®æ—¶äº¤äº’çš„åœºæ™¯ï¼Œä¹Ÿå¯ä½œä¸ºè½»é‡çº§åŸºåº§æ¨¡å‹ä¾›ç ”ç©¶è€…è¿›è¡ŒäºŒæ¬¡å¼€å‘ã€‚æ¨¡å‹åŸºäºTransformeræ¶æ„ï¼Œä½¿ç”¨PyTorchæ¡†æ¶å’ŒSafeTensorsæ ¼å¼å‘å¸ƒã€‚",
      "summary_es": "Llama-3.1-8B-Instruct es un modelo de lenguaje de 8 mil millones de parÃ¡metros optimizado para tareas de instrucciÃ³n y conversaciÃ³n. Basado en la arquitectura Transformer, estÃ¡ especializado en generaciÃ³n de texto en inglÃ©s. Su tamaÃ±o equilibrado permite un buen rendimiento en aplicaciones como chatbots, asistencia automatizada y comprensiÃ³n de consultas, siendo eficiente para despliegues con recursos limitados. Es adecuado para desarrolladores que necesitan un modelo conversacional potente pero mÃ¡s ligero que versiones mayores.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼šLlama-3.1-8B-Instruct"
    },
    {
      "id": "FacebookAI/roberta-large",
      "source": "hf",
      "name": "roberta-large",
      "url": "https://huggingface.co/FacebookAI/roberta-large",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "onnx",
        "safetensors",
        "roberta",
        "fill-mask",
        "exbert",
        "en",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "arxiv:1907.11692",
        "arxiv:1806.02847",
        "license:mit",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 12229272,
        "likes_total": 246
      },
      "score": 24581.544,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "RoBERTa-largeæ˜¯åŸºäºTransformeræ¶æ„çš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œç”±Meta AIåœ¨BERTåŸºç¡€ä¸Šä¼˜åŒ–è€Œæˆã€‚è¯¥æ¨¡å‹é€šè¿‡ç§»é™¤ä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡ã€æ‰©å¤§è®­ç»ƒæ•°æ®å’ŒåŠ¨æ€æ©ç ç­–ç•¥ï¼Œæå‡äº†æ–‡æœ¬ç†è§£èƒ½åŠ›ã€‚æ”¯æŒæ©ç å¡«å……ã€æ–‡æœ¬åˆ†ç±»ç­‰è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œåœ¨GLUEç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚é€‚ç”¨äºç ”ç©¶æˆ–å·¥ç¨‹åœºæ™¯ä¸­çš„è‹±æ–‡æ–‡æœ¬åˆ†æï¼Œå¦‚æƒ…æ„Ÿåˆ†æã€è¯­ä¹‰æ¨ç†ç­‰ã€‚æ¨¡å‹æä¾›PyTorchã€TensorFlowç­‰å¤šæ¡†æ¶æ”¯æŒï¼Œå¯ç›´æ¥é€šè¿‡HuggingFaceå¹³å°è°ƒç”¨ã€‚",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "RoBERTa-large is a robust English language model optimized for masked language modeling. It excels in tasks like text classification, named entity recognition, and question answering by leveraging extensive pretraining without next-sentence prediction. Built on the Transformer architecture, it supports multiple frameworks including PyTorch, TensorFlow, and JAX. The model is widely applicable for NLP research and production systems requiring high accuracy.",
      "summary_zh": "RoBERTa-largeæ˜¯åŸºäºTransformeræ¶æ„çš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œç”±Meta AIåœ¨BERTåŸºç¡€ä¸Šä¼˜åŒ–è€Œæˆã€‚è¯¥æ¨¡å‹é€šè¿‡ç§»é™¤ä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡ã€æ‰©å¤§è®­ç»ƒæ•°æ®å’ŒåŠ¨æ€æ©ç ç­–ç•¥ï¼Œæå‡äº†æ–‡æœ¬ç†è§£èƒ½åŠ›ã€‚æ”¯æŒæ©ç å¡«å……ã€æ–‡æœ¬åˆ†ç±»ç­‰è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œåœ¨GLUEç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚é€‚ç”¨äºç ”ç©¶æˆ–å·¥ç¨‹åœºæ™¯ä¸­çš„è‹±æ–‡æ–‡æœ¬åˆ†æï¼Œå¦‚æƒ…æ„Ÿåˆ†æã€è¯­ä¹‰æ¨ç†ç­‰ã€‚æ¨¡å‹æä¾›PyTorchã€TensorFlowç­‰å¤šæ¡†æ¶æ”¯æŒï¼Œå¯ç›´æ¥é€šè¿‡HuggingFaceå¹³å°è°ƒç”¨ã€‚",
      "summary_es": "RoBERTa-large es un modelo de lenguaje grande optimizado para el inglÃ©s, basado en la arquitectura BERT pero con mejoras en el entrenamiento. Destaca por su alto rendimiento en tareas de comprensiÃ³n del lenguaje como clasificaciÃ³n de texto, respuesta a preguntas y llenado de mÃ¡scaras. Es ideal para aplicaciones que requieren procesamiento robusto de texto en inglÃ©s, como anÃ¡lisis de sentimientos o extracciÃ³n de informaciÃ³n. Su diseÃ±o sin tareas especÃ­ficas de siguiente oraciÃ³n lo hace versÃ¡til y eficiente.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼šroberta-large"
    },
    {
      "id": "distilbert/distilbert-base-uncased",
      "source": "hf",
      "name": "distilbert-base-uncased",
      "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "rust",
        "safetensors",
        "distilbert",
        "fill-mask",
        "exbert",
        "en",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "arxiv:1910.01108",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 11913020,
        "likes_total": 758
      },
      "score": 24205.04,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "DistilBERTæ˜¯åŸºäºBERTæ¶æ„çš„ç²¾ç®€ç‰ˆæœ¬ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯å°†æ¨¡å‹è§„æ¨¡å‹ç¼©40%ï¼ŒåŒæ—¶ä¿ç•™97%çš„è¯­è¨€ç†è§£èƒ½åŠ›ã€‚è¯¥æ¨¡å‹ä¸“ä¸ºè‹±æ–‡æ–‡æœ¬è®¾è®¡ï¼Œæ”¯æŒæ©ç å¡«å……ä»»åŠ¡ï¼Œå¯é«˜æ•ˆå¤„ç†æ–‡æœ¬åˆ†ç±»ã€å®ä½“è¯†åˆ«ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚ç›¸æ¯”åŸç‰ˆBERTï¼ŒDistilBERTåœ¨ä¿æŒè¾ƒé«˜å‡†ç¡®åº¦çš„åŒæ—¶æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦ï¼Œé€‚åˆç®—åŠ›å—é™çš„éƒ¨ç½²åœºæ™¯ã€‚æ¨¡å‹æä¾›PyTorchã€TensorFlowç­‰å¤šæ¡†æ¶æ”¯æŒï¼Œå¯ä½œä¸ºè½»é‡çº§æ›¿ä»£æ–¹æ¡ˆç”¨äºæœç´¢å¼•æ“ä¼˜åŒ–ã€å†…å®¹åˆ†æç­‰å®é™…ä»»åŠ¡ã€‚",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "DistilBERT is a smaller, faster version of BERT that retains most of its language understanding capabilities. It is optimized for tasks like masked language modeling, text classification, and question answering. Its primary strength is delivering high performance with reduced computational requirements, making it suitable for resource-constrained environments. This model is widely applicable in production systems where efficiency and speed are critical.",
      "summary_zh": "DistilBERTæ˜¯åŸºäºBERTæ¶æ„çš„ç²¾ç®€ç‰ˆæœ¬ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯å°†æ¨¡å‹è§„æ¨¡å‹ç¼©40%ï¼ŒåŒæ—¶ä¿ç•™97%çš„è¯­è¨€ç†è§£èƒ½åŠ›ã€‚è¯¥æ¨¡å‹ä¸“ä¸ºè‹±æ–‡æ–‡æœ¬è®¾è®¡ï¼Œæ”¯æŒæ©ç å¡«å……ä»»åŠ¡ï¼Œå¯é«˜æ•ˆå¤„ç†æ–‡æœ¬åˆ†ç±»ã€å®ä½“è¯†åˆ«ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚ç›¸æ¯”åŸç‰ˆBERTï¼ŒDistilBERTåœ¨ä¿æŒè¾ƒé«˜å‡†ç¡®åº¦çš„åŒæ—¶æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦ï¼Œé€‚åˆç®—åŠ›å—é™çš„éƒ¨ç½²åœºæ™¯ã€‚æ¨¡å‹æä¾›PyTorchã€TensorFlowç­‰å¤šæ¡†æ¶æ”¯æŒï¼Œå¯ä½œä¸ºè½»é‡çº§æ›¿ä»£æ–¹æ¡ˆç”¨äºæœç´¢å¼•æ“ä¼˜åŒ–ã€å†…å®¹åˆ†æç­‰å®é™…ä»»åŠ¡ã€‚",
      "summary_es": "DistilBERT es una versiÃ³n compacta de BERT que reduce el tamaÃ±o en un 40% manteniendo el 97% de su rendimiento. Optimizado para tareas de comprensiÃ³n del lenguaje inglÃ©s como clasificaciÃ³n de texto y respuesta a preguntas. Ideal para entornos con recursos limitados o aplicaciones que requieren baja latencia. Utiliza tÃ©cnicas de destilaciÃ³n para preservar capacidades de modelos grandes con menor costo computacional.",
      "reason_label": "distillation",
      "reason_text": "è’¸é¦/è½»é‡åŒ–æˆæœï¼šdistilbert-base-uncased"
    },
    {
      "id": "google/electra-base-discriminator",
      "source": "hf",
      "name": "electra-base-discriminator",
      "url": "https://huggingface.co/google/electra-base-discriminator",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "rust",
        "electra",
        "pretraining",
        "en",
        "arxiv:1406.2661",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 11129059,
        "likes_total": 65
      },
      "score": 22290.618000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ELECTRA-base-discriminatoræ˜¯ç”±Googleæå‡ºçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨åˆ¤åˆ«å¼é¢„è®­ç»ƒæ–¹æ³•æ›¿ä»£ä¼ ç»Ÿçš„ç”Ÿæˆå¼é¢„è®­ç»ƒã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºé€šè¿‡åˆ¤æ–­è¾“å…¥è¯æ˜¯å¦è¢«æ›¿æ¢æ¥è¿›è¡Œè®­ç»ƒï¼Œæ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡ä¸æ¨¡å‹æ€§èƒ½ã€‚è¯¥æ¨¡å‹åŸºäºTransformeræ¶æ„ï¼Œæ”¯æŒPyTorchã€TensorFlowã€JAXå’ŒRustå¤šç§æ¡†æ¶ï¼Œé€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€è¯­ä¹‰ç†è§£ç­‰è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚ä½œä¸ºå¤šè¯­è¨€æ¨¡å‹ï¼Œå…¶è®­ç»ƒæ•°æ®ä»¥è‹±æ–‡ä¸ºä¸»ï¼Œå¯ä½œä¸ºä¸‹æ¸¸ä»»åŠ¡çš„å¼ºåŸºçº¿æ¨¡å‹æˆ–ç‰¹å¾æå–å™¨ã€‚",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "ELECTRA-base-discriminator is a pre-trained transformer model that uses a discriminative approach to language modeling, distinguishing between real and generated tokens. It is efficient for tasks like text classification, token classification, and sequence labeling, offering strong performance with less computational cost than generative pre-training. The model supports multiple frameworks including PyTorch, TensorFlow, and JAX, and is suitable for English NLP applications. Its Apache 2.0 license allows for broad commercial and research use.",
      "summary_zh": "ELECTRA-base-discriminatoræ˜¯ç”±Googleæå‡ºçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨åˆ¤åˆ«å¼é¢„è®­ç»ƒæ–¹æ³•æ›¿ä»£ä¼ ç»Ÿçš„ç”Ÿæˆå¼é¢„è®­ç»ƒã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºé€šè¿‡åˆ¤æ–­è¾“å…¥è¯æ˜¯å¦è¢«æ›¿æ¢æ¥è¿›è¡Œè®­ç»ƒï¼Œæ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡ä¸æ¨¡å‹æ€§èƒ½ã€‚è¯¥æ¨¡å‹åŸºäºTransformeræ¶æ„ï¼Œæ”¯æŒPyTorchã€TensorFlowã€JAXå’ŒRustå¤šç§æ¡†æ¶ï¼Œé€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€è¯­ä¹‰ç†è§£ç­‰è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚ä½œä¸ºå¤šè¯­è¨€æ¨¡å‹ï¼Œå…¶è®­ç»ƒæ•°æ®ä»¥è‹±æ–‡ä¸ºä¸»ï¼Œå¯ä½œä¸ºä¸‹æ¸¸ä»»åŠ¡çš„å¼ºåŸºçº¿æ¨¡å‹æˆ–ç‰¹å¾æå–å™¨ã€‚",
      "summary_es": "ELECTRA-base-discriminator es un modelo de lenguaje preentrenado que utiliza una arquitectura de discriminaciÃ³n para el aprendizaje eficiente. Destaca por su eficiencia computacional y rendimiento en tareas de comprensiÃ³n del lenguaje natural. Es ideal para clasificaciÃ³n de texto, anÃ¡lisis de sentimientos y preguntas-respuestas. Soporta mÃºltiples frameworks como PyTorch, TensorFlow y JAX.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼šelectra-base-discriminator"
    },
    {
      "id": "prajjwal1/bert-tiny",
      "source": "hf",
      "name": "bert-tiny",
      "url": "https://huggingface.co/prajjwal1/bert-tiny",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "BERT",
        "MNLI",
        "NLI",
        "transformer",
        "pre-training",
        "en",
        "arxiv:1908.08962",
        "arxiv:2110.01518",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 9595121,
        "likes_total": 129
      },
      "score": 19254.742000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "è¿™æ˜¯ä¸€ä¸ªåŸºäºBERTæ¶æ„çš„å¾®å‹è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹ï¼Œå‚æ•°é‡ä»…ä¸º440ä¸‡ã€‚è¯¥æ¨¡å‹é€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯ä»å¤§å‹BERTæ¨¡å‹å‹ç¼©è€Œæ¥ï¼Œåœ¨ä¿æŒåˆç†æ€§èƒ½çš„åŒæ—¶å¤§å¹…æå‡æ¨ç†é€Ÿåº¦ã€‚æ”¯æŒæ–‡æœ¬åˆ†ç±»ã€è‡ªç„¶è¯­è¨€æ¨ç†ç­‰ä¸‹æ¸¸ä»»åŠ¡ï¼Œç‰¹åˆ«é€‚ç”¨äºMNLIç­‰è¯­ä¹‰ç†è§£åœºæ™¯ã€‚ç”±äºæ¨¡å‹ä½“ç§¯å°å·§ï¼Œé€‚åˆéƒ¨ç½²åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡æˆ–éœ€è¦ä½å»¶è¿Ÿå“åº”çš„ç”Ÿäº§ç¯å¢ƒä¸­ã€‚åŸºäºPyTorchæ¡†æ¶å’ŒTransformersåº“ï¼Œå¯å¿«é€Ÿé›†æˆåˆ°ç°æœ‰NLP pipelineä¸­ã€‚",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "A compact BERT variant designed for efficient natural language inference (NLI) tasks, particularly MNLI. Ideal for resource-constrained environments like mobile devices or edge computing. Offers faster inference and lower memory usage compared to standard BERT while maintaining reasonable performance. Suited for lightweight text classification, entailment detection, and prototyping where full-scale models are impractical.",
      "summary_zh": "è¿™æ˜¯ä¸€ä¸ªåŸºäºBERTæ¶æ„çš„å¾®å‹è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹ï¼Œå‚æ•°é‡ä»…ä¸º440ä¸‡ã€‚è¯¥æ¨¡å‹é€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯ä»å¤§å‹BERTæ¨¡å‹å‹ç¼©è€Œæ¥ï¼Œåœ¨ä¿æŒåˆç†æ€§èƒ½çš„åŒæ—¶å¤§å¹…æå‡æ¨ç†é€Ÿåº¦ã€‚æ”¯æŒæ–‡æœ¬åˆ†ç±»ã€è‡ªç„¶è¯­è¨€æ¨ç†ç­‰ä¸‹æ¸¸ä»»åŠ¡ï¼Œç‰¹åˆ«é€‚ç”¨äºMNLIç­‰è¯­ä¹‰ç†è§£åœºæ™¯ã€‚ç”±äºæ¨¡å‹ä½“ç§¯å°å·§ï¼Œé€‚åˆéƒ¨ç½²åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡æˆ–éœ€è¦ä½å»¶è¿Ÿå“åº”çš„ç”Ÿäº§ç¯å¢ƒä¸­ã€‚åŸºäºPyTorchæ¡†æ¶å’ŒTransformersåº“ï¼Œå¯å¿«é€Ÿé›†æˆåˆ°ç°æœ‰NLP pipelineä¸­ã€‚",
      "summary_es": "BERT-tiny es un modelo de lenguaje pequeÃ±o basado en la arquitectura BERT, optimizado para tareas de inferencia en lenguaje natural (NLI) como MNLI. Su principal fortaleza es la eficiencia computacional, ideal para entornos con recursos limitados o aplicaciones que requieren baja latencia. Es Ãºtil para clasificaciÃ³n de texto, anÃ¡lisis de similitud y fine-tuning en dispositivos mÃ³viles o sistemas embebidos. Basado en investigaciones de compresiÃ³n de modelos, mantiene un rendimiento aceptable en tareas bÃ¡sicas de NLP.",
      "reason_label": "distillation",
      "reason_text": "è’¸é¦/è½»é‡åŒ–æˆæœï¼šbert-tiny"
    },
    {
      "id": "trpakov/vit-face-expression",
      "source": "hf",
      "name": "vit-face-expression",
      "url": "https://huggingface.co/trpakov/vit-face-expression",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "vit",
        "image-classification",
        "doi:10.57967/hf/2289",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8254929,
        "likes_total": 80
      },
      "score": 16549.858,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "è¿™æ˜¯ä¸€ä¸ªåŸºäºVision Transformer (ViT)æ¶æ„çš„é¢éƒ¨è¡¨æƒ…åˆ†ç±»æ¨¡å‹ï¼Œèƒ½å¤Ÿä»è¾“å…¥å›¾åƒä¸­è¯†åˆ«ä¸ƒç§åŸºæœ¬è¡¨æƒ…ï¼šæ„¤æ€’ã€åŒæ¶ã€ææƒ§ã€å¿«ä¹ã€ä¸­æ€§ã€æ‚²ä¼¤å’ŒæƒŠè®¶ã€‚è¯¥æ¨¡å‹ç›´æ¥åº”ç”¨äºå¯¹é½åçš„äººè„¸å›¾åƒï¼Œé€‚ç”¨äºæƒ…æ„Ÿè®¡ç®—ã€äººæœºäº¤äº’åŠè¡Œä¸ºåˆ†æç­‰åœºæ™¯ã€‚å…¶äº®ç‚¹åœ¨äºé‡‡ç”¨äº†å…ˆè¿›çš„Transformeræ¶æ„è¿›è¡Œè§†è§‰ä»»åŠ¡ï¼Œå¹¶æä¾›äº†PyTorchã€ONNXç­‰å¤šç§æ ¼å¼ï¼Œä¾¿äºéƒ¨ç½²å’Œé›†æˆã€‚å¼€å‘è€…å¯å°†å…¶ç”¨äºéœ€è¦å®æ—¶æƒ…æ„Ÿè¯†åˆ«çš„åº”ç”¨ï¼Œå¦‚æ™ºèƒ½å®¢æœæˆ–é©¾é©¶å‘˜çŠ¶æ€ç›‘æ§ç³»ç»Ÿã€‚",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "vit-face-expression is a Vision Transformer (ViT) model fine-tuned for facial expression classification. It identifies emotions such as happiness, sadness, anger, and neutrality from facial images. Built on PyTorch and compatible with ONNX and SafeTensors, it supports efficient deployment. The model is suitable for applications in emotion-aware systems, human-computer interaction, and behavioral analysis research.",
      "summary_zh": "è¿™æ˜¯ä¸€ä¸ªåŸºäºVision Transformer (ViT)æ¶æ„çš„é¢éƒ¨è¡¨æƒ…åˆ†ç±»æ¨¡å‹ï¼Œèƒ½å¤Ÿä»è¾“å…¥å›¾åƒä¸­è¯†åˆ«ä¸ƒç§åŸºæœ¬è¡¨æƒ…ï¼šæ„¤æ€’ã€åŒæ¶ã€ææƒ§ã€å¿«ä¹ã€ä¸­æ€§ã€æ‚²ä¼¤å’ŒæƒŠè®¶ã€‚è¯¥æ¨¡å‹ç›´æ¥åº”ç”¨äºå¯¹é½åçš„äººè„¸å›¾åƒï¼Œé€‚ç”¨äºæƒ…æ„Ÿè®¡ç®—ã€äººæœºäº¤äº’åŠè¡Œä¸ºåˆ†æç­‰åœºæ™¯ã€‚å…¶äº®ç‚¹åœ¨äºé‡‡ç”¨äº†å…ˆè¿›çš„Transformeræ¶æ„è¿›è¡Œè§†è§‰ä»»åŠ¡ï¼Œå¹¶æä¾›äº†PyTorchã€ONNXç­‰å¤šç§æ ¼å¼ï¼Œä¾¿äºéƒ¨ç½²å’Œé›†æˆã€‚å¼€å‘è€…å¯å°†å…¶ç”¨äºéœ€è¦å®æ—¶æƒ…æ„Ÿè¯†åˆ«çš„åº”ç”¨ï¼Œå¦‚æ™ºèƒ½å®¢æœæˆ–é©¾é©¶å‘˜çŠ¶æ€ç›‘æ§ç³»ç»Ÿã€‚",
      "summary_es": "Este modelo Vision Transformer (ViT) clasifica expresiones faciales en imÃ¡genes. Basado en transformers y PyTorch, es compatible con ONNX y SafeTensors. Ideal para anÃ¡lisis de emociones, investigaciÃ³n en psicologÃ­a o sistemas interactivos. Ofrece alta precisiÃ³n y fÃ¡cil integraciÃ³n gracias a su compatibilidad con AutoTrain y endpoints.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼švit-face-expression"
    },
    {
      "id": "amazon/chronos-t5-small",
      "source": "hf",
      "name": "chronos-t5-small",
      "url": "https://huggingface.co/amazon/chronos-t5-small",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "t5",
        "text2text-generation",
        "time series",
        "forecasting",
        "pretrained models",
        "foundation models",
        "time series foundation models",
        "time-series",
        "time-series-forecasting",
        "arxiv:2403.07815",
        "arxiv:1910.10683",
        "license:apache-2.0",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7826603,
        "likes_total": 132
      },
      "score": 15719.206,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Chronos-T5-smallæ˜¯äºšé©¬é€ŠåŸºäºT5æ¶æ„å¼€å‘çš„æ—¶åºé¢„æµ‹åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹å°†æ—¶é—´åºåˆ—æ•°æ®è½¬åŒ–ä¸ºæ–‡æœ¬åºåˆ—è¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡æ–‡æœ¬ç”Ÿæˆæ–¹å¼å®ç°å¤šé¢†åŸŸæ—¶åºé¢„æµ‹ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºç»Ÿä¸€çš„æ–‡æœ¬åˆ°æ–‡æœ¬æ¡†æ¶ï¼Œå¯çµæ´»é€‚åº”ä¸åŒé¢‘ç‡å’Œé•¿åº¦çš„è¾“å…¥æ•°æ®ã€‚æ¨¡å‹åœ¨é¢„è®­ç»ƒé˜¶æ®µå­¦ä¹ äº†å¤§è§„æ¨¡æ—¶åºæ•°æ®çš„é€šç”¨æ¨¡å¼ï¼Œæ— éœ€é¢†åŸŸç‰¹å®šè°ƒæ•´å³å¯å®Œæˆé¢„æµ‹ä»»åŠ¡ã€‚é€‚ç”¨äºèƒ½æºæ¶ˆè€—ã€é”€å”®é¢„æµ‹ç­‰éœ€è¦é›¶æ ·æœ¬æˆ–å°‘æ ·æœ¬å­¦ä¹ çš„å•†ä¸šåœºæ™¯ï¼Œä¸ºä¼ ç»Ÿç»Ÿè®¡æ–¹æ³•æä¾›äº†æœ‰ä»·å€¼çš„è¡¥å……æ–¹æ¡ˆã€‚",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "time_series_forecasting"
      ],
      "summary_en": "Chronos-T5-small is a pretrained text-to-text foundation model adapted for time series forecasting. It treats forecasting as a sequence-to-sequence task, converting numerical series into tokenized strings for processing. The model is particularly useful for univariate point forecasting across various domains like retail, energy, and finance. Its key strength lies in leveraging transfer learning from a large language model backbone, enabling competitive performance even with limited training data.",
      "summary_zh": "Chronos-T5-smallæ˜¯äºšé©¬é€ŠåŸºäºT5æ¶æ„å¼€å‘çš„æ—¶åºé¢„æµ‹åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹å°†æ—¶é—´åºåˆ—æ•°æ®è½¬åŒ–ä¸ºæ–‡æœ¬åºåˆ—è¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡æ–‡æœ¬ç”Ÿæˆæ–¹å¼å®ç°å¤šé¢†åŸŸæ—¶åºé¢„æµ‹ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºç»Ÿä¸€çš„æ–‡æœ¬åˆ°æ–‡æœ¬æ¡†æ¶ï¼Œå¯çµæ´»é€‚åº”ä¸åŒé¢‘ç‡å’Œé•¿åº¦çš„è¾“å…¥æ•°æ®ã€‚æ¨¡å‹åœ¨é¢„è®­ç»ƒé˜¶æ®µå­¦ä¹ äº†å¤§è§„æ¨¡æ—¶åºæ•°æ®çš„é€šç”¨æ¨¡å¼ï¼Œæ— éœ€é¢†åŸŸç‰¹å®šè°ƒæ•´å³å¯å®Œæˆé¢„æµ‹ä»»åŠ¡ã€‚é€‚ç”¨äºèƒ½æºæ¶ˆè€—ã€é”€å”®é¢„æµ‹ç­‰éœ€è¦é›¶æ ·æœ¬æˆ–å°‘æ ·æœ¬å­¦ä¹ çš„å•†ä¸šåœºæ™¯ï¼Œä¸ºä¼ ç»Ÿç»Ÿè®¡æ–¹æ³•æä¾›äº†æœ‰ä»·å€¼çš„è¡¥å……æ–¹æ¡ˆã€‚",
      "summary_es": "Chronos-T5-small es un modelo de serie temporal basado en T5, preentrenado para pronÃ³sticos. Codifica/decodifica series como secuencias de tokens, adaptando tÃ©cnicas de lenguaje natural. Es liviano, eficiente y Ãºtil para predicciones univariadas con patrones estacionales o tendencias. Ideal como base para fine-tuning en dominios especÃ­ficos.",
      "reason_label": "notable",
      "reason_text": "å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼šchronos-t5-small"
    },
    {
      "id": "BAAI/bge-base-en-v1.5",
      "source": "hf",
      "name": "bge-base-en-v1.5",
      "url": "https://huggingface.co/BAAI/bge-base-en-v1.5",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "sentence-transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "bert",
        "feature-extraction",
        "sentence-similarity",
        "transformers",
        "mteb",
        "en",
        "arxiv:2401.03462",
        "arxiv:2312.15503",
        "arxiv:2311.13534",
        "arxiv:2310.07554",
        "arxiv:2309.07597",
        "license:mit",
        "model-index",
        "autotrain_compatible",
        "text-embeddings-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7468962,
        "likes_total": 347
      },
      "score": 15111.424,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BGE-base-en-v1.5æ˜¯ç”±åŒ—äº¬æ™ºæºäººå·¥æ™ºèƒ½ç ”ç©¶é™¢å¼€å‘çš„è‹±æ–‡æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼ŒåŸºäºBERTæ¶æ„ä¼˜åŒ–ã€‚è¯¥æ¨¡å‹ä¸“ä¸ºå¥å­å’Œæ®µè½çº§åˆ«çš„è¯­ä¹‰è¡¨ç¤ºè®¾è®¡ï¼Œèƒ½å¤Ÿå°†æ–‡æœ¬è½¬æ¢ä¸ºé«˜ç»´å‘é‡ï¼Œä¾¿äºè®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦ã€‚åœ¨å¤šé¡¹è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶é€‚ç”¨äºæ£€ç´¢ã€èšç±»å’Œæ–‡æœ¬åŒ¹é…åœºæ™¯ã€‚æ¨¡å‹æ”¯æŒå¤šç§éƒ¨ç½²æ ¼å¼ï¼ŒåŒ…æ‹¬PyTorchå’ŒONNXï¼Œæ–¹ä¾¿é›†æˆåˆ°ç°æœ‰æŠ€æœ¯æ ˆä¸­ã€‚",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "BGE-Base-EN-v1.5 is a BERT-based English sentence embedding model optimized for semantic similarity tasks. It excels in feature extraction, enabling applications like information retrieval, clustering, and semantic search. The model is trained to produce high-quality embeddings that capture nuanced text relationships, supporting robust performance across diverse benchmarks. It is suitable for developers building NLP systems requiring efficient and accurate sentence representations.",
      "summary_zh": "BGE-base-en-v1.5æ˜¯ç”±åŒ—äº¬æ™ºæºäººå·¥æ™ºèƒ½ç ”ç©¶é™¢å¼€å‘çš„è‹±æ–‡æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼ŒåŸºäºBERTæ¶æ„ä¼˜åŒ–ã€‚è¯¥æ¨¡å‹ä¸“ä¸ºå¥å­å’Œæ®µè½çº§åˆ«çš„è¯­ä¹‰è¡¨ç¤ºè®¾è®¡ï¼Œèƒ½å¤Ÿå°†æ–‡æœ¬è½¬æ¢ä¸ºé«˜ç»´å‘é‡ï¼Œä¾¿äºè®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦ã€‚åœ¨å¤šé¡¹è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶é€‚ç”¨äºæ£€ç´¢ã€èšç±»å’Œæ–‡æœ¬åŒ¹é…åœºæ™¯ã€‚æ¨¡å‹æ”¯æŒå¤šç§éƒ¨ç½²æ ¼å¼ï¼ŒåŒ…æ‹¬PyTorchå’ŒONNXï¼Œæ–¹ä¾¿é›†æˆåˆ°ç°æœ‰æŠ€æœ¯æ ˆä¸­ã€‚",
      "summary_es": "BGE-base-en-v1.5 es un modelo de embeddings de texto en inglÃ©s basado en BERT. Genera representaciones vectoriales densas para frases o pÃ¡rrafos, optimizado para tareas de similitud semÃ¡ntica, bÃºsqueda y clustering. Su punto fuerte es el alto rendimiento en benchmarks como MTEB, siendo eficaz para RAG, motores de bÃºsqueda semÃ¡ntica y aplicaciones de comparaciÃ³n textual.",
      "reason_label": "new_release",
      "reason_text": "æ–°ç‰ˆæœ¬å‘å¸ƒï¼šbge-base-en-v1.5"
    }
  ]
}