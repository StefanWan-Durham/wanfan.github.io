{
  "date": "2025-09-18",
  "updated_at": "2025-09-17T18:42:44.950Z",
  "items": [
    {
      "id": "twbs/bootstrap",
      "source": "github",
      "name": "bootstrap",
      "url": "https://github.com/twbs/bootstrap",
      "license": "MIT",
      "lang": "MDX",
      "tags": [
        "bootstrap",
        "css",
        "css-framework",
        "html",
        "javascript",
        "sass",
        "scss"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 173434,
        "forks": 79156,
        "issues": 575
      },
      "score": 189365.05255952934,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Bootstrap æ˜¯ä¸€ä¸ªå¼€æºçš„å‰ç«¯æ¡†æ¶ï¼Œç”¨äºå¿«é€Ÿæ„å»ºå“åº”å¼ã€ç§»åŠ¨ä¼˜å…ˆçš„ç½‘ç«™å’Œ Web åº”ç”¨ã€‚å®ƒæä¾›äº†ä¸€å¥—ä¸°å¯Œçš„ CSS å’Œ JavaScript ç»„ä»¶ï¼ŒåŒ…æ‹¬ç½‘æ ¼ç³»ç»Ÿã€æŒ‰é’®ã€è¡¨å•å’Œå¯¼èˆªç­‰ï¼Œå¸®åŠ©å¼€å‘è€…é«˜æ•ˆå®ç°ä¸€è‡´çš„ç”¨æˆ·ç•Œé¢ã€‚å…¶æ ¸å¿ƒäº®ç‚¹åœ¨äºå¼ºå¤§çš„å“åº”å¼è®¾è®¡èƒ½åŠ›ï¼Œèƒ½å¤Ÿè‡ªåŠ¨é€‚é…ä¸åŒè®¾å¤‡å±å¹•å°ºå¯¸ã€‚é€‚ç”¨äºå„ç±» Web é¡¹ç›®å¼€å‘ï¼Œå°¤å…¶é€‚åˆéœ€è¦å¿«é€ŸåŸå‹è®¾è®¡æˆ–å›¢é˜Ÿåä½œçš„åœºæ™¯ã€‚",
      "updated_at": "2025-09-17T16:49:33Z",
      "summary_en": "Bootstrap is a leading open-source front-end framework for building responsive, mobile-first websites and web applications. It provides a comprehensive set of CSS and JavaScript components, such as grids, forms, and navigation bars, enabling rapid and consistent UI development. Its extensive documentation and large community support make it accessible for developers of all skill levels. Widely used for prototyping and production projects, it streamlines cross-device compatibility and design consistency.",
      "summary_zh": "Bootstrap æ˜¯ä¸€ä¸ªå¼€æºçš„å‰ç«¯æ¡†æ¶ï¼Œç”¨äºå¿«é€Ÿæ„å»ºå“åº”å¼ã€ç§»åŠ¨ä¼˜å…ˆçš„ç½‘ç«™å’Œ Web åº”ç”¨ã€‚å®ƒæä¾›äº†ä¸€å¥—ä¸°å¯Œçš„ CSS å’Œ JavaScript ç»„ä»¶ï¼ŒåŒ…æ‹¬ç½‘æ ¼ç³»ç»Ÿã€æŒ‰é’®ã€è¡¨å•å’Œå¯¼èˆªç­‰ï¼Œå¸®åŠ©å¼€å‘è€…é«˜æ•ˆå®ç°ä¸€è‡´çš„ç”¨æˆ·ç•Œé¢ã€‚å…¶æ ¸å¿ƒäº®ç‚¹åœ¨äºå¼ºå¤§çš„å“åº”å¼è®¾è®¡èƒ½åŠ›ï¼Œèƒ½å¤Ÿè‡ªåŠ¨é€‚é…ä¸åŒè®¾å¤‡å±å¹•å°ºå¯¸ã€‚é€‚ç”¨äºå„ç±» Web é¡¹ç›®å¼€å‘ï¼Œå°¤å…¶é€‚åˆéœ€è¦å¿«é€ŸåŸå‹è®¾è®¡æˆ–å›¢é˜Ÿåä½œçš„åœºæ™¯ã€‚",
      "summary_es": "Bootstrap es un framework front-end para crear sitios web responsivos y mobile-first. Incluye componentes predefinidos y un sistema de grid flexible. Es ideal para prototipado rÃ¡pido y desarrollo consistente. Ampliamente usado en aplicaciones empresariales y proyectos que priorizan la compatibilidad multiplataforma."
    },
    {
      "id": "avelino/awesome-go",
      "source": "github",
      "name": "awesome-go",
      "url": "https://github.com/avelino/awesome-go",
      "license": "MIT",
      "lang": "Go",
      "tags": [
        "awesome",
        "awesome-list",
        "go",
        "golang",
        "golang-library",
        "hacktoberfest"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 152540,
        "forks": 12568,
        "issues": 157
      },
      "score": 155153.57667218364,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "è¿™æ˜¯ä¸€ä¸ªç²¾é€‰çš„Goè¯­è¨€èµ„æºé›†åˆï¼Œæ”¶å½•äº†å¤§é‡é«˜è´¨é‡çš„æ¡†æ¶ã€åº“å’Œè½¯ä»¶é¡¹ç›®ã€‚å†…å®¹æ¶µç›–ç½‘ç»œç¼–ç¨‹ã€æ•°æ®åº“ã€å·¥å…·é“¾ç­‰å¤šä¸ªé¢†åŸŸï¼Œé€‚åˆGoå¼€å‘è€…å¿«é€ŸæŸ¥æ‰¾å’Œä½¿ç”¨æˆç†Ÿçš„å¼€æºç»„ä»¶ã€‚è¯¥é¡¹ç›®ç”±ç¤¾åŒºå…±åŒç»´æŠ¤ï¼Œéµå¾ªMITå¼€æºåè®®ï¼Œå…·æœ‰æé«˜çš„æ´»è·ƒåº¦å’Œå¯é æ€§ã€‚æ— è®ºæ˜¯åˆå­¦è€…è¿˜æ˜¯èµ„æ·±å·¥ç¨‹å¸ˆï¼Œéƒ½å¯ä»¥ä»ä¸­æ‰¾åˆ°æå‡å¼€å‘æ•ˆç‡çš„å®ç”¨å·¥å…·ã€‚",
      "updated_at": "2025-09-17T17:43:10Z",
      "summary_en": "A curated collection of high-quality Go frameworks, libraries, and software, maintained by the community. Ideal for developers seeking reliable tools for building scalable applications, microservices, and system utilities. Covers a wide range of domains, from web development to networking and DevOps. An essential resource for Go programmers to discover and evaluate production-ready solutions.",
      "summary_zh": "è¿™æ˜¯ä¸€ä¸ªç²¾é€‰çš„Goè¯­è¨€èµ„æºé›†åˆï¼Œæ”¶å½•äº†å¤§é‡é«˜è´¨é‡çš„æ¡†æ¶ã€åº“å’Œè½¯ä»¶é¡¹ç›®ã€‚å†…å®¹æ¶µç›–ç½‘ç»œç¼–ç¨‹ã€æ•°æ®åº“ã€å·¥å…·é“¾ç­‰å¤šä¸ªé¢†åŸŸï¼Œé€‚åˆGoå¼€å‘è€…å¿«é€ŸæŸ¥æ‰¾å’Œä½¿ç”¨æˆç†Ÿçš„å¼€æºç»„ä»¶ã€‚è¯¥é¡¹ç›®ç”±ç¤¾åŒºå…±åŒç»´æŠ¤ï¼Œéµå¾ªMITå¼€æºåè®®ï¼Œå…·æœ‰æé«˜çš„æ´»è·ƒåº¦å’Œå¯é æ€§ã€‚æ— è®ºæ˜¯åˆå­¦è€…è¿˜æ˜¯èµ„æ·±å·¥ç¨‹å¸ˆï¼Œéƒ½å¯ä»¥ä»ä¸­æ‰¾åˆ°æå‡å¼€å‘æ•ˆç‡çš„å®ç”¨å·¥å…·ã€‚",
      "summary_es": "Lista curada de marcos, bibliotecas y software destacados en Go. Facilita el descubrimiento de herramientas de calidad para desarrollo backend, sistemas distribuidos y CLI. Ideal para desarrolladores que buscan referencias confiables y soluciones probadas en el ecosistema Go."
    },
    {
      "id": "trimstray/the-book-of-secret-knowledge",
      "source": "github",
      "name": "the-book-of-secret-knowledge",
      "url": "https://github.com/trimstray/the-book-of-secret-knowledge",
      "license": "MIT",
      "lang": "N/A",
      "tags": [
        "awesome",
        "awesome-list",
        "bsd",
        "cheatsheets",
        "devops",
        "guidelines",
        "hacking",
        "hacks",
        "howtos",
        "linux",
        "lists",
        "manuals",
        "one-liners",
        "pentesters",
        "resources",
        "search-engines",
        "security",
        "security-researchers",
        "sysops"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 186475,
        "forks": 11535,
        "issues": 100
      },
      "score": 188881.96745150464,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ã€Šç§˜å¯†çŸ¥è¯†ä¹‹ä¹¦ã€‹æ˜¯ä¸€ä¸ªå¼€æºçš„çŸ¥è¯†é›†åˆé¡¹ç›®ï¼Œæ”¶å½•äº†å¤§é‡å®ç”¨èµ„æºï¼ŒåŒ…æ‹¬æ¸…å•ã€æ‰‹å†Œã€é€ŸæŸ¥è¡¨ã€åšå®¢ã€æŠ€å·§ã€å‘½ä»¤è¡Œå’Œç½‘é¡µå·¥å…·ç­‰ã€‚å†…å®¹æ¶µç›–ç³»ç»Ÿç®¡ç†ã€DevOpsã€å®‰å…¨ã€Linuxç­‰å¤šä¸ªæŠ€æœ¯é¢†åŸŸï¼Œé€‚åˆå¼€å‘è€…å’Œè¿ç»´äººå‘˜å¿«é€ŸæŸ¥æ‰¾å’Œå‚è€ƒã€‚é¡¹ç›®ç»“æ„æ¸…æ™°ï¼Œèµ„æºåˆ†ç±»è¯¦ç»†ï¼Œä¾¿äºé«˜æ•ˆæ£€ç´¢å’Œä½¿ç”¨ã€‚æ— è®ºæ˜¯æ—¥å¸¸å¼€å‘ã€é—®é¢˜æ’æŸ¥è¿˜æ˜¯æŠ€èƒ½æå‡ï¼Œéƒ½èƒ½ä»ä¸­æ‰¾åˆ°æœ‰ä»·å€¼çš„å‚è€ƒèµ„æ–™ã€‚",
      "updated_at": "2025-09-17T17:39:11Z",
      "summary_en": "The Book of Secret Knowledge is a comprehensive, curated collection of resources for developers, sysadmins, and security professionals. It includes cheatsheets, guides, tools, and practical tips covering Linux, DevOps, and cybersecurity. Its strength lies in its extensive, well-organized content, making it a valuable reference for both learning and daily use. Ideal for quick lookups, skill enhancement, and troubleshooting in technical environments.",
      "summary_zh": "ã€Šç§˜å¯†çŸ¥è¯†ä¹‹ä¹¦ã€‹æ˜¯ä¸€ä¸ªå¼€æºçš„çŸ¥è¯†é›†åˆé¡¹ç›®ï¼Œæ”¶å½•äº†å¤§é‡å®ç”¨èµ„æºï¼ŒåŒ…æ‹¬æ¸…å•ã€æ‰‹å†Œã€é€ŸæŸ¥è¡¨ã€åšå®¢ã€æŠ€å·§ã€å‘½ä»¤è¡Œå’Œç½‘é¡µå·¥å…·ç­‰ã€‚å†…å®¹æ¶µç›–ç³»ç»Ÿç®¡ç†ã€DevOpsã€å®‰å…¨ã€Linuxç­‰å¤šä¸ªæŠ€æœ¯é¢†åŸŸï¼Œé€‚åˆå¼€å‘è€…å’Œè¿ç»´äººå‘˜å¿«é€ŸæŸ¥æ‰¾å’Œå‚è€ƒã€‚é¡¹ç›®ç»“æ„æ¸…æ™°ï¼Œèµ„æºåˆ†ç±»è¯¦ç»†ï¼Œä¾¿äºé«˜æ•ˆæ£€ç´¢å’Œä½¿ç”¨ã€‚æ— è®ºæ˜¯æ—¥å¸¸å¼€å‘ã€é—®é¢˜æ’æŸ¥è¿˜æ˜¯æŠ€èƒ½æå‡ï¼Œéƒ½èƒ½ä»ä¸­æ‰¾åˆ°æœ‰ä»·å€¼çš„å‚è€ƒèµ„æ–™ã€‚",
      "summary_es": "Este proyecto es una extensa colecciÃ³n de recursos tÃ©cnicos, incluyendo listas, manuales, hojas de referencia y herramientas CLI/web. Destaca por su enfoque en DevOps, hacking y administraciÃ³n de sistemas Linux. Es ideal para profesionales que buscan referencias rÃ¡pidas, mejores prÃ¡cticas y soluciones tÃ©cnicas. Su estructura organizada y contenido prÃ¡ctico lo convierten en una valiosa fuente de conocimiento para desarrolladores y administradores."
    },
    {
      "id": "ohmyzsh/ohmyzsh",
      "source": "github",
      "name": "ohmyzsh",
      "url": "https://github.com/ohmyzsh/ohmyzsh",
      "license": "MIT",
      "lang": "Shell",
      "tags": [
        "cli",
        "cli-app",
        "hacktoberfest",
        "oh-my-zsh",
        "oh-my-zsh-plugin",
        "oh-my-zsh-theme",
        "ohmyzsh",
        "plugin-framework",
        "plugins",
        "productivity",
        "shell",
        "terminal",
        "theme",
        "themes",
        "zsh",
        "zsh-configuration"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 181464,
        "forks": 26215,
        "issues": 502
      },
      "score": 186806.79700397377,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Ohmyzsh æ˜¯ä¸€ä¸ªç¤¾åŒºé©±åŠ¨çš„ Zsh é…ç½®ç®¡ç†æ¡†æ¶ï¼Œæ‹¥æœ‰è¶…è¿‡ 2400 åè´¡çŒ®è€…ã€‚å®ƒæä¾›äº† 300 å¤šä¸ªå¯é€‰æ’ä»¶ï¼Œæ”¯æŒå¤šç§å¼€å‘ç¯å¢ƒå’Œå·¥å…·ï¼Œå¦‚ Gitã€Dockerã€Python ç­‰ï¼Œå¹¶åŒ…å« 140 å¤šç§ä¸»é¢˜ï¼Œå¯é«˜åº¦è‡ªå®šä¹‰ç»ˆç«¯å¤–è§‚ã€‚å†…ç½®çš„è‡ªåŠ¨æ›´æ–°å·¥å…·æ–¹ä¾¿ç”¨æˆ·åŠæ—¶è·å–ç¤¾åŒºæœ€æ–°åŠŸèƒ½ã€‚é€‚ç”¨äºå¸Œæœ›æå‡ç»ˆç«¯ä½¿ç”¨æ•ˆç‡å’Œç¾è§‚åº¦çš„å¼€å‘è€…å’Œé«˜çº§ç”¨æˆ·ã€‚",
      "updated_at": "2025-09-17T16:25:33Z",
      "summary_en": "Oh My Zsh is a community-driven framework for managing ZSH shell configurations. It offers over 300 plugins for tools like Git, Docker, and Python, enhancing productivity and workflow automation. With 140+ themes, it allows extensive customization of the terminal interface. Its auto-update feature ensures users stay current with community contributions, making it ideal for developers and power users.",
      "summary_zh": "Ohmyzsh æ˜¯ä¸€ä¸ªç¤¾åŒºé©±åŠ¨çš„ Zsh é…ç½®ç®¡ç†æ¡†æ¶ï¼Œæ‹¥æœ‰è¶…è¿‡ 2400 åè´¡çŒ®è€…ã€‚å®ƒæä¾›äº† 300 å¤šä¸ªå¯é€‰æ’ä»¶ï¼Œæ”¯æŒå¤šç§å¼€å‘ç¯å¢ƒå’Œå·¥å…·ï¼Œå¦‚ Gitã€Dockerã€Python ç­‰ï¼Œå¹¶åŒ…å« 140 å¤šç§ä¸»é¢˜ï¼Œå¯é«˜åº¦è‡ªå®šä¹‰ç»ˆç«¯å¤–è§‚ã€‚å†…ç½®çš„è‡ªåŠ¨æ›´æ–°å·¥å…·æ–¹ä¾¿ç”¨æˆ·åŠæ—¶è·å–ç¤¾åŒºæœ€æ–°åŠŸèƒ½ã€‚é€‚ç”¨äºå¸Œæœ›æå‡ç»ˆç«¯ä½¿ç”¨æ•ˆç‡å’Œç¾è§‚åº¦çš„å¼€å‘è€…å’Œé«˜çº§ç”¨æˆ·ã€‚",
      "summary_es": "Ohmyzsh es un marco de configuraciÃ³n para la terminal zsh, impulsado por la comunidad. Ofrece mÃ¡s de 300 plugins y 140 temas para mejorar la productividad en lÃ­nea de comandos. Su principal fortaleza es la personalizaciÃ³n y automatizaciÃ³n de tareas comunes. Es ideal para desarrolladores y administradores de sistemas."
    },
    {
      "id": "github/gitignore",
      "source": "github",
      "name": "gitignore",
      "url": "https://github.com/github/gitignore",
      "license": "CC0-1.0",
      "lang": "N/A",
      "tags": [
        "git",
        "gitignore"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 169421,
        "forks": 83002,
        "issues": 319
      },
      "score": 186121.2881690972,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "è¿™æ˜¯ä¸€ä¸ªç”± GitHub å®˜æ–¹ç»´æŠ¤çš„ `.gitignore` æ¨¡æ¿é›†åˆï¼Œé€‚ç”¨äºå„ç§ç¼–ç¨‹è¯­è¨€ã€æ¡†æ¶å’Œå¼€å‘ç¯å¢ƒã€‚å®ƒå¯ä»¥å¸®åŠ©å¼€å‘è€…å¿«é€Ÿç”Ÿæˆé€‚åˆé¡¹ç›®çš„ `.gitignore` æ–‡ä»¶ï¼Œé¿å…å°†ä¸å¿…è¦çš„æ–‡ä»¶ï¼ˆå¦‚ç¼–è¯‘äº§ç‰©ã€æ—¥å¿—ã€ä¾èµ–ç›®å½•ç­‰ï¼‰æäº¤åˆ° Git ä»“åº“ä¸­ã€‚è¯¥é¡¹ç›®é‡‡ç”¨ CC0-1.0 åè®®ï¼Œå…è®¸è‡ªç”±ä½¿ç”¨å’Œåˆ†å‘ã€‚æ— è®ºæ˜¯ä¸ªäººé¡¹ç›®è¿˜æ˜¯å›¢é˜Ÿåä½œï¼Œéƒ½å¯ä»¥é€šè¿‡è¿™ä¸ªæ¨¡æ¿åº“æå‡ä»£ç ç®¡ç†çš„æ•ˆç‡å’Œæ•´æ´æ€§ã€‚",
      "updated_at": "2025-09-17T17:04:56Z",
      "summary_en": "Project: gitignore  \nA comprehensive collection of .gitignore templates for various programming languages, frameworks, and tools. It helps developers exclude unnecessary files from version control, reducing repository clutter and improving performance. Widely applicable for any Git-based project, it is maintained by GitHub and community contributions. Simplifies setup and ensures best practices for ignoring files across different environments.",
      "summary_zh": "è¿™æ˜¯ä¸€ä¸ªç”± GitHub å®˜æ–¹ç»´æŠ¤çš„ `.gitignore` æ¨¡æ¿é›†åˆï¼Œé€‚ç”¨äºå„ç§ç¼–ç¨‹è¯­è¨€ã€æ¡†æ¶å’Œå¼€å‘ç¯å¢ƒã€‚å®ƒå¯ä»¥å¸®åŠ©å¼€å‘è€…å¿«é€Ÿç”Ÿæˆé€‚åˆé¡¹ç›®çš„ `.gitignore` æ–‡ä»¶ï¼Œé¿å…å°†ä¸å¿…è¦çš„æ–‡ä»¶ï¼ˆå¦‚ç¼–è¯‘äº§ç‰©ã€æ—¥å¿—ã€ä¾èµ–ç›®å½•ç­‰ï¼‰æäº¤åˆ° Git ä»“åº“ä¸­ã€‚è¯¥é¡¹ç›®é‡‡ç”¨ CC0-1.0 åè®®ï¼Œå…è®¸è‡ªç”±ä½¿ç”¨å’Œåˆ†å‘ã€‚æ— è®ºæ˜¯ä¸ªäººé¡¹ç›®è¿˜æ˜¯å›¢é˜Ÿåä½œï¼Œéƒ½å¯ä»¥é€šè¿‡è¿™ä¸ªæ¨¡æ¿åº“æå‡ä»£ç ç®¡ç†çš„æ•ˆç‡å’Œæ•´æ´æ€§ã€‚",
      "summary_es": "ColecciÃ³n de plantillas .gitignore para proyectos de software. Simplifica la exclusiÃ³n de archivos innecesarios en repositorios Git. Incluye configuraciones para lenguajes, entornos y herramientas especÃ­ficas. Ideal para mantener repositorios limpios y optimizados."
    },
    {
      "id": "flutter/flutter",
      "source": "github",
      "name": "flutter",
      "url": "https://github.com/flutter/flutter",
      "license": "BSD-3-Clause",
      "lang": "Dart",
      "tags": [
        "android",
        "app-framework",
        "cross-platform",
        "dart",
        "dart-platform",
        "desktop",
        "flutter",
        "flutter-package",
        "fuchsia",
        "ios",
        "linux-desktop",
        "macos",
        "material-design",
        "mobile",
        "mobile-development",
        "skia",
        "web",
        "web-framework",
        "windows"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 172478,
        "forks": 29213,
        "issues": 12251
      },
      "score": 178420.59939594907,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Flutter æ˜¯ç”± Google å¼€å‘çš„å¼€æº UI æ¡†æ¶ï¼Œä½¿ç”¨ Dart è¯­è¨€æ„å»ºé«˜æ€§èƒ½ã€è·¨å¹³å°çš„åº”ç”¨ç¨‹åºã€‚å®ƒæ”¯æŒç§»åŠ¨ç«¯ï¼ˆiOS å’Œ Androidï¼‰ã€æ¡Œé¢ç«¯ï¼ˆWindowsã€macOSã€Linuxï¼‰ä»¥åŠ Web ç«¯å¼€å‘ï¼Œé€šè¿‡å•ä¸€ä»£ç åº“å®ç°å¤šå¹³å°éƒ¨ç½²ã€‚Flutter çš„æ ¸å¿ƒäº®ç‚¹åŒ…æ‹¬å…¶ä¸°å¯Œçš„ç»„ä»¶åº“ã€é«˜åº¦è‡ªå®šä¹‰çš„ UI è®¾è®¡èƒ½åŠ›ï¼Œä»¥åŠçƒ­é‡è½½åŠŸèƒ½ï¼Œæ˜¾è‘—æå‡å¼€å‘æ•ˆç‡ã€‚é€‚ç”¨äºéœ€è¦å¿«é€Ÿè¿­ä»£ã€è¿½æ±‚ä¸€è‡´ç”¨æˆ·ä½“éªŒçš„è·¨å¹³å°åº”ç”¨å¼€å‘åœºæ™¯ã€‚",
      "updated_at": "2025-09-17T17:52:59Z",
      "summary_en": "Flutter is an open-source UI framework for building natively compiled applications for mobile, web, and desktop from a single codebase. It uses the Dart programming language and provides a rich set of pre-designed widgets, enabling fast development with a consistent look and feel across platforms. Its hot reload feature allows for real-time updates during development, improving productivity. Flutter is ideal for developers aiming to create high-performance, visually appealing apps efficiently.",
      "summary_zh": "Flutter æ˜¯ç”± Google å¼€å‘çš„å¼€æº UI æ¡†æ¶ï¼Œä½¿ç”¨ Dart è¯­è¨€æ„å»ºé«˜æ€§èƒ½ã€è·¨å¹³å°çš„åº”ç”¨ç¨‹åºã€‚å®ƒæ”¯æŒç§»åŠ¨ç«¯ï¼ˆiOS å’Œ Androidï¼‰ã€æ¡Œé¢ç«¯ï¼ˆWindowsã€macOSã€Linuxï¼‰ä»¥åŠ Web ç«¯å¼€å‘ï¼Œé€šè¿‡å•ä¸€ä»£ç åº“å®ç°å¤šå¹³å°éƒ¨ç½²ã€‚Flutter çš„æ ¸å¿ƒäº®ç‚¹åŒ…æ‹¬å…¶ä¸°å¯Œçš„ç»„ä»¶åº“ã€é«˜åº¦è‡ªå®šä¹‰çš„ UI è®¾è®¡èƒ½åŠ›ï¼Œä»¥åŠçƒ­é‡è½½åŠŸèƒ½ï¼Œæ˜¾è‘—æå‡å¼€å‘æ•ˆç‡ã€‚é€‚ç”¨äºéœ€è¦å¿«é€Ÿè¿­ä»£ã€è¿½æ±‚ä¸€è‡´ç”¨æˆ·ä½“éªŒçš„è·¨å¹³å°åº”ç”¨å¼€å‘åœºæ™¯ã€‚",
      "summary_es": "Flutter es un framework de cÃ³digo abierto para crear aplicaciones nativas compiladas para mÃ³vil, web y escritorio desde una Ãºnica base de cÃ³digo. Utiliza el lenguaje Dart y ofrece alto rendimiento con renderizado propio. Ideal para desarrollo cross-platform con interfaces fluidas y personalizables. Ampliamente adoptado en aplicaciones de producciÃ³n."
    },
    {
      "id": "AUTOMATIC1111/stable-diffusion-webui",
      "source": "github",
      "name": "stable-diffusion-webui",
      "url": "https://github.com/AUTOMATIC1111/stable-diffusion-webui",
      "license": "AGPL-3.0",
      "lang": "Python",
      "tags": [
        "ai",
        "ai-art",
        "deep-learning",
        "diffusion",
        "gradio",
        "image-generation",
        "image2image",
        "img2img",
        "pytorch",
        "stable-diffusion",
        "text2image",
        "torch",
        "txt2img",
        "unstable",
        "upscaling",
        "web"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 156485,
        "forks": 29043,
        "issues": 2426
      },
      "score": 162393.59025243056,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Stable Diffusion web UI æ˜¯ä¸€ä¸ªåŸºäº Gradio æ„å»ºçš„ Web ç•Œé¢ï¼Œç”¨äºè¿è¡Œ Stable Diffusion å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚å®ƒæ”¯æŒæ–‡æœ¬åˆ°å›¾åƒã€å›¾åƒåˆ°å›¾åƒç­‰å¤šç§ç”Ÿæˆæ¨¡å¼ï¼Œå¹¶æä¾›äº†ä¸°å¯Œçš„è‡ªå®šä¹‰é€‰é¡¹ï¼Œå¦‚æ¨¡å‹é€‰æ‹©ã€å‚æ•°è°ƒæ•´å’Œæ’ä»¶æ‰©å±•ã€‚è¯¥é¡¹ç›®é€‚ç”¨äº AI è‰ºæœ¯åˆ›ä½œã€è®¾è®¡è¾…åŠ©å’Œå®éªŒç ”ç©¶ç­‰åœºæ™¯ï¼Œç”¨æˆ·æ— éœ€ç¼–å†™ä»£ç å³å¯ä½¿ç”¨å¼ºå¤§çš„å›¾åƒç”ŸæˆåŠŸèƒ½ã€‚å…¶å¼€æºç‰¹æ€§å…è®¸å¼€å‘è€…è‡ªç”±ä¿®æ”¹å’Œæ‰©å±•åŠŸèƒ½ï¼Œæ¨åŠ¨äº† AI ç”Ÿæˆå†…å®¹çš„æ™®åŠå’Œåˆ›æ–°ã€‚",
      "updated_at": "2025-09-17T17:49:02Z",
      "summary_en": "Stable Diffusion web UI is a popular open-source interface for running and customizing Stable Diffusion models. It enables users to generate, edit, and manipulate images via text prompts and image inputs. The tool supports various workflows, including text-to-image, image-to-image, and inpainting, making it versatile for creative and experimental use. Built with Gradio and PyTorch, it is widely adopted by artists, researchers, and hobbyists for accessible AI-driven image generation.",
      "summary_zh": "Stable Diffusion web UI æ˜¯ä¸€ä¸ªåŸºäº Gradio æ„å»ºçš„ Web ç•Œé¢ï¼Œç”¨äºè¿è¡Œ Stable Diffusion å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚å®ƒæ”¯æŒæ–‡æœ¬åˆ°å›¾åƒã€å›¾åƒåˆ°å›¾åƒç­‰å¤šç§ç”Ÿæˆæ¨¡å¼ï¼Œå¹¶æä¾›äº†ä¸°å¯Œçš„è‡ªå®šä¹‰é€‰é¡¹ï¼Œå¦‚æ¨¡å‹é€‰æ‹©ã€å‚æ•°è°ƒæ•´å’Œæ’ä»¶æ‰©å±•ã€‚è¯¥é¡¹ç›®é€‚ç”¨äº AI è‰ºæœ¯åˆ›ä½œã€è®¾è®¡è¾…åŠ©å’Œå®éªŒç ”ç©¶ç­‰åœºæ™¯ï¼Œç”¨æˆ·æ— éœ€ç¼–å†™ä»£ç å³å¯ä½¿ç”¨å¼ºå¤§çš„å›¾åƒç”ŸæˆåŠŸèƒ½ã€‚å…¶å¼€æºç‰¹æ€§å…è®¸å¼€å‘è€…è‡ªç”±ä¿®æ”¹å’Œæ‰©å±•åŠŸèƒ½ï¼Œæ¨åŠ¨äº† AI ç”Ÿæˆå†…å®¹çš„æ™®åŠå’Œåˆ›æ–°ã€‚",
      "summary_es": "Interfaz web para Stable Diffusion que permite generar y transformar imÃ¡genes mediante IA. Ofrece amplias opciones de personalizaciÃ³n, soporta mÃºltiples modelos y extensiones. Ideal para artistas digitales, investigadores y entusiastas de la inteligencia artificial que buscan una herramienta versÃ¡til y accesible para creaciÃ³n visual."
    },
    {
      "id": "Snailclimb/JavaGuide",
      "source": "github",
      "name": "JavaGuide",
      "url": "https://github.com/Snailclimb/JavaGuide",
      "license": "Apache-2.0",
      "lang": "Java",
      "tags": [
        "algorithms",
        "interview",
        "java",
        "jvm",
        "mysql",
        "redis",
        "spring",
        "system",
        "system-design",
        "zookeeper"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 151773,
        "forks": 45985,
        "issues": 73
      },
      "score": 161069.93299934414,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ã€ŠJavaGuideã€‹æ˜¯ä¸€ä»½é¢å‘ Java å¼€å‘è€…çš„ç»¼åˆæ€§å­¦ä¹ ä¸é¢è¯•æŒ‡å—ï¼Œå†…å®¹æ¶µç›– Java æ ¸å¿ƒçŸ¥è¯†ã€JVMã€å¸¸ç”¨æ¡†æ¶ï¼ˆå¦‚ Springï¼‰ã€æ•°æ®åº“ï¼ˆMySQLã€Redisï¼‰ã€åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡åŠå¸¸ç”¨ä¸­é—´ä»¶ï¼ˆå¦‚ ZooKeeperï¼‰ã€‚è¯¥é¡¹ç›®ç»“æ„æ¸…æ™°ã€å†…å®¹å®ç”¨ï¼Œä¸ä»…é€‚åˆç³»ç»Ÿå­¦ä¹  Java æŠ€æœ¯æ ˆï¼Œä¹Ÿä¸ºæ±‚èŒé¢è¯•æä¾›äº†é«˜è´¨é‡çš„èµ„æ–™æ”¯æŒã€‚æ— è®ºæ˜¯åˆå­¦è€…å…¥é—¨ï¼Œè¿˜æ˜¯å¼€å‘è€…è¿›é˜¶å’Œé¢è¯•å‡†å¤‡ï¼Œéƒ½èƒ½ä»ä¸­è·å¾—å¸®åŠ©ã€‚",
      "updated_at": "2025-09-17T17:24:18Z",
      "summary_en": "JavaGuide is a comprehensive open-source resource for Java developers, covering core knowledge areas like algorithms, JVM, databases, and frameworks. It serves as a study and interview preparation guide, offering practical insights and examples. Its strengths include broad topic coverage, clear explanations, and relevance to real-world development and hiring processes. Ideal for learners and professionals aiming to deepen their Java expertise or prepare for technical interviews.",
      "summary_zh": "ã€ŠJavaGuideã€‹æ˜¯ä¸€ä»½é¢å‘ Java å¼€å‘è€…çš„ç»¼åˆæ€§å­¦ä¹ ä¸é¢è¯•æŒ‡å—ï¼Œå†…å®¹æ¶µç›– Java æ ¸å¿ƒçŸ¥è¯†ã€JVMã€å¸¸ç”¨æ¡†æ¶ï¼ˆå¦‚ Springï¼‰ã€æ•°æ®åº“ï¼ˆMySQLã€Redisï¼‰ã€åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡åŠå¸¸ç”¨ä¸­é—´ä»¶ï¼ˆå¦‚ ZooKeeperï¼‰ã€‚è¯¥é¡¹ç›®ç»“æ„æ¸…æ™°ã€å†…å®¹å®ç”¨ï¼Œä¸ä»…é€‚åˆç³»ç»Ÿå­¦ä¹  Java æŠ€æœ¯æ ˆï¼Œä¹Ÿä¸ºæ±‚èŒé¢è¯•æä¾›äº†é«˜è´¨é‡çš„èµ„æ–™æ”¯æŒã€‚æ— è®ºæ˜¯åˆå­¦è€…å…¥é—¨ï¼Œè¿˜æ˜¯å¼€å‘è€…è¿›é˜¶å’Œé¢è¯•å‡†å¤‡ï¼Œéƒ½èƒ½ä»ä¸­è·å¾—å¸®åŠ©ã€‚",
      "summary_es": "JavaGuide es una guÃ­a integral para desarrolladores Java, enfocada en aprendizaje y preparaciÃ³n para entrevistas. Cubre conocimientos esenciales como algoritmos, JVM, bases de datos y frameworks como Spring. Su enfoque prÃ¡ctico y contenido actualizado lo hacen ideal para estudiantes y profesionales que buscan reforzar habilidades tÃ©cnicas o prepararse para procesos de selecciÃ³n."
    },
    {
      "id": "huggingface/transformers",
      "source": "github",
      "name": "transformers",
      "url": "https://github.com/huggingface/transformers",
      "license": "Apache-2.0",
      "lang": "Python",
      "tags": [
        "audio",
        "deep-learning",
        "deepseek",
        "gemma",
        "glm",
        "hacktoberfest",
        "llm",
        "machine-learning",
        "model-hub",
        "natural-language-processing",
        "nlp",
        "pretrained-models",
        "python",
        "pytorch",
        "pytorch-transformers",
        "qwen",
        "speech-recognition",
        "transformer",
        "vlm"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "stars": 149912,
        "forks": 30436,
        "issues": 1990
      },
      "score": 156099.1655996528,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ğŸ¤— Transformers æ˜¯ä¸€ä¸ªå¼€æºæœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œä¸“æ³¨äºæä¾›æœ€å…ˆè¿›çš„æ–‡æœ¬ã€è§†è§‰ã€éŸ³é¢‘å’Œå¤šæ¨¡æ€æ¨¡å‹çš„å®ç°ã€‚å®ƒæ”¯æŒæ¨ç†å’Œè®­ç»ƒï¼Œé€‚ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰å’ŒéŸ³é¢‘å¤„ç†ç­‰å¤šç§ä»»åŠ¡ã€‚è¯¥æ¡†æ¶é›†æˆäº†å¤§é‡é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¦‚ BERTã€GPT å’Œ T5ï¼Œå¹¶æ”¯æŒå¿«é€Ÿéƒ¨ç½²å’Œå¾®è°ƒã€‚é€‚ç”¨äºç ”ç©¶äººå‘˜ã€å·¥ç¨‹å¸ˆå’Œå¼€å‘è€…ï¼Œç”¨äºæ„å»ºå’Œå®éªŒå…ˆè¿›çš„ AI åº”ç”¨ã€‚",
      "updated_at": "2025-09-17T17:38:23Z",
      "summary_en": "ğŸ¤— Transformers is a versatile open-source library for state-of-the-art machine learning models across text, vision, audio, and multimodal tasks. It supports both training and inference, offering a unified framework for models like BERT, GPT, and Whisper. Its strengths include extensive pre-trained models, ease of fine-tuning, and broad applicability in NLP, computer vision, and speech processing. Ideal for researchers and developers building scalable AI applications.",
      "summary_zh": "ğŸ¤— Transformers æ˜¯ä¸€ä¸ªå¼€æºæœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œä¸“æ³¨äºæä¾›æœ€å…ˆè¿›çš„æ–‡æœ¬ã€è§†è§‰ã€éŸ³é¢‘å’Œå¤šæ¨¡æ€æ¨¡å‹çš„å®ç°ã€‚å®ƒæ”¯æŒæ¨ç†å’Œè®­ç»ƒï¼Œé€‚ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰å’ŒéŸ³é¢‘å¤„ç†ç­‰å¤šç§ä»»åŠ¡ã€‚è¯¥æ¡†æ¶é›†æˆäº†å¤§é‡é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¦‚ BERTã€GPT å’Œ T5ï¼Œå¹¶æ”¯æŒå¿«é€Ÿéƒ¨ç½²å’Œå¾®è°ƒã€‚é€‚ç”¨äºç ”ç©¶äººå‘˜ã€å·¥ç¨‹å¸ˆå’Œå¼€å‘è€…ï¼Œç”¨äºæ„å»ºå’Œå®éªŒå…ˆè¿›çš„ AI åº”ç”¨ã€‚",
      "summary_es": "Transformers es una biblioteca de cÃ³digo abierto para modelos de aprendizaje profundo en texto, visiÃ³n, audio y multimodal. Ofrece implementaciones de Ãºltima generaciÃ³n para inferencia y entrenamiento, con soporte para mÃºltiples arquitecturas. Sus puntos fuertes incluyen integraciÃ³n con el Hub de modelos y facilidad de uso. Es ampliamente utilizado en procesamiento de lenguaje natural y tareas multimodales."
    },
    {
      "id": "omni-research/Tarsier2-Recap-7b",
      "source": "hf",
      "name": "Tarsier2-Recap-7b",
      "url": "https://huggingface.co/omni-research/Tarsier2-Recap-7b",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "safetensors",
        "video LLM",
        "arxiv:2501.07888",
        "license:apache-2.0",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 8263301,
        "hf_likes": 17
      },
      "score": 16535.102,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Tarsier2-Recap-7b æ˜¯ä¸€ä¸ªåŸºäº Transformer æ¶æ„çš„è§†é¢‘è¯­è¨€æ¨¡å‹ï¼Œä¸“æ³¨äºè§†é¢‘å†…å®¹ç†è§£ä¸æ‘˜è¦ç”Ÿæˆã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿå¤„ç†è§†é¢‘è¾“å…¥å¹¶ç”Ÿæˆç»“æ„åŒ–çš„æ–‡æœ¬æ‘˜è¦ï¼Œé€‚ç”¨äºè§†é¢‘å†…å®¹åˆ†æã€è‡ªåŠ¨å­—å¹•ç”Ÿæˆå’Œå¤šåª’ä½“ä¿¡æ¯æ£€ç´¢ç­‰åœºæ™¯ã€‚å…¶äº®ç‚¹åœ¨äºç»“åˆäº†è§†è§‰ä¸è¯­è¨€æ¨¡æ€ï¼Œæ”¯æŒå¯¹è§†é¢‘æ—¶åºä¿¡æ¯çš„å»ºæ¨¡ï¼Œæå‡äº†é•¿è§†é¢‘å†…å®¹çš„ç†è§£èƒ½åŠ›ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºè§†é¢‘å¹³å°ã€æ™ºèƒ½ç›‘æ§å’Œå¤šåª’ä½“æ•°æ®åˆ†æç­‰é¢†åŸŸï¼Œä¸ºè‡ªåŠ¨åŒ–è§†é¢‘å¤„ç†æä¾›äº†é«˜æ•ˆå·¥å…·ã€‚",
      "updated_at": "2025-09-17T17:53:14.779Z",
      "summary_en": "Tarsier2-Recap-7b is a 7-billion-parameter video language model designed for summarizing and analyzing video content. It excels at generating concise recaps and extracting key information from videos, making it suitable for applications in media analysis, content indexing, and accessibility. Its Apache 2.0 license and strong performance metrics indicate broad usability for research and practical deployment. The model is particularly effective for tasks requiring efficient video understanding without extensive computational resources.",
      "summary_zh": "Tarsier2-Recap-7b æ˜¯ä¸€ä¸ªåŸºäº Transformer æ¶æ„çš„è§†é¢‘è¯­è¨€æ¨¡å‹ï¼Œä¸“æ³¨äºè§†é¢‘å†…å®¹ç†è§£ä¸æ‘˜è¦ç”Ÿæˆã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿå¤„ç†è§†é¢‘è¾“å…¥å¹¶ç”Ÿæˆç»“æ„åŒ–çš„æ–‡æœ¬æ‘˜è¦ï¼Œé€‚ç”¨äºè§†é¢‘å†…å®¹åˆ†æã€è‡ªåŠ¨å­—å¹•ç”Ÿæˆå’Œå¤šåª’ä½“ä¿¡æ¯æ£€ç´¢ç­‰åœºæ™¯ã€‚å…¶äº®ç‚¹åœ¨äºç»“åˆäº†è§†è§‰ä¸è¯­è¨€æ¨¡æ€ï¼Œæ”¯æŒå¯¹è§†é¢‘æ—¶åºä¿¡æ¯çš„å»ºæ¨¡ï¼Œæå‡äº†é•¿è§†é¢‘å†…å®¹çš„ç†è§£èƒ½åŠ›ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºè§†é¢‘å¹³å°ã€æ™ºèƒ½ç›‘æ§å’Œå¤šåª’ä½“æ•°æ®åˆ†æç­‰é¢†åŸŸï¼Œä¸ºè‡ªåŠ¨åŒ–è§†é¢‘å¤„ç†æä¾›äº†é«˜æ•ˆå·¥å…·ã€‚",
      "summary_es": "Tarsier2-Recap-7b es un modelo de lenguaje multimodal especializado en el anÃ¡lisis y resumen de contenido de video. Basado en la arquitectura Llama-3.2-7B, destaca por su capacidad para procesar marcos de video y generar descripciones textuales precisas. Sus principales aplicaciones incluyen la creaciÃ³n automÃ¡tica de resÃºmenes de vÃ­deos, extracciÃ³n de informaciÃ³n clave y generaciÃ³n de metadatos descriptivos. El modelo utiliza el formato de tensores seguros (safetensors) y estÃ¡ disponible bajo licencia Apache 2.0."
    },
    {
      "id": "meta-llama/Llama-3.1-8B-Instruct",
      "source": "hf",
      "name": "Llama-3.1-8B-Instruct",
      "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "facebook",
        "meta",
        "pytorch",
        "llama-3",
        "conversational",
        "en",
        "de",
        "fr",
        "it",
        "pt",
        "hi",
        "es",
        "th",
        "arxiv:2204.05149",
        "base_model:meta-llama/Llama-3.1-8B",
        "base_model:finetune:meta-llama/Llama-3.1-8B",
        "license:llama3.1",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 7230352,
        "hf_likes": 4626
      },
      "score": 16773.703999999998,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Llama-3.1-8B-Instruct æ˜¯ Meta æ¨å‡ºçš„å¼€æºå¯¹è¯ä¼˜åŒ–è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Llama-3 æ¶æ„ï¼Œå‚æ•°é‡ä¸º 80 äº¿ã€‚è¯¥æ¨¡å‹ä¸“ä¸ºæŒ‡ä»¤éµå¾ªå’Œå¯¹è¯äº¤äº’è®¾è®¡ï¼Œé€‚ç”¨äºæ–‡æœ¬ç”Ÿæˆã€é—®ç­”ã€ä»£ç è¾…åŠ©ç­‰å¤šç§ä»»åŠ¡ã€‚å…¶äº®ç‚¹åœ¨äºé«˜æ•ˆçš„æ¨ç†æ€§èƒ½ä¸è¾ƒå¼ºçš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ï¼Œå°¤å…¶é€‚åˆèµ„æºå—é™ç¯å¢ƒä¸‹çš„éƒ¨ç½²ã€‚æ¨¡å‹æ”¯æŒ Transformers å’Œ PyTorch æ¡†æ¶ï¼Œä¸»è¦é¢å‘è‹±è¯­åœºæ™¯ï¼Œå¯ç”¨äºèŠå¤©æœºå™¨äººã€å†…å®¹åˆ›ä½œæˆ–è‡ªåŠ¨åŒ–ä»»åŠ¡å¤„ç†ç­‰åº”ç”¨ã€‚",
      "updated_at": "2025-09-17T17:53:14.779Z",
      "summary_en": "Llama-3.1-8B-Instruct is an 8-billion-parameter language model optimized for instruction-following tasks. It excels in conversational applications, text generation, and structured reasoning. Built on the robust Llama-3 architecture, it offers strong performance in English while maintaining efficiency for deployment. Ideal for chatbots, content creation, and research prototyping.",
      "summary_zh": "Llama-3.1-8B-Instruct æ˜¯ Meta æ¨å‡ºçš„å¼€æºå¯¹è¯ä¼˜åŒ–è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Llama-3 æ¶æ„ï¼Œå‚æ•°é‡ä¸º 80 äº¿ã€‚è¯¥æ¨¡å‹ä¸“ä¸ºæŒ‡ä»¤éµå¾ªå’Œå¯¹è¯äº¤äº’è®¾è®¡ï¼Œé€‚ç”¨äºæ–‡æœ¬ç”Ÿæˆã€é—®ç­”ã€ä»£ç è¾…åŠ©ç­‰å¤šç§ä»»åŠ¡ã€‚å…¶äº®ç‚¹åœ¨äºé«˜æ•ˆçš„æ¨ç†æ€§èƒ½ä¸è¾ƒå¼ºçš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ï¼Œå°¤å…¶é€‚åˆèµ„æºå—é™ç¯å¢ƒä¸‹çš„éƒ¨ç½²ã€‚æ¨¡å‹æ”¯æŒ Transformers å’Œ PyTorch æ¡†æ¶ï¼Œä¸»è¦é¢å‘è‹±è¯­åœºæ™¯ï¼Œå¯ç”¨äºèŠå¤©æœºå™¨äººã€å†…å®¹åˆ›ä½œæˆ–è‡ªåŠ¨åŒ–ä»»åŠ¡å¤„ç†ç­‰åº”ç”¨ã€‚",
      "summary_es": "Llama-3.1-8B-Instruct es un modelo de lenguaje de 8 mil millones de parÃ¡metros optimizado para tareas de instrucciÃ³n y diÃ¡logo. Basado en la arquitectura Transformer, destaca por su eficiencia computacional y capacidad para generar respuestas coherentes en inglÃ©s. Es ideal para chatbots, asistentes virtuales y aplicaciones de procesamiento de lenguaje natural. Su licencia permite uso comercial e investigaciÃ³n."
    },
    {
      "id": "amazon/chronos-t5-small",
      "source": "hf",
      "name": "chronos-t5-small",
      "url": "https://huggingface.co/amazon/chronos-t5-small",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "t5",
        "text2text-generation",
        "time series",
        "forecasting",
        "pretrained models",
        "foundation models",
        "time series foundation models",
        "time-series",
        "time-series-forecasting",
        "arxiv:2403.07815",
        "arxiv:1910.10683",
        "license:apache-2.0",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 13199198,
        "hf_likes": 131
      },
      "score": 26463.896,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Chronos-T5-smallæ˜¯äºšé©¬é€ŠåŸºäºT5æ¶æ„å¼€å‘çš„æ—¶é—´åºåˆ—é¢„æµ‹åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹é‡‡ç”¨æ–‡æœ¬åˆ°æ–‡æœ¬çš„ç”ŸæˆèŒƒå¼ï¼Œå°†æ•°å€¼æ—¶é—´åºåˆ—è½¬æ¢ä¸ºæ ‡è®°åºåˆ—è¿›è¡Œè®­ç»ƒå’Œæ¨ç†ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºé€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒæ•æ‰é€šç”¨æ—¶é—´æ¨¡å¼ï¼Œæ— éœ€é¢†åŸŸç‰¹å¼‚æ€§è®­ç»ƒå³å¯å®Œæˆå¤šç§é¢„æµ‹ä»»åŠ¡ã€‚æ¨¡å‹é€‚ç”¨äºå•†ä¸šæŒ‡æ ‡é¢„æµ‹ã€ä¼ æ„Ÿå™¨æ•°æ®åˆ†æç­‰åœºæ™¯ï¼Œä¸ºæ—¶é—´åºåˆ—åˆ†ææä¾›äº†é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬çš„è§£å†³æ–¹æ¡ˆã€‚å¼€æºç‰ˆæœ¬ä¸ºsmallè§„æ¨¡ï¼Œå¹³è¡¡äº†æ€§èƒ½ä¸è®¡ç®—æ•ˆç‡ã€‚",
      "updated_at": "2025-09-17T17:53:14.778Z",
      "summary_en": "Chronos-T5-small is a compact, pretrained time series forecasting model based on T5 architecture. It excels at converting time series data into text-like sequences for accurate predictions across various domains like finance, energy, and IoT. Its strengths include efficient handling of univariate series, zero-shot generalization, and integration with Hugging Face Transformers. Ideal for researchers and practitioners needing lightweight, scalable forecasting without extensive retraining.",
      "summary_zh": "Chronos-T5-smallæ˜¯äºšé©¬é€ŠåŸºäºT5æ¶æ„å¼€å‘çš„æ—¶é—´åºåˆ—é¢„æµ‹åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹é‡‡ç”¨æ–‡æœ¬åˆ°æ–‡æœ¬çš„ç”ŸæˆèŒƒå¼ï¼Œå°†æ•°å€¼æ—¶é—´åºåˆ—è½¬æ¢ä¸ºæ ‡è®°åºåˆ—è¿›è¡Œè®­ç»ƒå’Œæ¨ç†ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºé€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒæ•æ‰é€šç”¨æ—¶é—´æ¨¡å¼ï¼Œæ— éœ€é¢†åŸŸç‰¹å¼‚æ€§è®­ç»ƒå³å¯å®Œæˆå¤šç§é¢„æµ‹ä»»åŠ¡ã€‚æ¨¡å‹é€‚ç”¨äºå•†ä¸šæŒ‡æ ‡é¢„æµ‹ã€ä¼ æ„Ÿå™¨æ•°æ®åˆ†æç­‰åœºæ™¯ï¼Œä¸ºæ—¶é—´åºåˆ—åˆ†ææä¾›äº†é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬çš„è§£å†³æ–¹æ¡ˆã€‚å¼€æºç‰ˆæœ¬ä¸ºsmallè§„æ¨¡ï¼Œå¹³è¡¡äº†æ€§èƒ½ä¸è®¡ç®—æ•ˆç‡ã€‚",
      "summary_es": "Chronos-T5-small es un modelo de series temporales basado en T5, preentrenado para predecir secuencias numÃ©ricas. Destaca por su capacidad de generalizaciÃ³n en mÃºltiples dominios sin ajuste especÃ­fico. Usa tokenizaciÃ³n numÃ©rica y genera pronÃ³sticos en formato de texto. Ideal para aplicaciones de forecasting en finanzas, energÃ­a o demanda."
    },
    {
      "id": "distilbert/distilbert-base-uncased",
      "source": "hf",
      "name": "distilbert-base-uncased",
      "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "rust",
        "safetensors",
        "distilbert",
        "fill-mask",
        "exbert",
        "en",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "arxiv:1910.01108",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 12227309,
        "hf_likes": 755
      },
      "score": 24832.118000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "DistilBERT-base-uncased æ˜¯ä¸€ä¸ªè½»é‡åŒ–çš„ BERT æ¨¡å‹ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯å°† BERT å‚æ•°é‡å‹ç¼© 40%ï¼ŒåŒæ—¶ä¿ç•™ 97% çš„è¯­è¨€ç†è§£èƒ½åŠ›ã€‚å®ƒé€‚ç”¨äºæ©ç è¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼Œæ”¯æŒå¤šç§æ¡†æ¶ï¼ŒåŒ…æ‹¬ PyTorchã€TensorFlow å’Œ JAXã€‚è¯¥æ¨¡å‹åœ¨è‹±æ–‡æ–‡æœ¬å¤„ç†ä¸­è¡¨ç°é«˜æ•ˆï¼Œç‰¹åˆ«é€‚åˆèµ„æºå—é™æˆ–éœ€è¦å¿«é€Ÿæ¨ç†çš„åœºæ™¯ï¼Œå¦‚æœç´¢ã€åˆ†ç±»å’Œå®ä½“è¯†åˆ«ã€‚",
      "updated_at": "2025-09-17T17:53:14.778Z",
      "summary_en": "DistilBERT is a distilled version of BERT, designed for efficient natural language understanding tasks. It retains 97% of BERT's performance while being 40% smaller and 60% faster, making it ideal for resource-constrained environments. Common use cases include text classification, named entity recognition, and masked language modeling. It supports multiple frameworks and is widely used in production for its balance of speed and accuracy.",
      "summary_zh": "DistilBERT-base-uncased æ˜¯ä¸€ä¸ªè½»é‡åŒ–çš„ BERT æ¨¡å‹ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯å°† BERT å‚æ•°é‡å‹ç¼© 40%ï¼ŒåŒæ—¶ä¿ç•™ 97% çš„è¯­è¨€ç†è§£èƒ½åŠ›ã€‚å®ƒé€‚ç”¨äºæ©ç è¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼Œæ”¯æŒå¤šç§æ¡†æ¶ï¼ŒåŒ…æ‹¬ PyTorchã€TensorFlow å’Œ JAXã€‚è¯¥æ¨¡å‹åœ¨è‹±æ–‡æ–‡æœ¬å¤„ç†ä¸­è¡¨ç°é«˜æ•ˆï¼Œç‰¹åˆ«é€‚åˆèµ„æºå—é™æˆ–éœ€è¦å¿«é€Ÿæ¨ç†çš„åœºæ™¯ï¼Œå¦‚æœç´¢ã€åˆ†ç±»å’Œå®ä½“è¯†åˆ«ã€‚",
      "summary_es": "DistilBERT es un modelo de lenguaje basado en BERT, optimizado para eficiencia y velocidad. Conserva el 97% del rendimiento de BERT original con un 40% menos de parÃ¡metros. Ideal para tareas de procesamiento de lenguaje natural como clasificaciÃ³n de texto, anÃ¡lisis de sentimiento y relleno de mÃ¡scaras. Ampliamente utilizado en entornos con recursos limitados."
    },
    {
      "id": "FacebookAI/roberta-large",
      "source": "hf",
      "name": "roberta-large",
      "url": "https://huggingface.co/FacebookAI/roberta-large",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "onnx",
        "safetensors",
        "roberta",
        "fill-mask",
        "exbert",
        "en",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "arxiv:1907.11692",
        "arxiv:1806.02847",
        "license:mit",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 12085823,
        "hf_likes": 245
      },
      "score": 24294.146,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "RoBERTa-largeæ˜¯åŸºäºTransformeræ¶æ„çš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œç”±Facebook AIå¼€å‘ã€‚å®ƒåœ¨BERTçš„åŸºç¡€ä¸Šé€šè¿‡ä¼˜åŒ–è®­ç»ƒç­–ç•¥ï¼ˆå¦‚ç§»é™¤ä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡ã€ä½¿ç”¨æ›´å¤§æ‰¹æ¬¡å’Œæ›´é•¿çš„åºåˆ—ï¼‰æå‡äº†æ€§èƒ½ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºå¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«å’Œæ©ç è¯­è¨€å»ºæ¨¡ã€‚ä¸»è¦é¢å‘ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…ï¼Œç”¨äºæ„å»ºé«˜æ•ˆçš„NLPåº”ç”¨æˆ–ä½œä¸ºä¸‹æ¸¸ä»»åŠ¡çš„åŸºå‡†æ¨¡å‹ã€‚æ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…æ‹¬PyTorchã€TensorFlowå’ŒJAXã€‚",
      "updated_at": "2025-09-17T17:53:14.778Z",
      "summary_en": "RoBERTa-large is a robust transformer-based language model optimized for masked language modeling. It excels in a wide range of natural language understanding tasks, including text classification, named entity recognition, and sentiment analysis. With strong performance across benchmarks, it is well-suited for research and production applications requiring high accuracy. Its compatibility with multiple frameworks (PyTorch, TensorFlow, JAX, ONNX) ensures flexibility in deployment.",
      "summary_zh": "RoBERTa-largeæ˜¯åŸºäºTransformeræ¶æ„çš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œç”±Facebook AIå¼€å‘ã€‚å®ƒåœ¨BERTçš„åŸºç¡€ä¸Šé€šè¿‡ä¼˜åŒ–è®­ç»ƒç­–ç•¥ï¼ˆå¦‚ç§»é™¤ä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡ã€ä½¿ç”¨æ›´å¤§æ‰¹æ¬¡å’Œæ›´é•¿çš„åºåˆ—ï¼‰æå‡äº†æ€§èƒ½ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºå¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«å’Œæ©ç è¯­è¨€å»ºæ¨¡ã€‚ä¸»è¦é¢å‘ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…ï¼Œç”¨äºæ„å»ºé«˜æ•ˆçš„NLPåº”ç”¨æˆ–ä½œä¸ºä¸‹æ¸¸ä»»åŠ¡çš„åŸºå‡†æ¨¡å‹ã€‚æ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…æ‹¬PyTorchã€TensorFlowå’ŒJAXã€‚",
      "summary_es": "RoBERTa-large es un modelo de lenguaje basado en transformers optimizado para tareas de comprensiÃ³n y generaciÃ³n de texto. Destaca por su entrenamiento robusto sin tareas de siguiente frase, mejorando rendimiento en clasificaciÃ³n, entidad nombrada y relleno de mÃ¡scaras. Usos comunes incluyen anÃ¡lisis de sentimientos, preguntas-respuestas y procesamiento de lenguaje natural en inglÃ©s."
    },
    {
      "id": "google/electra-base-discriminator",
      "source": "hf",
      "name": "electra-base-discriminator",
      "url": "https://huggingface.co/google/electra-base-discriminator",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "rust",
        "electra",
        "pretraining",
        "en",
        "arxiv:1406.2661",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 11547887,
        "hf_likes": 64
      },
      "score": 23127.774,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ELECTRA-base-discriminatoræ˜¯ç”±Googleå¼€å‘çš„ä¸€ç§åŸºäºELECTRAæ¶æ„çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åˆ¤åˆ«å™¨ã€‚è¯¥æ¨¡å‹é€šè¿‡æ›¿æ¢tokenæ£€æµ‹ä»»åŠ¡è¿›è¡Œé¢„è®­ç»ƒï¼Œç›¸æ¯”ä¼ ç»ŸMLMæ–¹æ³•å…·æœ‰æ›´é«˜çš„è®­ç»ƒæ•ˆç‡ã€‚æ¨¡å‹æ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…æ‹¬PyTorchã€TensorFlowå’ŒJAXã€‚é€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æç­‰ä¸‹æ¸¸NLPä»»åŠ¡ï¼Œç‰¹åˆ«é€‚åˆéœ€è¦é«˜æ•ˆæ–‡æœ¬è¡¨å¾çš„åœºæ™¯ã€‚æ¨¡å‹åœ¨è‹±æ–‡è¯­æ–™ä¸Šè®­ç»ƒï¼Œé‡‡ç”¨Apache 2.0å¼€æºåè®®ã€‚",
      "updated_at": "2025-09-17T17:53:14.778Z",
      "summary_en": "ELECTRA-base-discriminator is a pretrained transformer model designed for efficient discriminative tasks. It excels in natural language understanding, including text classification, named entity recognition, and sentiment analysis. Its key strength lies in its pretraining efficiency, outperforming many models of similar size. It is widely applicable in research and production environments for English-language NLP tasks.",
      "summary_zh": "ELECTRA-base-discriminatoræ˜¯ç”±Googleå¼€å‘çš„ä¸€ç§åŸºäºELECTRAæ¶æ„çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åˆ¤åˆ«å™¨ã€‚è¯¥æ¨¡å‹é€šè¿‡æ›¿æ¢tokenæ£€æµ‹ä»»åŠ¡è¿›è¡Œé¢„è®­ç»ƒï¼Œç›¸æ¯”ä¼ ç»ŸMLMæ–¹æ³•å…·æœ‰æ›´é«˜çš„è®­ç»ƒæ•ˆç‡ã€‚æ¨¡å‹æ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…æ‹¬PyTorchã€TensorFlowå’ŒJAXã€‚é€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æç­‰ä¸‹æ¸¸NLPä»»åŠ¡ï¼Œç‰¹åˆ«é€‚åˆéœ€è¦é«˜æ•ˆæ–‡æœ¬è¡¨å¾çš„åœºæ™¯ã€‚æ¨¡å‹åœ¨è‹±æ–‡è¯­æ–™ä¸Šè®­ç»ƒï¼Œé‡‡ç”¨Apache 2.0å¼€æºåè®®ã€‚",
      "summary_es": "ELECTRA-base-discriminator es un modelo de lenguaje preentrenado que utiliza un enfoque de discriminaciÃ³n para el aprendizaje de representaciones. Destaca por su eficiencia computacional y rendimiento en tareas de comprensiÃ³n del lenguaje natural. Es ideal para clasificaciÃ³n de texto, anÃ¡lisis de sentimientos y extracciÃ³n de informaciÃ³n. Soporta mÃºltiples frameworks como PyTorch, TensorFlow y JAX."
    },
    {
      "id": "prajjwal1/bert-tiny",
      "source": "hf",
      "name": "bert-tiny",
      "url": "https://huggingface.co/prajjwal1/bert-tiny",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "BERT",
        "MNLI",
        "NLI",
        "transformer",
        "pre-training",
        "en",
        "arxiv:1908.08962",
        "arxiv:2110.01518",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 10176180,
        "hf_likes": 127
      },
      "score": 20415.86,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "bert-tinyæ˜¯ä¸€ä¸ªè½»é‡çº§BERTæ¨¡å‹ï¼Œä¸“ä¸ºèµ„æºå—é™ç¯å¢ƒè®¾è®¡ã€‚å®ƒåŸºäºBERTæ¶æ„ï¼Œä½†æ˜¾è‘—å‡å°‘äº†å‚æ•°é‡ï¼Œåœ¨ä¿æŒåˆç†æ€§èƒ½çš„åŒæ—¶å¤§å¹…æå‡æ¨ç†é€Ÿåº¦ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€è‡ªç„¶è¯­è¨€æ¨ç†ç­‰ä»»åŠ¡ï¼Œç‰¹åˆ«é€‚åˆç§»åŠ¨è®¾å¤‡æˆ–è¾¹ç¼˜è®¡ç®—åœºæ™¯ã€‚æ”¯æŒPyTorchæ¡†æ¶ï¼Œé¢„è®­ç»ƒæƒé‡å¯ç›´æ¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡çš„å¾®è°ƒã€‚",
      "updated_at": "2025-09-17T17:53:14.778Z",
      "summary_en": "BERT-Tiny is a compact, efficient variant of the BERT model, designed for resource-constrained environments. It is pre-trained on English text and fine-tuned for natural language inference tasks like MNLI. Ideal for applications requiring fast inference and low memory usage, such as mobile or edge devices. Its small size makes it suitable for prototyping and lightweight NLP pipelines.",
      "summary_zh": "bert-tinyæ˜¯ä¸€ä¸ªè½»é‡çº§BERTæ¨¡å‹ï¼Œä¸“ä¸ºèµ„æºå—é™ç¯å¢ƒè®¾è®¡ã€‚å®ƒåŸºäºBERTæ¶æ„ï¼Œä½†æ˜¾è‘—å‡å°‘äº†å‚æ•°é‡ï¼Œåœ¨ä¿æŒåˆç†æ€§èƒ½çš„åŒæ—¶å¤§å¹…æå‡æ¨ç†é€Ÿåº¦ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ã€è‡ªç„¶è¯­è¨€æ¨ç†ç­‰ä»»åŠ¡ï¼Œç‰¹åˆ«é€‚åˆç§»åŠ¨è®¾å¤‡æˆ–è¾¹ç¼˜è®¡ç®—åœºæ™¯ã€‚æ”¯æŒPyTorchæ¡†æ¶ï¼Œé¢„è®­ç»ƒæƒé‡å¯ç›´æ¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡çš„å¾®è°ƒã€‚",
      "summary_es": "BERT-Tiny es una versiÃ³n ultrapequeÃ±a del modelo BERT, optimizada para eficiencia computacional. Ideal para dispositivos con recursos limitados, mantiene capacidades sÃ³lidas en tareas de comprensiÃ³n del lenguaje natural como inferencia (NLI/MNLI). Su diseÃ±o compacto permite despliegues rÃ¡pidos en entornos restringidos, manteniendo un buen rendimiento en clasificaciÃ³n de texto y otras aplicaciones de NLP ligero."
    },
    {
      "id": "trpakov/vit-face-expression",
      "source": "hf",
      "name": "vit-face-expression",
      "url": "https://huggingface.co/trpakov/vit-face-expression",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "vit",
        "image-classification",
        "doi:10.57967/hf/2289",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 8025363,
        "hf_likes": 78
      },
      "score": 16089.726,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "vit-face-expressionæ˜¯åŸºäºVision Transformeræ¶æ„çš„é¢éƒ¨è¡¨æƒ…åˆ†ç±»æ¨¡å‹ï¼Œèƒ½å¤Ÿè¯†åˆ«å›¾åƒä¸­çš„ä¸ƒç§åŸºæœ¬è¡¨æƒ…ï¼ˆå¦‚é«˜å…´ã€æ‚²ä¼¤ã€æ„¤æ€’ç­‰ï¼‰ã€‚è¯¥æ¨¡å‹ä½¿ç”¨PyTorchå’ŒONNXæ ¼å¼æä¾›ï¼Œæ”¯æŒå¿«é€Ÿæ¨ç†å’Œéƒ¨ç½²ï¼Œé€‚ç”¨äºå®æ—¶è¡¨æƒ…åˆ†æåœºæ™¯ã€‚å…¶äº®ç‚¹åœ¨äºç»“åˆäº†ViTçš„å…¨å±€å»ºæ¨¡èƒ½åŠ›ä¸è½»é‡åŒ–è®¾è®¡ï¼Œåœ¨ä¿è¯ç²¾åº¦çš„åŒæ—¶å…·å¤‡è¾ƒé«˜çš„è®¡ç®—æ•ˆç‡ã€‚é€‚ç”¨äºäººæœºäº¤äº’ã€æƒ…æ„Ÿè®¡ç®—æˆ–å¿ƒç†å­¦ç ”ç©¶ç­‰éœ€è¦è‡ªåŠ¨åŒ–è¡¨æƒ…è¯†åˆ«çš„é¢†åŸŸã€‚",
      "updated_at": "2025-09-17T17:53:14.779Z",
      "summary_en": "A Vision Transformer (ViT) model fine-tuned for facial expression classification. It supports PyTorch, ONNX, and SafeTensors formats, enabling efficient deployment across platforms. Ideal for emotion recognition in images, with applications in human-computer interaction and behavioral analysis. High download count reflects its reliability and broad usability.",
      "summary_zh": "vit-face-expressionæ˜¯åŸºäºVision Transformeræ¶æ„çš„é¢éƒ¨è¡¨æƒ…åˆ†ç±»æ¨¡å‹ï¼Œèƒ½å¤Ÿè¯†åˆ«å›¾åƒä¸­çš„ä¸ƒç§åŸºæœ¬è¡¨æƒ…ï¼ˆå¦‚é«˜å…´ã€æ‚²ä¼¤ã€æ„¤æ€’ç­‰ï¼‰ã€‚è¯¥æ¨¡å‹ä½¿ç”¨PyTorchå’ŒONNXæ ¼å¼æä¾›ï¼Œæ”¯æŒå¿«é€Ÿæ¨ç†å’Œéƒ¨ç½²ï¼Œé€‚ç”¨äºå®æ—¶è¡¨æƒ…åˆ†æåœºæ™¯ã€‚å…¶äº®ç‚¹åœ¨äºç»“åˆäº†ViTçš„å…¨å±€å»ºæ¨¡èƒ½åŠ›ä¸è½»é‡åŒ–è®¾è®¡ï¼Œåœ¨ä¿è¯ç²¾åº¦çš„åŒæ—¶å…·å¤‡è¾ƒé«˜çš„è®¡ç®—æ•ˆç‡ã€‚é€‚ç”¨äºäººæœºäº¤äº’ã€æƒ…æ„Ÿè®¡ç®—æˆ–å¿ƒç†å­¦ç ”ç©¶ç­‰éœ€è¦è‡ªåŠ¨åŒ–è¡¨æƒ…è¯†åˆ«çš„é¢†åŸŸã€‚",
      "summary_es": "Modelo de clasificaciÃ³n de expresiones faciales basado en Vision Transformer (ViT). Detecta emociones como alegrÃ­a, tristeza o enfado en imÃ¡genes. Destaca por su precisiÃ³n y eficiencia usando arquitecturas transformer. Ãštil para anÃ¡lisis de comportamiento humano o interacciones persona-computadora."
    },
    {
      "id": "BAAI/bge-base-en-v1.5",
      "source": "hf",
      "name": "bge-base-en-v1.5",
      "url": "https://huggingface.co/BAAI/bge-base-en-v1.5",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "sentence-transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "bert",
        "feature-extraction",
        "sentence-similarity",
        "transformers",
        "mteb",
        "en",
        "arxiv:2401.03462",
        "arxiv:2312.15503",
        "arxiv:2311.13534",
        "arxiv:2310.07554",
        "arxiv:2309.07597",
        "license:mit",
        "model-index",
        "autotrain_compatible",
        "text-embeddings-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 7340919,
        "hf_likes": 346
      },
      "score": 14854.838,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "bge-base-en-v1.5 æ˜¯ä¸€ä¸ªåŸºäº BERT æ¶æ„çš„è‹±æ–‡æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œç”±åŒ—äº¬æ™ºæºäººå·¥æ™ºèƒ½ç ”ç©¶é™¢ï¼ˆBAAIï¼‰å¼€å‘ã€‚è¯¥æ¨¡å‹ä¸»è¦ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„å¥å­æˆ–æ®µè½çº§å‘é‡è¡¨ç¤ºï¼Œé€‚ç”¨äºè¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—ã€ä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬èšç±»ç­‰ä»»åŠ¡ã€‚å…¶äº®ç‚¹åœ¨äºé€šè¿‡å¤§è§„æ¨¡å¯¹æ¯”å­¦ä¹ ä¼˜åŒ–ï¼Œåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ï¼ˆå¦‚ MTEBï¼‰ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ“…é•¿å¤„ç†è‹±æ–‡æ–‡æœ¬çš„è¯­ä¹‰ç†è§£ã€‚é€‚ç”¨äºéœ€è¦é«˜æ•ˆä¸”ç²¾å‡†çš„æ–‡æœ¬è¡¨ç¤ºåµŒå…¥çš„åœºæ™¯ï¼Œå¦‚æœç´¢å¼•æ“ã€æ¨èç³»ç»Ÿæˆ–è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ã€‚",
      "updated_at": "2025-09-17T17:53:14.779Z",
      "summary_en": "BGE-base-en-v1.5 is a BERT-based English sentence embedding model optimized for semantic similarity and retrieval tasks. It excels in generating dense vector representations for text, making it suitable for applications like search, clustering, and recommendation systems. With strong performance on benchmarks like MTEB, it is widely used in both research and production environments. The model supports multiple deployment formats, including PyTorch, ONNX, and SafeTensors, ensuring flexibility and ease of integration.",
      "summary_zh": "bge-base-en-v1.5 æ˜¯ä¸€ä¸ªåŸºäº BERT æ¶æ„çš„è‹±æ–‡æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œç”±åŒ—äº¬æ™ºæºäººå·¥æ™ºèƒ½ç ”ç©¶é™¢ï¼ˆBAAIï¼‰å¼€å‘ã€‚è¯¥æ¨¡å‹ä¸»è¦ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„å¥å­æˆ–æ®µè½çº§å‘é‡è¡¨ç¤ºï¼Œé€‚ç”¨äºè¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—ã€ä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬èšç±»ç­‰ä»»åŠ¡ã€‚å…¶äº®ç‚¹åœ¨äºé€šè¿‡å¤§è§„æ¨¡å¯¹æ¯”å­¦ä¹ ä¼˜åŒ–ï¼Œåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ï¼ˆå¦‚ MTEBï¼‰ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ“…é•¿å¤„ç†è‹±æ–‡æ–‡æœ¬çš„è¯­ä¹‰ç†è§£ã€‚é€‚ç”¨äºéœ€è¦é«˜æ•ˆä¸”ç²¾å‡†çš„æ–‡æœ¬è¡¨ç¤ºåµŒå…¥çš„åœºæ™¯ï¼Œå¦‚æœç´¢å¼•æ“ã€æ¨èç³»ç»Ÿæˆ–è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ã€‚",
      "summary_es": "Modelo de incrustaciÃ³n de texto BGE base en inglÃ©s, versiÃ³n 1.5. Basado en BERT, genera representaciones vectoriales densas para textos. Destaca en similitud semÃ¡ntica y recuperaciÃ³n de informaciÃ³n. Usos: bÃºsqueda, clustering y aplicaciones de NLP que requieran comparaciÃ³n de similitudes entre oraciones."
    }
  ]
}