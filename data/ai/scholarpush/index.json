{
  "generated_at": "2025-09-08T00:00:00+00:00",
  "items": [
    {
      "headline": "çŸ¥è¯†è’¸é¦åœ¨æ–‡æœ¬åˆ°SQLä¸­çš„åº”ç”¨",
      "one_liner": "æœ¬ç ”ç©¶ç»“åˆçŸ¥è¯†è’¸é¦ä¸æ–‡æœ¬åˆ°SQLé—®é¢˜ï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨Qwen2-7Bä½œä¸ºæ•™å¸ˆè®­ç»ƒGPT-2ã€‚",
      "task": "NLP",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "çŸ¥è¯†è’¸é¦"
      ],
      "limitations": [
        "N/A"
      ],
      "links": {
        "paper": "https://www.reddit.com/r/MachineLearning/comments/1n9ufsf/p_knowledge_distillation_for_texttosql_training/",
        "code": "N/A",
        "project": "N/A",
        "pdf": "N/A"
      },
      "tags": [
        "NLP",
        "çŸ¥è¯†è’¸é¦",
        "æ–‡æœ¬åˆ°SQL"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "æœ¬ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯æé«˜æ–‡æœ¬åˆ°SQLè½¬æ¢çš„æ•ˆæœï¼Œåˆ©ç”¨Qwen2-7Bæ¨¡å‹ä½œä¸ºæ•™å¸ˆï¼Œè®­ç»ƒGPT-2æ¨¡å‹ä»¥å¢å¼ºå…¶æ€§èƒ½ã€‚",
      "who_should_try": "ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…",
      "title_i18n": {
        "zh": "çŸ¥è¯†è’¸é¦åœ¨æ–‡æœ¬åˆ°SQLä¸­çš„åº”ç”¨",
        "en": "[P] Knowledge Distillation for Text-to-SQL â€” Training GPT-2 with Qwen2-7B as Teacher"
      },
      "summary_i18n": {
        "zh": "æœ¬ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯æé«˜æ–‡æœ¬åˆ°SQLè½¬æ¢çš„æ•ˆæœï¼Œåˆ©ç”¨Qwen2-7Bæ¨¡å‹ä½œä¸ºæ•™å¸ˆï¼Œè®­ç»ƒGPT-2æ¨¡å‹ä»¥å¢å¼ºå…¶æ€§èƒ½ã€‚",
        "en": "Hey folks, Iâ€™ve been working on an experiment that combines Knowledge Distillation (KD) with the Text-to-SQL problem, and I wanted to share the results + repo with the community. ğŸ¯ Motivation  Natural language â†’ SQL is a powerful way for non-technical users to query databases wit"
      },
      "host": "www.reddit.com",
      "ts": "2025-09-06T08:36:00+00:00",
      "has_code": false,
      "key_numbers_compact": [
        "N/A N/A N/A"
      ]
    },
    {
      "headline": "å¼€æ”¾æºä»£ç çš„è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ç®¡é“",
      "one_liner": "è¯¥é¡¹ç›®æä¾›äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„ç®¡é“ï¼Œæ—¨åœ¨ä¸ºä½èµ„æºè¯­è¨€è¿›è¡Œè§†é¢‘é…éŸ³ï¼Œåˆæ­¥ç›®æ ‡ä¸ºæ³°å¢å›ºè¯­ã€‚",
      "task": "ASR",
      "type": "project",
      "novelty": "data",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "è§†é¢‘é…éŸ³"
      ],
      "limitations": [
        "N/A"
      ],
      "links": {
        "paper": "N/A",
        "code": "N/A",
        "project": "https://www.reddit.com/r/MachineLearning/comments/1n9wnel/p_an_opensource_pipeline_for_speechtospeech/",
        "pdf": "N/A"
      },
      "tags": [
        "ASR",
        "å¤šæ¨¡æ€",
        "ç¿»è¯‘"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "è¯¥é¡¹ç›®å±•ç¤ºäº†ä¸€ä¸ªç”¨äºä½èµ„æºè¯­è¨€çš„è§†é¢‘é…éŸ³çš„å¼€æ”¾æºä»£ç ç®¡é“ï¼Œæ—¨åœ¨è§£å†³è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ä¸­çš„æŒ‘æˆ˜ã€‚",
      "who_should_try": "å¤šæ¨¡æ€ç³»ç»Ÿç ”ç©¶è€…",
      "title_i18n": {
        "zh": "å¼€æ”¾æºä»£ç çš„è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ç®¡é“",
        "en": "å¼€æ”¾æºä»£ç çš„è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ç®¡é“"
      },
      "summary_i18n": {
        "zh": "è¯¥é¡¹ç›®å±•ç¤ºäº†ä¸€ä¸ªç”¨äºä½èµ„æºè¯­è¨€çš„è§†é¢‘é…éŸ³çš„å¼€æ”¾æºä»£ç ç®¡é“ï¼Œæ—¨åœ¨è§£å†³è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ä¸­çš„æŒ‘æˆ˜ã€‚",
        "en": "è¯¥é¡¹ç›®æä¾›äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„ç®¡é“ï¼Œæ—¨åœ¨ä¸ºä½èµ„æºè¯­è¨€è¿›è¡Œè§†é¢‘é…éŸ³ï¼Œåˆæ­¥ç›®æ ‡ä¸ºæ³°å¢å›ºè¯­ã€‚"
      },
      "host": "",
      "ts": "2025-09-08T00:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": [
        "N/A N/A N/A"
      ]
    },
    {
      "headline": "åœ¨çº¿å±‚æ¬¡èšç±»æ–°é—»äº‹ä»¶çš„ç¨³å®šæ€§é—®é¢˜",
      "one_liner": "æœ¬ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åœ¨æµåª’ä½“ç®¡é“ä¸­ä¿æŒäº‹ä»¶IDåœ¨åˆå¹¶/æ‹†åˆ†æ—¶çš„ç¨³å®šæ€§ã€‚",
      "task": "IR",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "äº‹ä»¶èšç±»"
      ],
      "limitations": [
        "N/A"
      ],
      "links": {
        "paper": "https://www.reddit.com/r/MachineLearning/comments/1n9xg20/d_online_hierarchical_clustering_for_news_how_to/",
        "code": "N/A",
        "project": "N/A",
        "pdf": "N/A"
      },
      "tags": [
        "IR",
        "èšç±»",
        "æ–°é—»"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åœ¨çº¿å±‚æ¬¡èšç±»æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜æ–°é—»äº‹ä»¶åœ¨æµåª’ä½“å¤„ç†ä¸­çš„ç¨³å®šæ€§ï¼Œç¡®ä¿äº‹ä»¶IDåœ¨åˆå¹¶å’Œæ‹†åˆ†æ—¶ä¿æŒä¸€è‡´ã€‚",
      "who_should_try": "æ•°æ®ç§‘å­¦å®¶å’Œæ–°é—»åˆ†æå¸ˆ",
      "title_i18n": {
        "zh": "åœ¨çº¿å±‚æ¬¡èšç±»æ–°é—»äº‹ä»¶çš„ç¨³å®šæ€§é—®é¢˜",
        "en": "[D] Online hierarchical clustering for news: how to keep event IDs stable under merges/splits in a streaming pipeline?"
      },
      "summary_i18n": {
        "zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åœ¨çº¿å±‚æ¬¡èšç±»æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜æ–°é—»äº‹ä»¶åœ¨æµåª’ä½“å¤„ç†ä¸­çš„ç¨³å®šæ€§ï¼Œç¡®ä¿äº‹ä»¶IDåœ¨åˆå¹¶å’Œæ‹†åˆ†æ—¶ä¿æŒä¸€è‡´ã€‚",
        "en": "Iâ€™m building a news ingestion system (currently Poland-focused; designed to scale) that clusters incoming articles into â€œeventsâ€ powering maps and graph views. Pipeline: embeddings â†’ cosine HAC with a fixed threshold â†’ periodic (5min) recluster. Granularity, time decay, and summa"
      },
      "host": "www.reddit.com",
      "ts": "2025-09-06T11:43:06+00:00",
      "has_code": false,
      "key_numbers_compact": [
        "N/A N/A N/A"
      ]
    },
    {
      "headline": "å¿«é€Ÿæœºå™¨å­¦ä¹ åœ¨åµŒå…¥å¼DSPä¸­çš„åº”ç”¨",
      "one_liner": "æœ¬ç ”ç©¶å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨é¢†åŸŸå¯å‘çš„æ¨¡å‹æ¥æå‡åµŒå…¥å¼æ•°å­—ä¿¡å·å¤„ç†çš„æ€§èƒ½ã€‚",
      "task": "DSP",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "é¢†åŸŸå¯å‘æ¨¡å‹"
      ],
      "limitations": [
        "N/A"
      ],
      "links": {
        "paper": "https://www.reddit.com/r/MachineLearning/comments/1nauq2g/p_fast_ml_for_funky_fx_using_domain_inspired/",
        "code": "N/A",
        "project": "N/A",
        "pdf": "N/A"
      },
      "tags": [
        "DSP",
        "å¿«é€ŸML",
        "æ¨¡å‹"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "æœ¬ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡é¢†åŸŸå¯å‘çš„æ¨¡å‹æ¥ä¼˜åŒ–åµŒå…¥å¼æ•°å­—ä¿¡å·å¤„ç†çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†å¿«é€Ÿæœºå™¨å­¦ä¹ çš„æ½œåŠ›ã€‚",
      "who_should_try": "åµŒå…¥å¼ç³»ç»Ÿå¼€å‘è€…",
      "title_i18n": {
        "zh": "å¿«é€Ÿæœºå™¨å­¦ä¹ åœ¨åµŒå…¥å¼DSPä¸­çš„åº”ç”¨",
        "en": "[P] Fast ML for Funky FX: Using domain inspired models for embedded DSP"
      },
      "summary_i18n": {
        "zh": "æœ¬ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡é¢†åŸŸå¯å‘çš„æ¨¡å‹æ¥ä¼˜åŒ–åµŒå…¥å¼æ•°å­—ä¿¡å·å¤„ç†çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†å¿«é€Ÿæœºå™¨å­¦ä¹ çš„æ½œåŠ›ã€‚",
        "en": "submitted by    /u/boscillator   [link]   [comments]"
      },
      "host": "www.reddit.com",
      "ts": "2025-09-07T14:32:26+00:00",
      "has_code": false,
      "key_numbers_compact": [
        "N/A N/A N/A"
      ]
    },
    {
      "headline": "AIåœ¨Donkey Kong Countryä¸­çš„åº”ç”¨",
      "one_liner": "è¯¥é¡¹ç›®å±•ç¤ºäº†å¦‚ä½•è®­ç»ƒAIåœ¨Donkey Kong Countryæ¸¸æˆä¸­è¿›è¡Œç‰¹å®šä»»åŠ¡ã€‚",
      "task": "Agent",
      "type": "project",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "æ¸¸æˆAIè®­ç»ƒ"
      ],
      "limitations": [
        "N/A"
      ],
      "links": {
        "paper": "N/A",
        "code": "https://github.com/pa",
        "project": "https://www.reddit.com/r/MachineLearning/comments/1nb5j8f/p_i_trained_an_ai_to_play_donkey_kong_country/",
        "pdf": "N/A"
      },
      "tags": [
        "Agent",
        "æ¸¸æˆ",
        "AIè®­ç»ƒ"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "è¯¥é¡¹ç›®å±•ç¤ºäº†å¦‚ä½•è®­ç»ƒä¸€ä¸ªAIä»£ç†åœ¨Donkey Kong Countryæ¸¸æˆä¸­æ‰§è¡Œç‰¹å®šä»»åŠ¡ï¼Œæä¾›äº†ç›¸å…³çš„ä»£ç å’Œè®­ç»ƒç¯å¢ƒã€‚",
      "who_should_try": "æ¸¸æˆå¼€å‘è€…å’ŒAIç ”ç©¶è€…",
      "title_i18n": {
        "zh": "AIåœ¨Donkey Kong Countryä¸­çš„åº”ç”¨",
        "en": "AIåœ¨Donkey Kong Countryä¸­çš„åº”ç”¨"
      },
      "summary_i18n": {
        "zh": "è¯¥é¡¹ç›®å±•ç¤ºäº†å¦‚ä½•è®­ç»ƒä¸€ä¸ªAIä»£ç†åœ¨Donkey Kong Countryæ¸¸æˆä¸­æ‰§è¡Œç‰¹å®šä»»åŠ¡ï¼Œæä¾›äº†ç›¸å…³çš„ä»£ç å’Œè®­ç»ƒç¯å¢ƒã€‚",
        "en": "è¯¥é¡¹ç›®å±•ç¤ºäº†å¦‚ä½•è®­ç»ƒAIåœ¨Donkey Kong Countryæ¸¸æˆä¸­è¿›è¡Œç‰¹å®šä»»åŠ¡ã€‚"
      },
      "host": "",
      "ts": "2025-09-08T00:00:00+00:00",
      "has_code": true,
      "key_numbers_compact": [
        "N/A N/A N/A"
      ]
    },
    {
      "headline": "AIç¼–ç åŠ©æ‰‹çš„é¢†åŸŸçŸ¥è¯†åº”ç”¨",
      "one_liner": "è¯¥é¡¹ç›®å±•ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªAIç¼–ç åŠ©æ‰‹ï¼Œä½¿å…¶èƒ½å¤Ÿç†è§£å›¢é˜Ÿçš„é¢†åŸŸçŸ¥è¯†å’Œæ¶æ„å†³ç­–ã€‚",
      "task": "Agent",
      "type": "project",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "é¢†åŸŸçŸ¥è¯†æ•´åˆ"
      ],
      "limitations": [
        "N/A"
      ],
      "links": {
        "paper": "https://www.reddit.com/r/MachineLearning/comments/1nanw9i/p_terra_code_cli_an_ai_coding_assistant_with/",
        "code": "N/A",
        "project": "N/A",
        "pdf": "N/A"
      },
      "tags": [
        "Agent",
        "ç¼–ç åŠ©æ‰‹",
        "é¢†åŸŸçŸ¥è¯†"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "è¯¥é¡¹ç›®æ¢è®¨äº†å¦‚ä½•æ„å»ºä¸€ä¸ªAIç¼–ç åŠ©æ‰‹ï¼Œä½¿å…¶èƒ½å¤Ÿç†è§£å›¢é˜Ÿçš„é¢†åŸŸçŸ¥è¯†å’Œæ¶æ„å†³ç­–ï¼Œæå‡ç¼–ç æ•ˆç‡ã€‚",
      "who_should_try": "è½¯ä»¶å¼€å‘è€…",
      "title_i18n": {
        "zh": "AIç¼–ç åŠ©æ‰‹çš„é¢†åŸŸçŸ¥è¯†åº”ç”¨",
        "en": "[P] Terra Code CLI â€“ An AI coding assistant with domain knowledge and semantic code search"
      },
      "summary_i18n": {
        "zh": "è¯¥é¡¹ç›®æ¢è®¨äº†å¦‚ä½•æ„å»ºä¸€ä¸ªAIç¼–ç åŠ©æ‰‹ï¼Œä½¿å…¶èƒ½å¤Ÿç†è§£å›¢é˜Ÿçš„é¢†åŸŸçŸ¥è¯†å’Œæ¶æ„å†³ç­–ï¼Œæå‡ç¼–ç æ•ˆç‡ã€‚",
        "en": "One limitation Iâ€™ve noticed with most AI coding assistants is that they donâ€™t really understand a teamâ€™s domain knowledge or architectural decisions. To explore this, we built a small CLI project: Terra Code CLI. The idea was to see if an assistant could feel more like a senior d"
      },
      "host": "www.reddit.com",
      "ts": "2025-09-07T08:26:54+00:00",
      "has_code": false,
      "key_numbers_compact": [
        "N/A N/A N/A"
      ]
    },
    {
      "headline": "è¯­è¨€æ¨¡å‹çš„å¹»è§‰ç°è±¡æ¢è®¨",
      "one_liner": "è¯¥è®¨è®ºæ¢è®¨äº†è¯­è¨€æ¨¡å‹å¹»è§‰ç°è±¡çš„åŸå› åŠå…¶å½±å“ã€‚",
      "task": "NLP",
      "type": "discussion",
      "novelty": "N/A",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "N/A"
      ],
      "limitations": [
        "N/A"
      ],
      "links": {
        "paper": "https://www.reddit.com/r/MachineLearning/comments/1namvsk/why_language_models_hallucinate_openai_pseudo/",
        "code": "N/A",
        "project": "N/A",
        "pdf": "N/A"
      },
      "tags": [
        "NLP",
        "å¹»è§‰",
        "æ¨¡å‹"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "è¯¥è®¨è®ºæ¢è®¨äº†è¯­è¨€æ¨¡å‹å¹»è§‰ç°è±¡çš„åŸå› ï¼Œåˆ†æäº†å…¶å¯¹AIç³»ç»Ÿå¯é æ€§çš„å½±å“ã€‚",
      "who_should_try": "AIç ”ç©¶è€…",
      "title_i18n": {
        "zh": "è¯­è¨€æ¨¡å‹çš„å¹»è§‰ç°è±¡æ¢è®¨",
        "en": "Why Language Models Hallucinate - OpenAi pseudo paper - [D]"
      },
      "summary_i18n": {
        "zh": "è¯¥è®¨è®ºæ¢è®¨äº†è¯­è¨€æ¨¡å‹å¹»è§‰ç°è±¡çš„åŸå› ï¼Œåˆ†æäº†å…¶å¯¹AIç³»ç»Ÿå¯é æ€§çš„å½±å“ã€‚",
        "en": "Hey Anybody read this ? It seems rather obvious and low quality, or am I missing something ?  https://openai.com/index/why-language-models-hallucinate/ â€œAt OpenAI, weâ€™re working hard to make AI systems more useful and reliable. Even as language models become more capable, one cha"
      },
      "host": "www.reddit.com",
      "ts": "2025-09-07T07:21:15+00:00",
      "has_code": false,
      "key_numbers_compact": [
        "N/A N/A N/A"
      ]
    }
  ],
  "refs": [],
  "stats": {
    "by_task": {
      "LLM": 0
    },
    "with_code": 0,
    "new_benchmarks": 0
  },
  "must_reads": [
    0,
    1,
    2,
    3,
    4
  ],
  "nice_to_read": [
    5,
    6,
    7,
    8
  ],
  "deep_dive": {
    "title": "å¯é€‰ä¸»é¢˜",
    "summary": "ä¸‰å¥è¯è¦ç‚¹ï¼ˆå¯é€‰ï¼‰",
    "refs": []
  }
}